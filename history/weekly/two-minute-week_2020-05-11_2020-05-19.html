
<!doctype html>
<html>
  <head>
    <meta charset=utf-8>
    <title>Future of Coding History</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <style>.alert{border-radius:0}.msg-response{background-color:white!important}</style>
  </head>
  <body class="p-3">
<div id="2020-05-06T22:03:52.228Z" class="alert alert-dark msg-root my-1 p-2 bg-light"><span class="small text-muted"><a href="#2020-05-06T22:03:52.228Z">2020-05-06 22:03:52</a></span> <span class="font-weight-bold">Unknown User: </span> <p><p>MSG NOT FOUND</p>
</p> <div id="2020-05-10T22:08:19.316Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-10T22:08:19.316Z">2020-05-10 22:08:19</a></span> <span class="font-weight-bold">Ivan Reese: </span> <p><p>One as yet unimplemented plan is that abstraction will come from building "symbols", which are a collection of graphics / logic wrapped up into an isolated unit with a clearly defined interface ‚Äî&nbsp;typical patcher stuff.</p>
<p>Each symbol instance will need its own sense of time. When looking at a particular instance, all child instances will execute "infinitely fast" to simulate continuous time semantics. All parent instances will execute discretely, only when necessary to satisfy the needs of the currently observed instance.</p>
<p>The GUI, including things like pulling a point off an edge, would be the ur parent of the simulation hierarchy. So if it were possible to run time backwards <em>outside</em> the GUI level, your editing interactions would gradually be undone, and that pulled point would hop back onto the edge where you pulled it off, right at the moment that you had pulled it (since the flow of time of the points-and-edges simulation is happening <em>inside</em> the GUI).</p>
<p>Not sure I'll end up going with this plan, though. I have stack of imagined "it would feel nice to <em>__</em>" experiences that guide my development. I'm trying each of them, keeping the ones that feel most simpatico. So we'll see!</p>
</p></div><div id="2020-05-10T22:10:51.316Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-10T22:10:51.316Z">2020-05-10 22:10:51</a></span> <span class="font-weight-bold">Ivan Reese: </span> <p><p>Also ‚Äî
&gt; Moving time backwards no longer includes that point.
Maybe. Some rewind strategies I've played with have this behaviour. Some don't. Still trying to find the approach (likely a hybrid of strategies) that feels nicest to use.</p>
</p></div><div id="2020-05-11T00:15:16.317Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-11T00:15:16.317Z">2020-05-11 00:15:16</a></span> <span class="font-weight-bold">Kartik Agaram: </span> <p><blockquote style="margin-left:1em;color:#555555;font-style:italic"><p>The major problem encountered in time travel is not that of accidentally becoming your own father or mother. There is no problem involved in becoming your own father or mother that a broadminded and well-adjusted family can't cope with. There is also no problem in changing the course of history; the course of history does not change because it all fits together like a jigsaw. All the important changes have happened before the things they were supposed to change and it all sorts itself out in the end.</p>
<p>No, the major problem is quite simply one of grammar, and the main work to consult in this matter is Dr Dan Streetmentioner's <em>Time Traveller's Handbook of 1001 Tense Formations</em>. It will tell you for instance how to describe something that was about to happen to you in the past before you avoided it by time-jumping forward two days in order to avoid it. The event will be described differently according to whether you are talking about it from the standpoint of your own natural time, from a time in the further future, or a time in the further past and is further complicated by the possibility of conducting conversations whilst you are actually travelling from one time to another with the intention of becoming your own father or mother.</p>
<p>Most readers get as far as the Future Semi-Conditionally Modified Subinverted Plagal Past Subjunctive Intentional before giving up: and in fact in later editions of the book all the pages beyond this point have been left blank to save on printing costs.
-- <em>"The Hitchhiker's Guide to the Galaxy"</em></p>
</blockquote>
</p></div></div><div id="2020-05-11T12:42:53.318Z" class="alert alert-dark msg-root my-1 p-2 bg-light"><span class="small text-muted"><a href="#2020-05-11T12:42:53.318Z">2020-05-11 12:42:53</a></span> <span class="font-weight-bold">Chris Maughan: </span> <p><p>It was a slow week this week.  I found I didn't have my usual energy for after-hours projects, and I needed a rest this weekend.  As is usually the case in such circumstances, I spent some time cleaning up code and refactoring - I often find such activities help keep the project momentum up, while requiring less time &amp; effort.
I have spent some time recently thinking about how to manage note events and synchronize beats &amp; timing.  It seems like a good idea to integrate Ableton Link at the outset, because on some level it helps drive towards a cleaner management of such things.  It is also really nice to have a built in way for musicians to work together with a live coder; a USP perhaps.  I don't say it in the video, but the tempo of the audio is being controlled using the iPad drumming app, which the sample app and the synth are aligning with.
Another piece of ongoing work is the integration of Orca-c which I've shown previously.  This is an embedded Orca inside my text editor and forms one way in which a coder can drive the synthesizer (and later, I hope, some geometry/graphics too).  Orca isn't the only way I intend to generate music, but it represents a relatively easier integration than music languages, etc.  As I say in the video, there is still work to do to complete this feature.</p>
</p> </div><div id="2020-05-08T03:26:23.261Z" class="alert alert-dark msg-root my-1 p-2 bg-light"><span class="small text-muted"><a href="#2020-05-08T03:26:23.261Z">2020-05-08 03:26:23</a></span> <span class="font-weight-bold">Unknown User: </span> <p><p>MSG NOT FOUND</p>
</p> <div id="2020-05-12T15:12:56.320Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-12T15:12:56.320Z">2020-05-12 15:12:56</a></span> <span class="font-weight-bold">Garth Goldwater: </span> <p><p><a href="http://calca.io/"></a><a href="http://calca.io/">http://calca.io/</a> for any curious folks</p>
</p></div></div><div id="2020-05-15T10:59:54.327Z" class="alert alert-dark msg-root my-1 p-2 bg-light"><span class="small text-muted"><a href="#2020-05-15T10:59:54.327Z">2020-05-15 10:59:54</a></span> <span class="font-weight-bold">U0123H7JRDM: </span> <p><p>Hi, in this very short 2nd introduction video I'll show you how to create a body mass index calculator with my flow-editor step by step. It also shows (very briefly) the new debug functionality to help "follow" the flow. <a href="https://youtu.be/oVNdm3JWE4g"></a><a href="https://youtu.be/oVNdm3JWE4g">https://youtu.be/oVNdm3JWE4g</a> </p>
</p> <div id="2020-05-15T13:24:40.331Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T13:24:40.331Z">2020-05-15 13:24:40</a></span> <span class="font-weight-bold">William Taysom: </span> <p><p>Here I see one slider feeding into another feeding into an expression... so what do the arrows mean in this editor?</p>
</p></div><div id="2020-05-15T13:30:47.335Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T13:30:47.335Z">2020-05-15 13:30:47</a></span> <span class="font-weight-bold">U0123H7JRDM: </span> <p><p>Do you mean the arrows of the connections between the nodes? That's the path and direction the flow follows when it is executed. In this example the sliders both trigger the weightSliderTask-node (each slider node has an "onChange" property which is assigned to the weightSliderTask-node for both sliders in this example)</p>
</p></div><div id="2020-05-15T14:02:26.340Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T14:02:26.340Z">2020-05-15 14:02:26</a></span> <span class="font-weight-bold">U0123H7JRDM: </span> <p><p>The tech stack on the frontend for those interested : mainly react, redux, react-konva, victor, rxjs, bootstrap, material ui slider, immer and a custom service worker running the flowrunner </p>
</p></div><div id="2020-05-15T16:06:20.347Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T16:06:20.347Z">2020-05-15 16:06:20</a></span> <span class="font-weight-bold">Ryan King: </span> <p><p>I find it a bit strange that weight flows into height when no data flowing from weight will change height in anyway. Do you think it would make more sense for both sliders to feed into the expression in parallel?</p>
</p></div><div id="2020-05-15T16:21:23.355Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T16:21:23.355Z">2020-05-15 16:21:23</a></span> <span class="font-weight-bold">U0123H7JRDM: </span> <p><p>I see your point, from my perspective the current approach makes sense because you let the payload grow as it progresses through the flow. From a user perspective that might be making less sense. I've got support for parellel flows already, I'll see if that will work here. Thanks for the feedback!</p>
</p></div><div id="2020-05-15T16:28:51.361Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T16:28:51.361Z">2020-05-15 16:28:51</a></span> <span class="font-weight-bold">Chris Maughan: </span> <p><p>My synthesiser project works in a similar way - multiple notes and generated channels of audio data flow along the pipeline, sometimes combining and splitting (like when the notes are combined into a stereo stream or when a pair of oscillators go into a mixer). There is a definite ‚Äòflow direction‚Äô.</p>
</p></div><div id="2020-05-15T16:32:11.361Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T16:32:11.361Z">2020-05-15 16:32:11</a></span> <span class="font-weight-bold">Ryan King: </span> <p><p>Maybe there's a way to indicate the data being collected as it flows down the pipeline. If we could see it, I believe it would make more sense.</p>
</p></div><div id="2020-05-15T16:39:51.362Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T16:39:51.362Z">2020-05-15 16:39:51</a></span> <span class="font-weight-bold">Garth Goldwater: </span> <p><p>i understand that the visualization is a work in progress‚ÄîI‚Äôm more excited by exactly how little you have to type to get these things connected together. so much of traditional UI programming depends on essentially ‚Äúwatch‚Äù statements</p>
</p></div><div id="2020-05-15T16:46:09.365Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T16:46:09.365Z">2020-05-15 16:46:09</a></span> <span class="font-weight-bold">U0123H7JRDM: </span> <p><p>Yes it's a work in progress but there's already much more too show then I did so far (2 minutes is very short offcourse ;-) ). Maybe I'll prepare a longer video and post it in #feedback, I'll think about it</p>
</p></div><div id="2020-05-15T16:50:14.368Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T16:50:14.368Z">2020-05-15 16:50:14</a></span> <span class="font-weight-bold">U0123H7JRDM: </span> <p><p>The way parallel flows currently works: there's a special start node and a parallel-resolve node.. the start node can split into multiple flows and the resolve node waits until they all ran and then passes all payloads through to the next node. </p>
</p></div><div id="2020-05-15T17:02:36.368Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T17:02:36.368Z">2020-05-15 17:02:36</a></span> <span class="font-weight-bold">Chris Maughan: </span> <p><p>Have you considered a directed graph where you 'pull data' from the far end?  So that parallel resolve will happen because the dependent node will evaluate the nodes further back until all inputs are up to date.</p>
</p></div><div id="2020-05-15T17:08:00.372Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T17:08:00.372Z">2020-05-15 17:08:00</a></span> <span class="font-weight-bold">U0123H7JRDM: </span> <p><p>I've got a special type of connection which is called "injection" which sounds like this and I was thinking about it actually as an alternative. The current implementation of that is rather limited though, it's just one level deep instead of going further if there are more nodes connected. </p>
</p></div><div id="2020-05-15T17:12:28.372Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T17:12:28.372Z">2020-05-15 17:12:28</a></span> <span class="font-weight-bold">U0123H7JRDM: </span> <p><p>this is the current parallel solution. Both sliders trigger the first node when a slider is changed in the UI, this is specified in the 'onChange' property of both slider nodes (you can see it in the video)</p>
</p></div><div id="2020-05-15T17:53:59.373Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T17:53:59.373Z">2020-05-15 17:53:59</a></span> <span class="font-weight-bold">Chris Maughan: </span> <p><p>I see, so does your diagram imply that you only have a single input/output for each node?</p>
</p></div><div id="2020-05-15T17:54:13.373Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T17:54:13.373Z">2020-05-15 17:54:13</a></span> <span class="font-weight-bold">Chris Maughan: </span> <p><p>(at least in terms of flow...?)</p>
</p></div><div id="2020-05-15T18:18:23.380Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T18:18:23.380Z">2020-05-15 18:18:23</a></span> <span class="font-weight-bold">U0123H7JRDM: </span> <p><p>Each node can be triggered by multiple nodes independently (the parallel example is an exception to that) and the payload the node receives determines the input parameters/properties and not all properties need to be handled by the node, most of them are usually just passed on to the next node. A node can trigger multiple output nodes </p>
</p></div><div id="2020-05-16T10:05:24.384Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-16T10:05:24.384Z">2020-05-16 10:05:24</a></span> <span class="font-weight-bold">U0123H7JRDM: </span> <p><p>The current system probably is limited in its applications because it doesn't have "control-inputs", I think I could implement these by adding observable properties in a task. I am going to that explore that idea further. <strong>Chris Maughan</strong> how is this implemented in your application?</p>
</p></div><div id="2020-05-16T11:15:53.385Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-16T11:15:53.385Z">2020-05-16 11:15:53</a></span> <span class="font-weight-bold">U0123H7JRDM: </span> <p><p>In the meantime I want to share another screenshot to show a bit more of the other applications of the flow-editor : here the flow-editor is used to create a flow which controls a react-native app. When you press save in the editor a json file is stored on the local file system and triggers the rebuild of the reactnative-app. The flow flow contains both the navigational structure and the form definitions as well as the calculations. The flow-editor runs locally here (using node.js).</p>
</p></div><div id="2020-05-16T20:42:51.386Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-16T20:42:51.386Z">2020-05-16 20:42:51</a></span> <span class="font-weight-bold">Chris Maughan: </span> <p><p>Hi U0123H7JRDM, I think my approach is quite different to yours.  Essentially I have a directed graph.  Once per frame, I read the output node(s) and they try to 'compute'.  First they look at their inputs, and if any of them are 'flow data' or 'control data', they are checked to see if they are current.  If not, the graph walks further up and evaluates until the node inputs are 'current'.  Then it can be computed.  So it's very much a 'pull' architecture.
I have 3 basic types of 'pins' on my nodes.
‚Ä¢ Flow Data.  This is like a big bundle of data arrays.  The node is expected to work on all data streams it receives in each compute step.  For music, these arrays are typically buffers of audio data; often with 1 buffer per note of polyphony.<br>‚Ä¢ Control Data. These are also bundles of arrays, but typically contain control information, such as modulation curves.  It is just convenient for me to separate the concept of control from data.
‚Ä¢ Parameters.  These are just data values such as float, int, etc.  They can be connected to other nodes, but they are not 'evaluated' to satisfy graph compute.  They are considered 'always valid', but that doesn't mean that the node won't walk back up the connection chain of the parameter to find the source value.
It should be considered prototype/research code, but you can see the graph Compute function here: <a href="https://github.com/cmaughan/nodegraph/blob/master/src/model/graph.cpp">https://github.com/cmaughan/nodegraph/blob/master/src/model/graph.cpp</a></p>
</p></div><div id="2020-05-17T08:13:19.389Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-17T08:13:19.389Z">2020-05-17 08:13:19</a></span> <span class="font-weight-bold">U0123H7JRDM: </span> <p><p>Hi, thanks for sharing your approach!
Summarizing: the main difference between our implementations is that in yours in each frame the whole graph gets evaluated and in mine a node gets only triggers by an event (which can be external) and this can be dependent of time but certainly not necessarily and most of the time it's user input that trigger a node or other node's triggering other nodes. Both our graphs are directed I think. Also the way the graph gets evaluated is different, in yours the pull architecture as you describe is very different then in mine , which is forward directed.
Very interesting this discussion about our approaches, I am going to think about it some more.</p>
</p></div><div id="2020-05-17T09:09:31.389Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-17T09:09:31.389Z">2020-05-17 09:09:31</a></span> <span class="font-weight-bold">Chris Maughan: </span> <p><p>Yes, you have it right I think.  Except to say that nodes in my graph that aren't required won't wind up getting evaluated; i.e. if they aren't part of the dependency chain of the output node, then they will not evaluate, and if a node is 'current', it doesn't need to do any work.   I don't allow loops in the network; i.e. a node will not evaluate twice per graph evaluation.  For this reason, I have a generation number on each node which can track the global generation and avoid repeat computation.  It makes the evaluation logic quite clean I think.</p>
</p></div><div id="2020-05-17T09:12:11.389Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-17T09:12:11.389Z">2020-05-17 09:12:11</a></span> <span class="font-weight-bold">Chris Maughan: </span> <p><p>I am probably quite influenced by the Maya directed graph approach, which was my first exposure to such an idea; though I don't implement the push/pull architecture that they do.</p>
</p></div><div id="2020-05-17T10:18:53.390Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-17T10:18:53.390Z">2020-05-17 10:18:53</a></span> <span class="font-weight-bold">U0123H7JRDM: </span> <p><p>My influence was the node-red project</p>
</p></div></div><div id="2020-05-15T12:20:33.329Z" class="alert alert-dark msg-root my-1 p-2 bg-light"><span class="small text-muted"><a href="#2020-05-15T12:20:33.329Z">2020-05-15 12:20:33</a></span> <span class="font-weight-bold">Mariano Guerra: </span> <p><p>Instadeq Week in Two Minutes #5: Form builder cell to create forms that emit output on change and submit, register and reload providers dynamically and allow services to specify configuration parameters that appear in the UI: <a href="https://youtu.be/Bk8SBjTRJLg">https://youtu.be/Bk8SBjTRJLg</a></p>
</p> <div id="2020-05-15T13:05:17.330Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T13:05:17.330Z">2020-05-15 13:05:17</a></span> <span class="font-weight-bold">U0123H7JRDM: </span> <p><p>Do you work on this fulltime? Great progress in a week time I think!</p>
</p></div><div id="2020-05-15T13:50:47.335Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T13:50:47.335Z">2020-05-15 13:50:47</a></span> <span class="font-weight-bold">Mariano Guerra: </span> <p><p>yes, I work full time</p>
</p></div><div id="2020-05-15T13:53:56.336Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T13:53:56.336Z">2020-05-15 13:53:56</a></span> <span class="font-weight-bold">U0123H7JRDM: </span> <p><p>That's awesome! My own project is still a side project. What's your tech stack on the frontend?</p>
</p></div><div id="2020-05-15T13:55:07.337Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T13:55:07.337Z">2020-05-15 13:55:07</a></span> <span class="font-weight-bold">Mariano Guerra: </span> <p><p>react, bootstrap, immutablejs, voca, draftjs, echarts</p>
</p></div><div id="2020-05-15T13:59:20.338Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T13:59:20.338Z">2020-05-15 13:59:20</a></span> <span class="font-weight-bold">U0123H7JRDM: </span> <p><p>Cool! I don't know voca and echarts so I'll look into those</p>
</p></div><div id="2020-05-15T14:00:53.340Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T14:00:53.340Z">2020-05-15 14:00:53</a></span> <span class="font-weight-bold">Mariano Guerra: </span> <p><p>voca is just string functions, echarts is just if you want charts üòÑ</p>
</p></div><div id="2020-05-15T16:21:52.355Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T16:21:52.355Z">2020-05-15 16:21:52</a></span> <span class="font-weight-bold">Ryan King: </span> <p><p>I don't have much input on this besides it looks like you're making good progress. I do know of a few smaller companies that need a super simple self setup data querying system like this, but a big thing for them is collating the data in nice reports for upper management. Do plan on helping people produce reports/documents from their queries, or are you just looking at the data analysis side of things?</p>
</p></div><div id="2020-05-15T22:26:31.383Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T22:26:31.383Z">2020-05-15 22:26:31</a></span> <span class="font-weight-bold">Mariano Guerra: </span> <p><p>reports and documents is the end goal, it's just that we know how to solve that part so I'm not showing that much and leaving the final touches on that to the end üôÇ</p>
</p></div><div id="2020-05-15T22:27:17.384Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T22:27:17.384Z">2020-05-15 22:27:17</a></span> <span class="font-weight-bold">Mariano Guerra: </span> <p><p>this is our current product: <a href="https://www.youtube.com/watch?v=LK9Lfo4dFLU">https://www.youtube.com/watch?v=LK9Lfo4dFLU</a></p>
</p></div></div><div id="2020-05-15T15:59:32.347Z" class="alert alert-dark msg-root my-1 p-2 bg-light"><span class="small text-muted"><a href="#2020-05-15T15:59:32.347Z">2020-05-15 15:59:32</a></span> <span class="font-weight-bold">Ryan King: </span> <p><p>Hey gang, not much of an update this week. Just documenting my struggles between wanting observable state and needing a centralised system to manage events. I tried to build my own system in a few days but soon realised there's a lot more I need to think about - and maybe there's some existing approaches you all know about that I could look into?</p>
<p>In general, am trying to update state solely via a centralised event manager, but also use observables to automatically trigger those events (if that make sense)</p>
<p>A messy sandbox you can play with can be found here:
<a href="https://codesandbox.io/s/eve-test-04e75?file=/src/App.js">https://codesandbox.io/s/eve-test-04e75?file=/src/App.js</a></p>
<p><a href="https://youtu.be/Hw4BgyWRAAA">https://youtu.be/Hw4BgyWRAAA</a></p>
</p> <div id="2020-05-15T16:13:17.347Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T16:13:17.347Z">2020-05-15 16:13:17</a></span> <span class="font-weight-bold">Mariano Guerra: </span> <p><p>have you considered the elm architecture or similar? <a href="https://guide.elm-lang.org/architecture/">https://guide.elm-lang.org/architecture/</a></p>
</p></div><div id="2020-05-15T16:16:11.349Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T16:16:11.349Z">2020-05-15 16:16:11</a></span> <span class="font-weight-bold">Mariano Guerra: </span> <p><p>your demo has a really fine grained event generation, maybe a coarse grained one would do? like transactions?</p>
</p></div><div id="2020-05-15T16:29:36.361Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T16:29:36.361Z">2020-05-15 16:29:36</a></span> <span class="font-weight-bold">Ryan King: </span> <p><p>Yeah it looks like I'm going for a elm-ish messaging architecture. I think I'm creating issues by have object both emit and listen to events. Maybe all updates should be dispatched via message...</p>
<p>I was also wondering on how much detail to go into the events. I suppose it's a matter of exposing what data is most likely to be listened to, otherwise you'd just need to filer it out later right?</p>
<p>Will definitely look into transactions! I've never even heard of them!</p>
</p></div><div id="2020-05-15T16:38:36.362Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T16:38:36.362Z">2020-05-15 16:38:36</a></span> <span class="font-weight-bold">Mariano Guerra: </span> <p><p>what I mean by them is that you bundle a group of mutations into a named thing and emit an event with the name of the thing and some extra parameters, much more semantic that emiting events every time you mutate a field</p>
</p></div><div id="2020-05-15T16:42:07.363Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T16:42:07.363Z">2020-05-15 16:42:07</a></span> <span class="font-weight-bold">Garth Goldwater: </span> <p><p>you might be interested in <a href="https://github.com/thefrontside/microstates">https://github.com/thefrontside/microstates</a> microstates</p>
</p></div><div id="2020-05-15T17:32:54.373Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T17:32:54.373Z">2020-05-15 17:32:54</a></span> <span class="font-weight-bold">Ryan King: </span> <p><p><strong>Mariano Guerra</strong> oh yes I think something like that will be needed but it might need to be in combination with the microevents so derived values can know when to update.</p>
<p><strong>Garth Goldwater</strong> üôå looks super interesting, thanks! I look forward to see what it can do!</p>
</p></div><div id="2020-05-15T17:35:13.373Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T17:35:13.373Z">2020-05-15 17:35:13</a></span> <span class="font-weight-bold">Garth Goldwater: </span> <p><p>the youtube talks listed on the readme are super clear (to me at least)‚Äîmight be worth checking out</p>
</p></div><div id="2020-05-15T17:35:36.373Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T17:35:36.373Z">2020-05-15 17:35:36</a></span> <span class="font-weight-bold">Garth Goldwater: </span> <p><p>fairly react-specific most of the time but i linked to the framework without the react integrations</p>
</p></div><div id="2020-05-15T20:17:35.383Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T20:17:35.383Z">2020-05-15 20:17:35</a></span> <span class="font-weight-bold">U0123H7JRDM: </span> <p><p>What's different in your scenario then the problems redux solve? Mobx is also a widely used alternative</p>
</p></div><div id="2020-05-15T20:59:52.383Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T20:59:52.383Z">2020-05-15 20:59:52</a></span> <span class="font-weight-bold">Ryan King: </span> <p><p>Yeah I basically want a cross between the two. I currently use something like mobx <a href="https://github.com/alloc/wana">https://github.com/alloc/wana</a> and I really like that api but something redux-like would be easier to manage as the app is getting larger. However, I do not enjoy using redux at all, there's lot of boilerplate, and I find it a bit cumbersome. So this is an attempt at a happy medium between the two.</p>
</p></div><div id="2020-05-15T21:07:05.383Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-15T21:07:05.383Z">2020-05-15 21:07:05</a></span> <span class="font-weight-bold">Ryan King: </span> <p><p>It's all trying to solve the same problem - I'm just playing with ideas to find what requires the least cognitive effort for me as programmer.</p>
</p></div><div id="2020-05-17T07:55:21.389Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-17T07:55:21.389Z">2020-05-17 07:55:21</a></span> <span class="font-weight-bold">Edward de Jong: </span> <p><p><strong>Ryan King</strong> you might consider looking at my Beads language. It has three aspects that relate to your work. It is a clean sheet approach and emits to raw JS with no external dependencies such as Rect, etc.. You declare a model as a graph database schema that will be filled in with data later with data. Then you write chunks of code that draw your screen using the model data in a pure manner (the view). The controller chunks are blocks of code appended to the view drawing subroutines.  There is also the notion of a derived quantity which is lazily evaluated when it is referenced. The key advantage over your method is that if a view drawing function uses model variables, a, b and c, if any of those 3 variables change their value, then the draw chunk is re-executed. This is all tracked automatically without any the programmer having to declare dependencies, similar to how spreadsheets work, except that this is about re-executing drawing functions with memorized parameters, which is quite different than simple formulas being executed in topological order. It has a central event system called the Loom, which combines publish/subscribe, network, keyboard, mouse, timer events into one unified event stream, that is fed to the constellation of code chunks, based on their appropriateness for that event.</p>
</p></div><div id="2020-05-17T15:19:47.397Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-17T15:19:47.397Z">2020-05-17 15:19:47</a></span> <span class="font-weight-bold">Ryan King: </span> <p><p><strong>Edward de Jong</strong> it does sound very nice. Honestly, it might be a risky business decision to adopt at this point. But I'd be happy to try to build something and provide feedback. Do you have links?</p>
</p></div><div id="2020-05-17T15:22:19.398Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-17T15:22:19.398Z">2020-05-17 15:22:19</a></span> <span class="font-weight-bold">Ryan King: </span> <p><p>Or maybe you next video could be on how to set up beads?</p>
</p></div></div><div id="2020-05-16T20:27:22.386Z" class="alert alert-dark msg-root my-1 p-2 bg-light"><span class="small text-muted"><a href="#2020-05-16T20:27:22.386Z">2020-05-16 20:27:22</a></span> <span class="font-weight-bold">Chris Maughan: </span> <p><p>Here is my weekly update.   Apart from some work on the internals to better represent time events, I spent some time on writing a little visualiser to help me understand scheduling.  I hope it will also end up being a nice additional tool for the end user to see what's going on too.  I really need some full days to work on some of the more interesting problems, and an hour or so a day (my usual schedule) is not cutting it at the moment :(</p>
</p> <div id="2020-05-17T06:49:12.388Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-17T06:49:12.388Z">2020-05-17 06:49:12</a></span> <span class="font-weight-bold">U0123H7JRDM: </span> <p><p>What is your end goal? Do you want to be able to develop vst's with your engine which can be used in daw's like ableton or something more standalone? </p>
</p></div><div id="2020-05-17T12:29:11.393Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-17T12:29:11.393Z">2020-05-17 12:29:11</a></span> <span class="font-weight-bold">U0123H7JRDM: </span> <p><p>How do you handle the communication between the user interface and the graph engine? I assume that the graph engine runs in a separate thread, do you send messages from there to the UI main thread?</p>
</p></div><div id="2020-05-17T13:14:32.397Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-17T13:14:32.397Z">2020-05-17 13:14:32</a></span> <span class="font-weight-bold">U0123H7JRDM: </span> <p><p>Another question: how do you handle an LFO to modulate a filter frequency in your graph engine? Do they have there own timers and update a "generation number" themselves?</p>
</p></div><div id="2020-05-17T16:24:01.398Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-17T16:24:01.398Z">2020-05-17 16:24:01</a></span> <span class="font-weight-bold">Chris Maughan: </span> <p><p>To answer the first question, you should probably check out my first 2 minute week video: <a href="https://futureofcoding.slack.com/files/UUQ2EQW21/F011WFWEGMC/week2minute_1.mp4">https://futureofcoding.slack.com/files/UUQ2EQW21/F011WFWEGMC/week2minute_1.mp4</a>
The short story is that I've been working on a 'Live Coding' environment for some time; it is audio + visual.  Designed as a toolkit for performance, teaching, research.  So the audio is a smaller part of the whole.</p>
</p></div><div id="2020-05-17T16:28:27.399Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-17T16:28:27.399Z">2020-05-17 16:28:27</a></span> <span class="font-weight-bold">Chris Maughan: </span> <p><p>When used in the audio code, the graph is running in the audio thread (same one the sound card requests a new buffer).  The generated notes from Orca/Music Language, etc. do run in a separate thread to this, but the notes are turned into PCM audio by the graph on the soundcard thread.
The UI is indeed on a separate thread.  I like lock-free programming, so as much as possible the UI is detached from the audio.  Some special nodes have 'real time' sections designed to happen in the audio thread, and 'UI' sections for display purposes.  It's up to the nodes that do this to manage shared state correctly.  This localises the problem somewhat.  An example of that might be the ADSR curve which has blue dots running along it containing note events.</p>
</p></div><div id="2020-05-17T16:29:22.399Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-17T16:29:22.399Z">2020-05-17 16:29:22</a></span> <span class="font-weight-bold">Chris Maughan: </span> <p><p>None of this is perfect yet, it is still a work in progress, and I tend to jump around filling in gaps as I see fit!</p>
</p></div><div id="2020-05-17T16:33:52.399Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-05-17T16:33:52.399Z">2020-05-17 16:33:52</a></span> <span class="font-weight-bold">Chris Maughan: </span> <p><p>For the question on LFO, it is probably best to think of what a graph step is in my engine.  When the sound card requests a buffer of, say, 500 stereo samples, the graph is run.  Any notes that are due for scheduling are updated in the 'instrument' node, and then the output node 'pulls' 500 samples.  This means each node then processes 500 audio samples in its 'compute' step.  This is an atomic operation.  For example, the oscillator's compute sample might build 500 sin samples into the buffer from the wavetable.  Each node has to handle multiple channels, and doesn't know up front what it will receive.  This is the data flow part.  The LFO is no different.  Suppose it is feeding an oscillator to modulate the frequency.  The LFO data flow pin is connected to the oscillator modulation data flow pin.  At run time, the LFO will generate its 500 samples when the oscillator evaluates the modulation input, then the oscillator will generate its 500 samples and combine them with the incoming data.  If you look at the Frequency analyser in my last video, you will see the separate channels of audio.  This node simply looks at what is connected to it, and displays all the channels it finds.</p>
</p></div></div>
  </body>
</html>
