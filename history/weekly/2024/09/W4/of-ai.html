
<!doctype html>
<html>
  <head>
    <meta charset=utf-8>
    <title>Future of Coding History</title>
    <link rel="stylesheet" href="https://marianoguerra.github.io/future-of-coding-weekly/history/style.css">
  </head>
  <body>
    <div id="ui">
      <a id="logo" href="https://futureofcoding.org">
        <img src="https://marianoguerra.github.io/future-of-coding-weekly/history/logo.svg" alt="Future of Coding History">
      </a>
      <div id="small-logo">
        <a href="https://futureofcoding.org">Future of Coding</a> History
      </div>
      <div id="center">
        <h4>
          You are viewing archived messages.<br>
          Go <a href="https://marianoguerra.github.io/future-of-coding-weekly/history">here</a> to search the history.
        </h4>
      </div>
      <div id="actions"></div>
    </div>
    <div id="msgs-output">
<div id="2024-09-16T17:32:59.411Z" class="post"><span class="user">Nilesh Trivedi</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-13&amp;toDate=2024-09-19&amp;channel=of-ai&amp;filter=#2024-09-16T17:32:59.411Z" class="date">2024-09-16 17:32:59</a> <div class="message"><p><a href="https://stephenfry.substack.com/p/ai-a-means-to-an-end-or-a-means-to">Stephen Fry on technology and AI</a>:</p>
<blockquote><p>Machines are capable of bias, hallucination, drift and overfitting on their own, but a greater and more urgent problem in my view is their use, abuse and misuse by the three Cs . They are 
 <em>Countries</em> 
 with their specific ambitions, paranoias, enmities and pride; 
 <em>Corporations</em> 
 with their unaccountable rapacity and of course 
 <em>Criminals</em> 
. All of them united by one deadly sin: greed. Greed for power, for status, for money, for control.</p>
</blockquote>
</div> <div class="attachments"></div> <div class="files"></div> <div class="replies"></div></div><div id="2024-09-17T00:09:22.355Z" class="post"><span class="user">Mattia Fregola</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-14&amp;toDate=2024-09-20&amp;channel=of-ai&amp;filter=#2024-09-17T00:09:22.355Z" class="date">2024-09-17 00:09:22</a> <div class="message"><p><a href="https://www.youtube.com/watch?v=M9YOO7N5jF8&amp;ab_channel=KyleKabasares">ChatGPT o1 preview + mini Wrote My PhD Code in 1 Hour*‚ÄîWhat Took Me ~1 Year</a></p>
</div> <div class="attachments"><blockquote><p>üé• <a href="https://www.youtube.com/watch?v=M9YOO7N5jF8&amp;amp;ab_channel=KyleKabasares">ChatGPT o1 preview + mini Wrote My PhD Code in 1 Hour*‚ÄîWhat Took Me ~1 Year</a></p>
<p><img src="https://i.ytimg.com/vi/M9YOO7N5jF8/hqdefault.jpg" alt="ChatGPT o1 preview + mini Wrote My PhD Code in 1 Hour*‚ÄîWhat Took Me ~1 Year"></p>
</blockquote>
</div> <div class="files"></div> <div class="replies"></div></div><div id="2024-09-17T07:34:31.043Z" class="post"><span class="user">Tom Larkworthy</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-14&amp;toDate=2024-09-20&amp;channel=of-ai&amp;filter=#2024-09-17T07:34:31.043Z" class="date">2024-09-17 07:34:31</a> <div class="message"><p>I got test-driven-development working with AI ( <code>o1-preview</code> ) and it is totally nuts. It can do complex stuff, I am making serious progress with a decompiler with it</p>
<p><a href="https://observablehq.com/@tomlarkworthy/ai-written-decompiler">observablehq.com/@tomlarkworthy/ai-written-decompiler</a>. The key was feeding the test suite results back into context (plus o1-preview's ability to improve code without forgetting half the stuff in the middle)</p>
</div> <div class="attachments"></div> <div class="files"></div> <div class="replies"><div id="2024-09-17T07:35:35.153Z" class="reply"><span class="user">Tom Larkworthy</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-14&amp;toDate=2024-09-20&amp;channel=of-ai&amp;filter=#2024-09-17T07:35:35.153Z" class="date">2024-09-17 07:35:35</a> <div class="message"><p>I am mostly prompting "get the tests to pass" and letting it either fix the tests or the code.</p>
</div> <div class="attachments"></div> <div class="files"></div></div></div></div><div id="2024-09-17T12:34:17.084Z" class="post"><span class="user">Konrad Hinsen</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-14&amp;toDate=2024-09-20&amp;channel=of-ai&amp;filter=#2024-09-17T12:34:17.084Z" class="date">2024-09-17 12:34:17</a> <div class="message"><p>I just read this <a href="https://www.wheresyoured.at/subprimeai/">very AI-skeptical article</a>, that basically says that today's generative AI has no credible business model and is unlikely to improve significantly enough to get one. While I am aware of counter-arguments to the technical aspects, I wonder if there are more positive takes on the financial/business aspects, coming from anyone else than AI vendors.</p>
</div> <div class="attachments"></div> <div class="files"></div> <div class="replies"><div id="2024-09-17T14:11:52.868Z" class="reply"><span class="user">Daniel Sosebee</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-14&amp;toDate=2024-09-20&amp;channel=of-ai&amp;filter=#2024-09-17T14:11:52.868Z" class="date">2024-09-17 14:11:52</a> <div class="message"><p>Carl Shulman‚Äôs perspective is interesting - I think he‚Äôs someone who really takes the ‚Äúlook at the trends and then keep extrapolating‚Äù thing seriously, which leads him to very extreme conclusions about the expected impact of AI. Could be a bit of a different discussion though, as he‚Äôs not talking about today‚Äôs models. Anyways here‚Äôs a very long interview with him. <a href="https://80000hours.org/podcast/episodes/carl-shulman-economy-agi/">80000hours.org/podcast/episodes/carl-shulman-economy-agi</a></p>
</div> <div class="attachments"><blockquote><p>üìù <a href="https://80000hours.org/podcast/episodes/carl-shulman-economy-agi/">Carl Shulman on the economy and national security after AGI (Part 1)</a></p>
</blockquote>
</div> <div class="files"></div></div><div id="2024-09-18T05:09:46.821Z" class="reply"><span class="user">Konrad Hinsen</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-15&amp;toDate=2024-09-21&amp;channel=of-ai&amp;filter=#2024-09-18T05:09:46.821Z" class="date">2024-09-18 05:09:46</a> <div class="message"><p>That's extrapolation with a big dose of speculation. We have no idea for now if AGI will ever happen. So it's not a basis for today's business plans. Even if AGI happens, and even if it happens soon, it's probably neither OpenAI nor Anthropic that will benefit economically from such a development.</p>
</div> <div class="attachments"></div> <div class="files"></div></div></div></div><div id="2024-09-21T02:48:27.818Z" class="post"><span class="user">Kartik Agaram</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-18&amp;toDate=2024-09-24&amp;channel=of-ai&amp;filter=#2024-09-21T02:48:27.818Z" class="date">2024-09-21 02:48:27</a> <div class="message"><p><a href="https://dynamicland.org/archive/2017/Is_this_the_civilization_we_really_want%3F">Bret Victor on AI</a> üí•</p>
</div> <div class="attachments"></div> <div class="files"></div> <div class="replies"><div id="2024-09-21T05:18:54.613Z" class="reply"><span class="user">Nilesh Trivedi</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-18&amp;toDate=2024-09-24&amp;channel=of-ai&amp;filter=#2024-09-21T05:18:54.613Z" class="date">2024-09-21 05:18:54</a> <div class="message"><p>Alan Kay <a href="https://dynamicland.org/archived-websites/worrydream.com/refs/Kay_1994_-_A_bicycle_for_the_mind_redux.html">pulls no punches</a>:</p>
<blockquote><p>When you put a person into a car, their muscles wither. You put a person into an information car, and their thinking ability withers. I wouldn't put a person within 15 yards of a computer unless I was absolutely sure that it was a kind of a bike for them.</p>
</blockquote>
<p>...</p>
<p>A lot of technology is just what I call inverse vandalism, which is people making machinery just because they can.</p>
</div> <div class="attachments"></div> <div class="files"></div></div><div id="2024-09-21T05:49:47.845Z" class="reply"><span class="user">Ivan Reese</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-18&amp;toDate=2024-09-24&amp;channel=of-ai&amp;filter=#2024-09-21T05:49:47.845Z" class="date">2024-09-21 05:49:47</a> <div class="message"><p>2016!</p>
</div> <div class="attachments"></div> <div class="files"><p><img src="http://history.futureofcoding.org/history/msg_files/F07/F07NC1RUX9B.png" alt="Screenshot 2024-09-20 at 11.49.30‚ÄØPM.png"></p>
</div></div><div id="2024-09-21T08:05:25.539Z" class="reply"><span class="user">Arvind Thyagarajan</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-18&amp;toDate=2024-09-24&amp;channel=of-ai&amp;filter=#2024-09-21T08:05:25.539Z" class="date">2024-09-21 08:05:25</a> <div class="message"><p>Wonderful read of a wonderful response. Makes me reflect on the mechanics and context of the (possibly exciting, possibly mundane) work that I do. Always love the bicycle analogy as it deftly sidesteps thickly disguised "are you a Luddite?" insinuations :-)</p>
</div> <div class="attachments"></div> <div class="files"></div></div><div id="2024-09-21T17:35:26.980Z" class="reply"><span class="user">Kartik Agaram</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-18&amp;toDate=2024-09-24&amp;channel=of-ai&amp;filter=#2024-09-21T17:35:26.980Z" class="date">2024-09-21 17:35:26</a> <div class="message"><p><a href="https://thewalrus.ca/collapse-of-self-worth-in-the-digital-age">This great article seems related.</a></p>
<p>Perhaps the end-game here is the things we share through relationships cannot involve money. I realize I've been aimed in roughly the direction of this thought for 10 years or so. Separation of Mammon and Muse. A parallel, complementary trade network.</p>
<p>It does require flattening the privilege curve a lot more, though.</p>
</div> <div class="attachments"><blockquote><p>üìù <a href="https://thewalrus.ca/collapse-of-self-worth-in-the-digital-age">The Collapse of Self-Worth in the Digital Age | The Walrus</a></p>
<p>Why are we letting algorithms rewrite the rules of art, work, and life?</p>
</blockquote>
</div> <div class="files"></div></div><div id="2024-09-22T01:24:01.664Z" class="reply"><span class="user">Jason Morris</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-19&amp;toDate=2024-09-25&amp;channel=of-ai&amp;filter=#2024-09-22T01:24:01.664Z" class="date">2024-09-22 01:24:01</a> <div class="message"><p>I want to understand the car/bike analogy better. Is the distinction between things that amplify the outcome of human effort as opposed to things that eliminate the need for it? Because unless you are drawing a line at an amplification level of "infinity", that seems like a distinction of degree, not type. What degree counts? Or does it have to do with some sort of judgement that a person who is a good driver is a worse person than a person who is physically fit by virtue of riding a bike? So our categories of bike/car are tied to what we think it means to be a good person or live a good life? We have to be political about our computing tools, and generate tools the use of which results in "better" people? And ignore people when they say "please make this easier for me" if doing so would atrophy something that we think is more important than they do? I'm very  sympathetic to this idea, because I am worried about the effect on legal reasoning capabilities in people from some kinds of generative AI, and also excited about the way some forms of symbolic AI force you to think more clearly. But I don't know how to draw this distinction in a way that isn't arbitrary.</p>
</div> <div class="attachments"></div> <div class="files"></div></div><div id="2024-09-22T08:21:36.906Z" class="reply"><span class="user">Stefan Lesser</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-19&amp;toDate=2024-09-25&amp;channel=of-ai&amp;filter=#2024-09-22T08:21:36.906Z" class="date">2024-09-22 08:21:36</a> <div class="message"><p>This seems another good resource to add to the mix: <a href="https://blog.ncase.me/the-creative-cyborg/">blog.ncase.me/the-creative-cyborg</a></p>
</div> <div class="attachments"><blockquote><p>üìù <a href="https://blog.ncase.me/the-creative-cyborg/">The Creative Cyborg (my XOXO 2024 mini-talk)</a></p>
<p>On how we may re-design AI to enhance artists, not replace them</p>
</blockquote>
</div> <div class="files"></div></div><div id="2024-09-22T08:38:43.132Z" class="reply"><span class="user">Dave Liepmann</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-19&amp;toDate=2024-09-25&amp;channel=of-ai&amp;filter=#2024-09-22T08:38:43.132Z" class="date">2024-09-22 08:38:43</a> <div class="message">
<blockquote><p>Because unless you are drawing a line at an amplification level of "infinity", that seems like a distinction of degree, not type.</p>
</blockquote>
<p>I don't agree. Transportation experts categorize even the most sedate bike riding (a Dutch bike on a flat path) as active mobility and driving a car or taking the bus as passive because riding a bike involves a kind <em>and</em> quantity of physical movement that is simply not present in driving a car ‚Äì exercising balance by leaning into turns, getting a baseline amount of leg-pumping, occasionally needing to exert hard force to, say, catch a light. This sounds pretty mild but produces a multitude of cascading health effects. I'll even take the bait and say you should steel-man your fitness-as-virtue argument: we're analogizing physical health to mental capability, not as an arbitrary dimension of person-worth, so it makes complete sense in this context to prefer the healthy option.</p>
<p>Kay also specifically calls out the quality of being able "to go flat out with [the rider's] body". This scaling-up-with-your-effort ability of the tool is especially enlightening for the analogy: programming languages have it, spreadsheets have it, scientific calculators kind of barely have it, whereas dumb calculators, CSV, and most low-code tools do not have it. The former accept almost arbitrarily complex mental input and do work on it that feeds a feedback loop, the latter force you into a narrow band of input and often only amplify it in specific predetermined directions.</p>
<blockquote><p>We have to be political about our computing tools, and generate tools the use of which results in "better" people?</p>
</blockquote>
<p>We should steel-man this line of thought as well. I think you're reading it precisely backwards, as authoritarian control of mental tools. To that we would say no. It's about enabling people to be better by giving them more power over the tools we build, to which we should say YES! Yes, when we build tools we should allow people to do more things than we specifically intend with it. It's good practice in software and perhaps even a moral quality demanding it for end users. Think of how valuable it is to have escape hatches like passing a function argument to define behavior in someone else's code, or to have macros available to create DSLs, or to occasionally be more verbose so to eke performance out of a hot loop, or to have a <a href="https://maggieappleton.com/programming-portals">programming portal</a> in a GUI to provide a more nuanced side channel.</p>
</div> <div class="attachments"><blockquote><p>üìù <a href="https://maggieappleton.com/programming-portals">Programming Portals</a></p>
<p>Small, scoped areas within a graphical interface that allow users to read and write simple programmes</p>
</blockquote>
</div> <div class="files"></div></div><div id="2024-09-22T10:08:21.509Z" class="reply"><span class="user">Joshua Horowitz</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-19&amp;toDate=2024-09-25&amp;channel=of-ai&amp;filter=#2024-09-22T10:08:21.509Z" class="date">2024-09-22 10:08:21</a> <div class="message"><p><strong>@Dave Liepmann</strong>:</p>
<blockquote><p>I think you‚Äôre reading it precisely backwards, as authoritarian control of mental tools. To that we would say no. It‚Äôs about enabling people to be better by giving them more power over the tools we build, to which we should say YES!</p>
</blockquote>
<p>In general I think the argument you‚Äôre making is great and I agree with it.</p>
<p>But: Just for the record, not everyone says ‚Äúno / yes‚Äù in this particular order. Sticking with our beloved bicycle example, Ivan Illich argued in <a href="https://blogs.ubc.ca/landscapesofenergy/files/2010/11/ivan-illich-energy_and_equity.pdf">‚ÄúEnergy and Equity‚Äù</a> that vehicles shouldn‚Äôt be allowed to travel faster than bicycles: ‚ÄúParticipatory democracy demands low-energy technology, and free people must travel the road to productive social relations at the speed of a bicycle‚Ä¶ Beyond a certain speed, motorized vehicles create remoteness which they alone can shrink.‚Äù</p>
<p>I don‚Äôt know how convinced I am by that specific argument in that situation. But I do think it‚Äôs important not to assume that a free-market ‚Äúbuild the right empowering thing and it will push out the bad things!‚Äù solution is the only option we have available. It‚Äôs nice when that works, but sometimes you have to actually do politics, and negotiate agreements as a society about how things should work. I don‚Äôt think that‚Äôs the same thing as ‚Äúauthoritarianism‚Äù. (Naturally, minarchists do think these are the same thing, but I imagine many of us have less radical views than that.)</p>
</div> <div class="attachments"></div> <div class="files"></div></div><div id="2024-09-22T16:37:47.790Z" class="reply"><span class="user">Dave Liepmann</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-19&amp;toDate=2024-09-25&amp;channel=of-ai&amp;filter=#2024-09-22T16:37:47.790Z" class="date">2024-09-22 16:37:47</a> <div class="message"><p>True ‚Äì I pose the "give people powerful tools" argument only in the context of tools for thought</p>
</div> <div class="attachments"></div> <div class="files"></div></div><div id="2024-09-22T16:42:30.127Z" class="reply"><span class="user">Jason Morris</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-19&amp;toDate=2024-09-25&amp;channel=of-ai&amp;filter=#2024-09-22T16:42:30.127Z" class="date">2024-09-22 16:42:30</a> <div class="message"><p>Walking is active transportation, and you have to walk to a bus stop. Busses amplify the effect of that walking. So I still don't see that distinction. I do see the all-out distinction, and I intuitively care about it. And for people who are explicitly seeking to build things that help people grow in certain ways, it's great that such things exist. But I don't see where we can get any sort of universal moral preference between those tools and tools that make a certain kind of effort unnecessary. I have a neuro-diversity that makes certain kinds of mental activity inherently difficult for me. Is it wrong to build me a tool that allows me to not have to do that sort of thing? Does a "to do" feature atrophy human memory?  The idea that this all-out idea can be a universal preference seems absurd. You "should" also design for accessibility, and designing for growth can be mutually exclusive.</p>
</div> <div class="attachments"></div> <div class="files"></div></div><div id="2024-09-22T18:16:08.079Z" class="reply"><span class="user">Kartik Agaram</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-19&amp;toDate=2024-09-25&amp;channel=of-ai&amp;filter=#2024-09-22T18:16:08.079Z" class="date">2024-09-22 18:16:08</a> <div class="message"><p>My version of (I think) Jason's point: were calculators a mistake?</p>
</div> <div class="attachments"></div> <div class="files"></div></div><div id="2024-09-22T18:21:31.255Z" class="reply"><span class="user">Dave Liepmann</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-19&amp;toDate=2024-09-25&amp;channel=of-ai&amp;filter=#2024-09-22T18:21:31.255Z" class="date">2024-09-22 18:21:31</a> <div class="message"><p>I'm not sure we're talking about a universal preference. I'm think I'm talking about a preference for a quality to be present in certain kinds of tools, and the preference grows the nearer the tool is to a certain category which includes tools for thought and sources of truth.</p>
<p>Maybe we're having trouble because this quality is vague: "[being] a material to be shaped", extensibility - interactivity - malleability...that it can be more than just itself. That it has no arbitrary restrictions on its participation in the network of all other tools.</p>
<p>Does the "to do" feature support being shaped to the user's needs?</p>
<p>(Is it true to say that dumb calculators only do rote tasks that we don't feel needs to be shaped beyond the supported functions? Or I suppose someone who wants programmable functions has the option to get a scientific calculator, so the question feels moot.)</p>
</div> <div class="attachments"></div> <div class="files"></div></div><div id="2024-09-22T18:47:45.207Z" class="reply"><span class="user">Kartik Agaram</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-19&amp;toDate=2024-09-25&amp;channel=of-ai&amp;filter=#2024-09-22T18:47:45.207Z" class="date">2024-09-22 18:47:45</a> <div class="message"><p><strong>@Dave Liepmann</strong> yeah. I'll state the extreme version of this question just because somebody should:</p>
<p> <em>If we start using the computer to simulate the computer, does some human capability wither?</em> </p>
<p>(<a href="https://history.futureofcoding.org/?fromDate=2024-09-19&amp;toDate=2024-09-25&amp;channel=devlog-together&amp;filter=#2024-09-22T18:32:22.017Z">üí¨ #devlog-together@2024-09-22</a>)</p>
<p>I'd say no because I do it pretty poorly anyway. But I can't really reason about it without referring to what I'd rather be doing. And there's a fundamental incommensurability between humans there. We want to spend our time doing different things.</p>
<p>Human beings have always used technology to compete for agency. Gain agency for the things you want to do, even if it takes away agency from others, or causes others at large to stop doing some things that they might otherwise have found pleasurable and worthwhile.</p>
<p>I think I agree with Jason's original point that it's a matter of degree, not type.</p>
</div> <div class="attachments"></div> <div class="files"></div></div><div id="2024-09-22T18:55:47.262Z" class="reply"><span class="user">Jason Morris</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-19&amp;toDate=2024-09-25&amp;channel=of-ai&amp;filter=#2024-09-22T18:55:47.262Z" class="date">2024-09-22 18:55:47</a> <div class="message"><p>I don't think the malleability property is fundamental to the car/bike idea. A bike cannot be molded into something else. Moldable things are one way to achieve bike-ness, but not the only way. That said, I'm persuaded that bike-ness is less frequently sought out in user-facing tools than perhaps would be ideal. "There should be more bike-ness" is a lot easier claim to swallow than "cars are bad, only make bikes."</p>
</div> <div class="attachments"></div> <div class="files"></div></div><div id="2024-09-22T19:13:09.571Z" class="reply"><span class="user">Kartik Agaram</span> <a href="https://history.futureofcoding.org/?fromDate=2024-09-19&amp;toDate=2024-09-25&amp;channel=of-ai&amp;filter=#2024-09-22T19:13:09.571Z" class="date">2024-09-22 19:13:09</a> <div class="message"><p>For me this conversation also connects up with my comment above about the parallel trade networks of Mammon vs Muse.</p>
<p>When you make a film you derive some pleasure from the act. That pleasure is separate from the pleasure I derive from watching it, or from the money I pay to watch it.</p>
<p>For the watcher, there is also something allegedly nice about access to an infinite stream of videos that provide some ineffable quality one can't articulate. (i.e. Tiktok)</p>
<p>It's plausible that the producer's desire is not more elevated than the consumer's.</p>
<p>AI is potentially a force to decouple these 2 trade networks. Do what you do for pleasure of the act, or for the extrinsic payoff. We may be forced to choose between the two at all levels of granularity.</p>
<p>Of course, the addition of this force to the world requires us to come up with countervailing forces:</p>
<ul><li>To spread the word about the joys of creating beyond the resulting artifact.</li><li>To spread the leisure around so everyone is able to participate in the Muse network.</li></ul></div> <div class="attachments"></div> <div class="files"></div></div></div></div>
    </div>
  </body>
</html>
