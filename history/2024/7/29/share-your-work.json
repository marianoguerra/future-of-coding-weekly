[
    {
        "user": "U0296ACR13M",
        "type": "message",
        "ts": "1722253333.203799",
        "client_msg_id": "e699c101-d26f-4b59-9e60-f490b83d13c7",
        "text": "Did an experiment on improving LLM accuracy with Structured Generation using my stuff: <https://www.linkedin.com/posts/jarnomontonen_improving-llm-accuracy-with-levlo-languages-activity-7223648019051626497-Ow0i|https://www.linkedin.com/posts/jarnomontonen_improving-llm-accuracy-with-levlo-languages-activity-7223648019051626497-Ow0i>",
        "team": "T5TCAFTA9",
        "thread_ts": "1722253333.203799",
        "reply_count": 5,
        "reply_users_count": 2,
        "latest_reply": "1722835419.712309",
        "reply_users": [
            "U06SS0DHZD1",
            "U0296ACR13M"
        ],
        "is_locked": false,
        "subscribed": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "A575L",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Did an experiment on improving LLM accuracy with Structured Generation using my stuff: "
                            },
                            {
                                "type": "link",
                                "url": "https://www.linkedin.com/posts/jarnomontonen_improving-llm-accuracy-with-levlo-languages-activity-7223648019051626497-Ow0i",
                                "text": "https://www.linkedin.com/posts/jarnomontonen_improving-llm-accuracy-with-levlo-languages-activity-7223648019051626497-Ow0i"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U06SS0DHZD1",
        "type": "message",
        "ts": "1722705531.879089",
        "client_msg_id": "30d7d460-5d8c-43d9-8a4e-7ad656b19be4",
        "text": "Cool stuff. Reminds me of <https://github.com/ggerganov/llama.cpp?tab=readme-ov-file#constrained-output-with-grammars> . I've used it to generate some scenarios for RPG games with friends. One issue that I've encountered (ignoring overabundance of tropes) was that the model was sometimes very uncooperative and refused to progress through the given template. Instead it got stuck in some place where it was free to generate arbitrary text and just happily stuttered around, never reaching the end. Have you encountered this? If so - what's your solution?",
        "team": "T5TCAFTA9",
        "thread_ts": "1722253333.203799",
        "parent_user_id": "U0296ACR13M",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "QW2UN",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Cool stuff. Reminds me of "
                            },
                            {
                                "type": "link",
                                "url": "https://github.com/ggerganov/llama.cpp?tab=readme-ov-file#constrained-output-with-grammars"
                            },
                            {
                                "type": "text",
                                "text": " . I've used it to generate some scenarios for RPG games with friends. One issue that I've encountered (ignoring overabundance of tropes) was that the model was sometimes very uncooperative and refused to progress through the given template. Instead it got stuck in some place where it was free to generate arbitrary text and just happily stuttered around, never reaching the end. Have you encountered this? If so - what's your solution?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U0296ACR13M",
        "type": "message",
        "ts": "1722798131.700389",
        "client_msg_id": "f425d96c-982a-4fcd-ba60-bdf95a6cbfab",
        "text": "Thanks and interesting use-case! Yes, there are several solutions for structured/constrained/guided generation, but all of the ones I've seen base the structure validation either on regex or context-free grammars. I can do context-sensitive grammars and semantic rules. Say you want to generate RPG character attribute values between 4-18, but the sum should be based on the level of the character. I don't think the solutions I've seen offer good support for something like that, but it would be fairly trivial with Levlo.\n\nI haven't really tried structures with free arbitrary text beyond just generated names, but I would imagine either prompting the LLM to only generate arbitrary text of certain length (as in \"a paragraph\", \"couple sentences\") or using appropriate length in samples would work. Have you tried? I suppose a potential challenge could be to make the LLM understand which part of the structure you mean with the length instructions in prompt, but I would be surprised if a dozen or so samples wouldn't work. Although, maybe the samples would end up directing the content of the arbitrary text too much as well..",
        "team": "T5TCAFTA9",
        "thread_ts": "1722253333.203799",
        "parent_user_id": "U0296ACR13M",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "NCNek",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Thanks and interesting use-case! Yes, there are several solutions for structured/constrained/guided generation, but all of the ones I've seen base the structure validation either on regex or context-free grammars. I can do context-sensitive grammars and semantic rules. Say you want to generate RPG character attribute values between 4-18, but the sum should be based on the level of the character. I don't think the solutions I've seen offer good support for something like that, but it would be fairly trivial with Levlo.\n\nI haven't really tried structures with free arbitrary text beyond just generated names, but I would imagine either prompting the LLM to only generate arbitrary text of certain length (as in \"a paragraph\", \"couple sentences\") or using appropriate length in samples would work. Have you tried? I suppose a potential challenge could be to make the LLM understand which part of the structure you mean with the length instructions in prompt, but I would be surprised if a dozen or so samples wouldn't work. Although, maybe the samples would end up directing the content of the arbitrary text too much as well.."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U0296ACR13M",
        "type": "message",
        "ts": "1722799107.757849",
        "edited": {
            "user": "U0296ACR13M",
            "ts": "1722800964.000000"
        },
        "client_msg_id": "e65d1705-6d28-4968-ad85-e55ea8c80e7e",
        "text": "Also, I'm very interested in hearing about use-cases people have had for structured generation and the challenges you've had with the current solutions. So thanks for sharing <@U06SS0DHZD1>!",
        "team": "T5TCAFTA9",
        "thread_ts": "1722253333.203799",
        "parent_user_id": "U0296ACR13M",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "tbgfI",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Also, I'm very interested in hearing about use-cases people have had for structured generation and the challenges you've had with the current solutions. So thanks for sharing "
                            },
                            {
                                "type": "user",
                                "user_id": "U06SS0DHZD1"
                            },
                            {
                                "type": "text",
                                "text": "!"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U06SS0DHZD1",
        "type": "message",
        "ts": "1722802784.612069",
        "client_msg_id": "50906974-4cf9-48d1-99cf-ba9b0e03872f",
        "text": "Actually some better prompting might have been the way to go... I was rewriting the whole scenario with LLM over many iterations (leaving the PC overnight) and sometimes it was randomly looping somewhere in the middle of text. I guess that shorter, maybe section-by-section prompts could prevent that... I've tried the grammar-based approach to limit the length but the issue there was that the model sometimes planned out the text for more sentences than the grammar permitted. This resulted in truncated descriptions.",
        "team": "T5TCAFTA9",
        "thread_ts": "1722253333.203799",
        "parent_user_id": "U0296ACR13M",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "EcHqa",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Actually some better prompting might have been the way to go... I was rewriting the whole scenario with LLM over many iterations (leaving the PC overnight) and sometimes it was randomly looping somewhere in the middle of text. I guess that shorter, maybe section-by-section prompts could prevent that... I've tried the grammar-based approach to limit the length but the issue there was that the model sometimes planned out the text for more sentences than the grammar permitted. This resulted in truncated descriptions."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U0296ACR13M",
        "type": "message",
        "ts": "1722835419.712309",
        "client_msg_id": "6c0e60cc-78e3-474f-a201-c5915d917b80",
        "text": "&gt; but the issue there was that the model sometimes planned out the text for more sentences than the grammar permitted\nYeah I can see this being a problem",
        "team": "T5TCAFTA9",
        "thread_ts": "1722253333.203799",
        "parent_user_id": "U0296ACR13M",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "9vwpx",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "but the issue there was that the model sometimes planned out the text for more sentences than the grammar permitted"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yeah I can see this being a problem"
                            }
                        ]
                    }
                ]
            }
        ]
    }
]