[
    {
        "user": "U5STGTB3J",
        "type": "message",
        "ts": "1711108783.712759",
        "client_msg_id": "55514581-9CE1-4AA4-8FB8-5C9392F8013D",
        "text": "Some speculation by <@U04BPBG8VN0> about <https://interconnected.org/home/2024/03/20/agents|the not so far out future of AI agents> and how we can/need to prepare for it. \nIn the other corner, some judgy comments about <https://www.garbageday.email/p/clout-world|AI\u2019s Looming Reputation Crisis> (scroll down to the middle to find that bit).\n\nI read both this morning and I know these are different use cases, however they beautifully cover the whole optimism/pessimism spectrum on AI.\n\nWhere do people here fall on that spectrum? Are there use cases that are obviously good/bad, or does that depend on\u2026 well\u2026 what? And are we going to outsource most of our lives soon to AI assistants while simultaneously drowning in mediocre generated bullsh*t trying to scam us?\n\nGosh, I miss the time of the early internet when I was excited about everything tech. Somehow I can\u2019t find back into that mindset these days. Can someone convince me that the future is going to be universally great, like it used to be 20 years ago?",
        "team": "T5TCAFTA9",
        "thread_ts": "1711108783.712759",
        "reply_count": 5,
        "reply_users_count": 2,
        "latest_reply": "1711150928.222419",
        "reply_users": [
            "UE6EFEPTQ",
            "U8A5MS6R1"
        ],
        "is_locked": false,
        "subscribed": false,
        "attachments": [
            {
                "from_url": "https://interconnected.org/home/2024/03/20/agents",
                "thumb_url": "https://interconnected.org/home/2024/03/20/agents.png?v=1",
                "thumb_width": 400,
                "thumb_height": 400,
                "id": 1,
                "original_url": "https://interconnected.org/home/2024/03/20/agents",
                "fallback": "Interconnected, a blog by Matt Webb: Who will build new search engines for new personal AI agents?",
                "text": "Posted on Wednesday 20 Mar 2024. 2,867 words, 12 links. By Matt Webb.",
                "title": "Who will build new search engines for new personal AI agents?",
                "title_link": "https://interconnected.org/home/2024/03/20/agents",
                "service_name": "Interconnected, a blog by Matt Webb"
            },
            {
                "image_url": "https://beehiiv-images-production.s3.amazonaws.com/uploads/asset/file/2836b5d2-79a1-4950-b37d-8dda0505e8f1/Screenshot_2024-03-20_at_1.29.52_PM.png?t=1710955810",
                "image_width": 1050,
                "image_height": 694,
                "image_bytes": 680512,
                "from_url": "https://www.garbageday.email/p/clout-world",
                "service_icon": "https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/cc1a45b3-0b3e-458a-b560-de940fc053f2/thumb_GD-ServerIcon.png",
                "id": 2,
                "original_url": "https://www.garbageday.email/p/clout-world",
                "fallback": "Garbage Day: Clout world",
                "text": "Read to the end for a good TikTok",
                "title": "Clout world",
                "title_link": "https://www.garbageday.email/p/clout-world",
                "service_name": "Garbage Day"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "XGmu1",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Some speculation by "
                            },
                            {
                                "type": "user",
                                "user_id": "U04BPBG8VN0"
                            },
                            {
                                "type": "text",
                                "text": " about "
                            },
                            {
                                "type": "link",
                                "url": "https://interconnected.org/home/2024/03/20/agents",
                                "text": "the not so far out future of AI agents"
                            },
                            {
                                "type": "text",
                                "text": " and how we can/need to prepare for it. \nIn the other corner, some judgy comments about "
                            },
                            {
                                "type": "link",
                                "url": "https://www.garbageday.email/p/clout-world",
                                "text": "AI\u2019s Looming Reputation Crisis"
                            },
                            {
                                "type": "text",
                                "text": " (scroll down to the middle to find that bit).\n\nI read both this morning and I know these are different use cases, however they beautifully cover the whole optimism/pessimism spectrum on AI.\n\nWhere do people here fall on that spectrum? Are there use cases that are obviously good/bad, or does that depend on\u2026 well\u2026 what? And are we going to outsource most of our lives soon to AI assistants while simultaneously drowning in mediocre generated bullsh*t trying to scam us?\n\nGosh, I miss the time of the early internet when I was excited about everything tech"
                            },
                            {
                                "type": "text",
                                "text": "."
                            },
                            {
                                "type": "text",
                                "text": " Somehow I "
                            },
                            {
                                "type": "text",
                                "text": "can\u2019t"
                            },
                            {
                                "type": "text",
                                "text": " find back into that mindset these days"
                            },
                            {
                                "type": "text",
                                "text": "."
                            },
                            {
                                "type": "text",
                                "text": " Can someone convince me that the future is going to be universally great, like it used to be 20 years ago?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UE6EFEPTQ",
        "type": "message",
        "ts": "1711114305.996379",
        "client_msg_id": "89a40753-6582-4d93-bc73-6b7a8277746d",
        "text": "I was blown away by the sudden appearance and then rapid development of AI, having followed the field at a medium distance all my life. But, like cryptocurrencies, I quickly filed it into \"interesting, follow quite closely, not my core thing\"",
        "team": "T5TCAFTA9",
        "thread_ts": "1711108783.712759",
        "parent_user_id": "U5STGTB3J",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "eLcb7",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I was blown away by the sudden appearance and then rapid development of AI, having followed the field at a medium distance all my life. But, like cryptocurrencies, I quickly filed it into \"interesting, follow quite closely, not my core thing\""
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UE6EFEPTQ",
        "type": "message",
        "ts": "1711114335.348539",
        "client_msg_id": "07fafb0f-b209-4a2a-b726-0c8c4f3f9d6e",
        "text": "I do get that excitement with \"my core thing\", though!",
        "team": "T5TCAFTA9",
        "thread_ts": "1711108783.712759",
        "parent_user_id": "U5STGTB3J",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "/UNT5",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I do get that excitement with \"my core thing\", though!"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U8A5MS6R1",
        "type": "message",
        "ts": "1711130279.535749",
        "client_msg_id": "c6168cbf-7054-4489-85f8-c4437eb8ed75",
        "text": "I've generally been skeptical of AI/ML but have come around a little bit. I've been very impressed with some specific applications, eg image and text generation, pattern recognition, etc.\n\nIn applications that need rigor, I'm very skeptical and actually think an ML based approach is completely backwards. Specifically for things like coding, engineering, maths and so on, a foundation of statistical correlation based on pre-existing text is... completely wrong (and why this is not blindingly obvious to everyone remains a mystery to me). You want to start with a semantic (not statistical) model. In any case I do find it easier to ask chatgpt about how to use an api for a specific purpose, and then validate that it actually works. People say LLMs sometimes hallucinate but in reality they _only_ hallucinate: is just so happens the hallucination sometimes matches reality.\n\nSide notes:\nI really don't like that the model makers dont reveal their training data. _Release your training data you cowards!_ \n\nAI/ML in decision making may help humans shrug away responsibility, which is also a major concern and I think we should stop talking about it as a magical entity that's different from a typical program. I think 'automation' is a great word, suggested by Emily Bender in this video: <https://www.youtube.com/watch?v=eK0md9tQ1KY>",
        "team": "T5TCAFTA9",
        "thread_ts": "1711108783.712759",
        "parent_user_id": "U5STGTB3J",
        "attachments": [
            {
                "from_url": "https://www.youtube.com/watch?v=eK0md9tQ1KY",
                "service_icon": "https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png",
                "thumb_url": "https://i.ytimg.com/vi/eK0md9tQ1KY/hqdefault.jpg",
                "thumb_width": 480,
                "thumb_height": 360,
                "video_html": "<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/eK0md9tQ1KY?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How should regulators think about &quot;AI&quot;?\"></iframe>",
                "video_html_width": 400,
                "video_html_height": 225,
                "id": 1,
                "original_url": "https://www.youtube.com/watch?v=eK0md9tQ1KY",
                "fallback": "YouTube Video: How should regulators think about \"AI\"?",
                "title": "How should regulators think about \"AI\"?",
                "title_link": "https://www.youtube.com/watch?v=eK0md9tQ1KY",
                "author_name": "Emily M. Bender",
                "author_link": "https://www.youtube.com/@emilym.bender9805",
                "service_name": "YouTube",
                "service_url": "https://www.youtube.com/"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "pyL8v",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I've generally been skeptical of AI/ML but have come around a little bit. I've been very impressed with some specific applications, eg image and text generation, pattern recognition, etc.\n\nIn applications that need rigor, I'm very skeptical and actually think an ML based approach is completely backwards. Specifically for things like coding, engineering, maths and so on, a foundation of statistical correlation based on pre-existing text is... completely wrong (and why this is not blindingly obvious to everyone remains a mystery to me). You want to start with a semantic (not statistical) model. In any case I do find it easier to ask chatgpt about how to use an api for a specific purpose, and then validate that it actually works. People say LLMs sometimes hallucinate but in reality they "
                            },
                            {
                                "type": "text",
                                "text": "only",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " hallucinate: is just so happens the hallucination sometimes matches reality.\n\nSide notes:\nI really don't like that the model makers dont reveal their training data. "
                            },
                            {
                                "type": "text",
                                "text": "Release your training data you cowards! ",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n\nAI/ML in decision making may help humans shrug away responsibility, which is also a major concern and I think we should stop talking about it as a magical entity that's different from a typical program. I think 'automation' is a great word, suggested by Emily Bender in this video: "
                            },
                            {
                                "type": "link",
                                "url": "https://www.youtube.com/watch?v=eK0md9tQ1KY"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "heavy_plus_sign",
                "users": [
                    "U0296ACR13M"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UE6EFEPTQ",
        "type": "message",
        "ts": "1711147147.783859",
        "client_msg_id": "4b298e50-59de-4209-8bfc-3814f61659ac",
        "text": "&gt; People say LLMs sometimes hallucinate but in reality they _only_ hallucinate: is just so happens the hallucination sometimes matches reality.\nWell the same can be said of the human mind: the abstraction of our senses to our conscious experience is a hallucination that is tightly constrained by incoming sense input. When we dream (or, well, when we hallucinate), those constraints are absent.",
        "team": "T5TCAFTA9",
        "thread_ts": "1711108783.712759",
        "parent_user_id": "U5STGTB3J",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "YWJYI",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "People say LLMs sometimes hallucinate but in reality they "
                            },
                            {
                                "type": "text",
                                "text": "only",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " hallucinate: is just so happens the hallucination sometimes matches reality."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Well the same can be said of the human mind: the abstraction of our senses to our conscious experience is a hallucination that is tightly constrained by incoming sense input. When we dream (or, well, when we hallucinate), those constraints are absent."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U8A5MS6R1",
        "type": "message",
        "ts": "1711150928.222419",
        "client_msg_id": "2f949f72-0d63-438c-9676-f38637d663ea",
        "text": "fair point. I guess hallucination is the wrong word to use here because it implies a kind of perception.",
        "team": "T5TCAFTA9",
        "thread_ts": "1711108783.712759",
        "parent_user_id": "U5STGTB3J",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "A7fII",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "fair point. I guess hallucination is the wrong word to use here because it implies a kind of perception."
                            }
                        ]
                    }
                ]
            }
        ]
    }
]