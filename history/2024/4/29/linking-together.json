[
    {
        "user": "U05SU27S1M2",
        "type": "message",
        "ts": "1714396420.894369",
        "edited": {
            "user": "U05SU27S1M2",
            "ts": "1714396488.000000"
        },
        "client_msg_id": "08f6ccac-01ef-44c4-88b2-d3c61deda754",
        "text": "FARM (aka ACM SIGPLAN International Workshop on Functional Art, Music, Modeling and Design) is taking place in Milan, Italy this year, September 2nd. The call for papers, demos and performances is open, deadline June 1st.\n<https://functional-art.org/2024/>",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "yHnE1",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "FARM (aka ACM SIGPLAN International Workshop on Functional Art, Music, Modeling and Design) is taking place in Milan, Italy this year, September 2nd. The call for papers, demos and performances is open, deadline June 1st.\n"
                            },
                            {
                                "type": "link",
                                "url": "https://functional-art.org/2024/"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "cake",
                "users": [
                    "U013ZLJARC7",
                    "U04FWD3SA90"
                ],
                "count": 2
            }
        ]
    },
    {
        "text": "Here is an interesting 2.5D experiment for those who like the canvas approach. I'm pretty sure it could have some practical applications. <https://twitter.com/OrionReedOne/status/1784871153787420920>",
        "files": [
            {
                "id": "F0715TMBNHG",
                "created": 1714410583,
                "timestamp": 1714410583,
                "name": "326391515-bbb2b225-3857-43ea-9337-5dfb9bfafd4d.mp4",
                "title": "326391515-bbb2b225-3857-43ea-9337-5dfb9bfafd4d.mp4",
                "mimetype": "video/mp4",
                "filetype": "mp4",
                "pretty_type": "MPEG 4 Video",
                "user": "U06SS0DHZD1",
                "user_team": "T5TCAFTA9",
                "editable": false,
                "size": 20285194,
                "mode": "hosted",
                "is_external": false,
                "external_type": "",
                "is_public": true,
                "public_url_shared": false,
                "display_as_bot": false,
                "username": "",
                "transcription": {
                    "status": "none"
                },
                "mp4": "https://files.slack.com/files-tmb/T5TCAFTA9-F0715TMBNHG-0dbaf56929/326391515-bbb2b225-3857-43ea-9337-5dfb9bfafd4d.mp4",
                "url_private": "https://files.slack.com/files-tmb/T5TCAFTA9-F0715TMBNHG-0dbaf56929/326391515-bbb2b225-3857-43ea-9337-5dfb9bfafd4d.mp4",
                "url_private_download": "https://files.slack.com/files-pri/T5TCAFTA9-F0715TMBNHG/download/326391515-bbb2b225-3857-43ea-9337-5dfb9bfafd4d.mp4",
                "hls": "https://files.slack.com/files-tmb/T5TCAFTA9-F0715TMBNHG-0dbaf56929/file.m3u8?_xcb=7fe28",
                "hls_embed": "data:application/vnd.apple.mpegurl;base64,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",
                "mp4_low": "https://files.slack.com/files-tmb/T5TCAFTA9-F0715TMBNHG-0dbaf56929/326391515-bbb2b225-3857-43ea-9337-5dfb9bfafd4d_trans.mp4",
                "duration_ms": 30630,
                "media_display_type": "video",
                "thumb_video": "https://files.slack.com/files-tmb/T5TCAFTA9-F0715TMBNHG-0dbaf56929/326391515-bbb2b225-3857-43ea-9337-5dfb9bfafd4d_thumb_video.jpeg",
                "thumb_video_w": 1920,
                "thumb_video_h": 1080,
                "thumb_video_ts": "https://files.slack.com/files-tmb/T5TCAFTA9-F0715TMBNHG-0dbaf56929/326391515-bbb2b225-3857-43ea-9337-5dfb9bfafd4d_thumb_video_ts.jpeg?1714410600625",
                "permalink": "https://futureofcoding.slack.com/files/U06SS0DHZD1/F0715TMBNHG/326391515-bbb2b225-3857-43ea-9337-5dfb9bfafd4d.mp4",
                "permalink_public": "https://slack-files.com/T5TCAFTA9-F0715TMBNHG-577784ba03",
                "is_starred": false,
                "has_rich_preview": false,
                "file_access": "visible"
            }
        ],
        "upload": false,
        "user": "U06SS0DHZD1",
        "display_as_bot": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "VAKh5",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Here is an interesting 2.5D experiment for those who like the canvas approach. I'm pretty sure it could have some practical applications. "
                            },
                            {
                                "type": "link",
                                "url": "https://twitter.com/OrionReedOne/status/1784871153787420920"
                            }
                        ]
                    }
                ]
            }
        ],
        "type": "message",
        "ts": "1714410953.740979",
        "client_msg_id": "9b8350e0-f004-42a8-8899-69bf6734dcb7",
        "thread_ts": "1714410953.740979",
        "reply_count": 12,
        "reply_users_count": 3,
        "latest_reply": "1714501352.089899",
        "reply_users": [
            "U06BUK2M2RH",
            "UC2A2ARPT",
            "U014WA16VNJ"
        ],
        "is_locked": false,
        "subscribed": false,
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "U06BUK2M2RH",
                    "U014WA16VNJ",
                    "U06SAHYT80L",
                    "U0123H7JRDM"
                ],
                "count": 4
            },
            {
                "name": "cake",
                "users": [
                    "U85HCL7JP",
                    "U013ZLJARC7"
                ],
                "count": 2
            }
        ]
    },
    {
        "user": "UUQ2EQW21",
        "type": "message",
        "ts": "1714416805.041219",
        "client_msg_id": "dda2b4b6-0671-41be-8bc3-f85663d5d2c4",
        "text": "The tooling here is next-level.  Bret Victor would be proud:\n<https://youtu.be/72y2EC5fkcE?si=MI2T1IME2SH3OCjp>",
        "team": "T5TCAFTA9",
        "thread_ts": "1714416805.041219",
        "reply_count": 5,
        "reply_users_count": 4,
        "latest_reply": "1714686804.540689",
        "reply_users": [
            "UC2A2ARPT",
            "UUQ2EQW21",
            "UDQBTJ211",
            "U05TJD2V4P2"
        ],
        "is_locked": false,
        "subscribed": false,
        "attachments": [
            {
                "from_url": "https://youtu.be/72y2EC5fkcE?si=MI2T1IME2SH3OCjp",
                "service_icon": "https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png",
                "thumb_url": "https://i.ytimg.com/vi/72y2EC5fkcE/hqdefault.jpg",
                "thumb_width": 480,
                "thumb_height": 360,
                "video_html": "<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/72y2EC5fkcE?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Tomorrow Corporation Tech Demo\"></iframe>",
                "video_html_width": 400,
                "video_html_height": 225,
                "id": 1,
                "original_url": "https://youtu.be/72y2EC5fkcE?si=MI2T1IME2SH3OCjp",
                "fallback": "YouTube Video: Tomorrow Corporation Tech Demo",
                "title": "Tomorrow Corporation Tech Demo",
                "title_link": "https://youtu.be/72y2EC5fkcE?si=MI2T1IME2SH3OCjp",
                "author_name": "retrogameinternals",
                "author_link": "https://www.youtube.com/@retrogameinternals4707",
                "service_name": "YouTube",
                "service_url": "https://www.youtube.com/"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "xfI4X",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The tooling here is next-level.  Bret Victor would be proud:\n"
                            },
                            {
                                "type": "link",
                                "url": "https://youtu.be/72y2EC5fkcE?si=MI2T1IME2SH3OCjp"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "100",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            },
            {
                "name": "scream",
                "users": [
                    "U05TJD2V4P2"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U06BUK2M2RH",
        "type": "message",
        "ts": "1714419997.323799",
        "client_msg_id": "5a493331-d46d-4996-9492-7d7de6ebc425",
        "text": "One of my favorite follows!",
        "team": "T5TCAFTA9",
        "thread_ts": "1714410953.740979",
        "parent_user_id": "U06SS0DHZD1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Yw6Vw",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "One of my favorite follows!"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "U014WA16VNJ"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UC2A2ARPT",
        "type": "message",
        "ts": "1714420048.972999",
        "client_msg_id": "b9b8f8dc-cd45-4bfa-95a9-283e7e519c61",
        "text": "I believe <@U014WA16VNJ> stops by from time to time if you have any questions.",
        "team": "T5TCAFTA9",
        "thread_ts": "1714410953.740979",
        "parent_user_id": "U06SS0DHZD1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "5O7XM",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I believe "
                            },
                            {
                                "type": "user",
                                "user_id": "U014WA16VNJ"
                            },
                            {
                                "type": "text",
                                "text": " stops by from time to time if you have any questions."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UC2A2ARPT",
        "type": "message",
        "ts": "1714420076.408479",
        "client_msg_id": "8ccea053-752f-4a18-8991-e0c50f5465d3",
        "text": "Yeah this one slaps",
        "team": "T5TCAFTA9",
        "thread_ts": "1714416805.041219",
        "parent_user_id": "UUQ2EQW21",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "wxZGr",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yeah this one slaps"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U014WA16VNJ",
        "type": "message",
        "ts": "1714421301.371839",
        "client_msg_id": "1C3B2ABC-E477-4F0A-BD95-B9B22A9EF755",
        "text": "Indeed! I really need to spend a lot more time here, the limited history of Slack gives me mild anxiety for some reason though.\nHappy to answer any questions!",
        "team": "T5TCAFTA9",
        "thread_ts": "1714410953.740979",
        "parent_user_id": "U06SS0DHZD1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "YULGO",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Indeed! I really need to spend a lot more time here, the limited history of Slack gives me mild anxiety for some reason though.\nHappy to answer any questions!"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "laughing",
                "users": [
                    "U06BUK2M2RH",
                    "U013ZLJARC7"
                ],
                "count": 2
            },
            {
                "name": "point_up_2",
                "users": [
                    "UJFN50C00"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UC2A2ARPT",
        "type": "message",
        "ts": "1714421442.198159",
        "edited": {
            "user": "UC2A2ARPT",
            "ts": "1714421558.000000"
        },
        "client_msg_id": "a1a719ce-eb59-4eaa-93c9-36d640d41faa",
        "text": "I'm curious if you've figured out something hard-hittingly _useful_ to do with this sense of depth. I feel like showing proximity and history are squarely _neat_ but sort of solutions in search of problems.\n\nTo be clear \u2014 I'm 1000% in favour of trying stuff for the sake of it. I'm just wondering what findings you've found thus far.\n\n(This stuff is surely also super early / under-explored, so I'm not expecting any grand revelations beyond what you shared in the tweet/masto threads)",
        "team": "T5TCAFTA9",
        "thread_ts": "1714410953.740979",
        "parent_user_id": "U06SS0DHZD1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "mCHzH",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I'm curious if you've figured out something hard-hittingly "
                            },
                            {
                                "type": "text",
                                "text": "useful ",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "to do with this sense of depth. I feel like showing proximity and history are squarely "
                            },
                            {
                                "type": "text",
                                "text": "neat",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " but sort of solutions in search of problems.\n\nTo be clear \u2014 I'm 1000% in favour of trying stuff for the sake of it. I'm just wondering what findings you've found thus far.\n\n(This stuff is surely also super early / under-explored, so I'm not expecting any grand revelations beyond what you shared in the tweet/masto threads)"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U014WA16VNJ",
        "type": "message",
        "ts": "1714424149.779829",
        "client_msg_id": "453B7AB9-AFE1-4968-92A9-FC0B5EAA00BC",
        "text": "Definitely under explored, came up with the idea yesterday\u2026\n\nTwo things that stand out so far are making larger topologies legible, when you have edges/connections to things further away, you can really \u201csee\u201d that distance with the edge visualisation.\n\nThe second is similar, where you gain a sense of context beyond the viewport, like \u201coh there\u2019s a cluster of shapes to my left\u2026\n\nI have a bunch of ideas I wanna try, I think there\u2019s some potentially quite useful stuff among the neat-ness",
        "team": "T5TCAFTA9",
        "thread_ts": "1714410953.740979",
        "parent_user_id": "U06SS0DHZD1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "lDsIM",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Definitely under explored, came up with the idea yesterday"
                            },
                            {
                                "type": "text",
                                "text": "\u2026"
                            },
                            {
                                "type": "text",
                                "text": "\n\nTwo things that stand out so far are making larger topologies legible, when you have edges/connections to things further away, you can really \u201csee\u201d that distance with the edge visualisation.\n\nThe second is similar, where you gain a sense of context beyond the viewport, like \u201coh "
                            },
                            {
                                "type": "text",
                                "text": "there\u2019s"
                            },
                            {
                                "type": "text",
                                "text": " a cluster of shapes to my left"
                            },
                            {
                                "type": "text",
                                "text": "\u2026"
                            },
                            {
                                "type": "text",
                                "text": "\n\nI have a bunch of ideas I wanna try, I think "
                            },
                            {
                                "type": "text",
                                "text": "there\u2019s"
                            },
                            {
                                "type": "text",
                                "text": " some potentially quite useful stuff among the neat-ness"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "U06BUK2M2RH"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UC2A2ARPT",
        "type": "message",
        "ts": "1714424365.740089",
        "client_msg_id": "1450d16a-c8cb-4c7c-85d1-b3331acf1a7c",
        "text": "The \"best\" (or maybe, \"most\") idea I've had for using depth in an otherwise 2d canvas is in the context of visual programming, as a way to represent different levels of abstraction. That is, things further behind the current plane are functions / subroutines / whatever that stuff on the current plane can call into. So in the context of node-wire, you can have wires between things on the same plane, or wires that go _inward_ representing the invocation of some function defined _elsewhere_. You don't necessarily need to see those abstractions in full granularity, either. They can be fogged or blurred (like depth of field).",
        "team": "T5TCAFTA9",
        "thread_ts": "1714410953.740979",
        "parent_user_id": "U06SS0DHZD1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "6k2I2",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The \"best\" (or maybe, \"most\") idea I've had for using depth in an otherwise 2d canvas is in the context of visual programming, as a way to represent different levels of abstraction. That is, things further behind the current plane are functions / subroutines / whatever that stuff on the current plane can call into. So in the context of node-wire, you can have wires between things on the same plane, or wires that go "
                            },
                            {
                                "type": "text",
                                "text": "inward",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " representing the invocation of some function defined "
                            },
                            {
                                "type": "text",
                                "text": "elsewhere",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ". You don't necessarily need to see those abstractions in full granularity, either. They can be fogged or blurred (like depth of field)."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "U06BUK2M2RH",
                    "U014WA16VNJ"
                ],
                "count": 2
            },
            {
                "name": "cake",
                "users": [
                    "U013ZLJARC7"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UC2A2ARPT",
        "type": "message",
        "ts": "1714424399.423639",
        "client_msg_id": "d3bedca2-455f-422d-898b-4b730bd5e430",
        "text": "A \"go to definition\" would zoom you inward along the Z axis.",
        "team": "T5TCAFTA9",
        "thread_ts": "1714410953.740979",
        "parent_user_id": "U06SS0DHZD1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "C+tkO",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "A \"go to definition\" would zoom you inward along the Z axis."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "exploding_head",
                "users": [
                    "U85HCL7JP"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UC2A2ARPT",
        "type": "message",
        "ts": "1714424587.919109",
        "client_msg_id": "86b41e8e-63a9-4a69-b6eb-74f51bdd8604",
        "text": "Anyway, something I've been meaning to explore. Not sure how well it'd work in practice. But it does feel like _depth_ sits at an interesting place in the range of (gestalt-y) visual dimensions for representation (color, shape, spacing, etc), in that it's both a continuous dimension (like hue and spacing, unlike shape) but also more useful as a discrete difference (deep vs shallow) than something with fine gradations (different meanings for z = 1, z = 2, \u2026 z = 100, z = 101\u2026)",
        "team": "T5TCAFTA9",
        "thread_ts": "1714410953.740979",
        "parent_user_id": "U06SS0DHZD1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "jCQR7",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Anyway, something I've been meaning to explore. Not sure how well it'd work in practice. But it does feel like "
                            },
                            {
                                "type": "text",
                                "text": "depth",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " sits at an interesting place in the range of (gestalt-y) visual dimensions for representation (color, shape, spacing, etc), in that it's both a continuous dimension (like hue and spacing, unlike shape) but also more useful as a discrete difference (deep vs shallow) than something with fine gradations (different meanings for z = 1, z = 2, \u2026 z = 100, z = 101\u2026)"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U014WA16VNJ",
        "type": "message",
        "ts": "1714425049.394429",
        "client_msg_id": "798E1FB9-AFC0-40C9-8976-8AB2E1937EF0",
        "text": "The other notable thing about depth is that it\u2019s made legible through motion, so it might naturally be suited to information which is relevant when navigating \u2014 I think your \u201clevel of abstraction\u201d example is good, as you often care about that when looking at multiple things, wanting to compare them in some way ",
        "team": "T5TCAFTA9",
        "thread_ts": "1714410953.740979",
        "parent_user_id": "U06SS0DHZD1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "6hKGJ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The other notable thing about depth is that it\u2019s made legible through motion, so it might naturally be suited to information which is relevant when navigating \u2014 I think your \u201clevel of abstraction\u201d example is good, as you often care about that when looking at multiple things, wanting to compare them in some way "
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "cake",
                "users": [
                    "U013ZLJARC7"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U014WA16VNJ",
        "type": "message",
        "ts": "1714425099.033499",
        "client_msg_id": "616344BD-EA32-4072-A46B-AEDAC61A806B",
        "text": "And when static, it can stay out of mind more easily than stuff in-plane ",
        "team": "T5TCAFTA9",
        "thread_ts": "1714410953.740979",
        "parent_user_id": "U06SS0DHZD1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "tv3yz",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "And when static, it can stay out of mind more easily than stuff in-plane "
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UUQ2EQW21",
        "type": "message",
        "ts": "1714467713.373209",
        "client_msg_id": "426e7c9a-59c2-4b98-a46b-c12a6f4b5ee5",
        "text": "There is frustratingly little detail about how it was built; I googled a bit, but couldn't find anything.  It would be interesting to know how it was put together.",
        "team": "T5TCAFTA9",
        "thread_ts": "1714416805.041219",
        "parent_user_id": "UUQ2EQW21",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "26eU9",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "There is frustratingly little detail about how it was built; I googled a bit, but couldn't find anything.  It would be interesting to know how it was put together."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UUQ2EQW21",
        "type": "message",
        "ts": "1714486655.048499",
        "edited": {
            "user": "UUQ2EQW21",
            "ts": "1714486670.000000"
        },
        "client_msg_id": "d56ca179-61c5-4f2f-abaa-c0b9bedbd02f",
        "text": "There's a little more detail in a response on their blog (<https://tomorrowcorporation.com/posts/how-we-make-games-at-tomorrow-corp-our-custom-tools-tech-demo>)\n\n\"The act of going forward and back is not itself recorded \u2013 just the evolution of the game\u2019s state.\nThe snapshots happen according to 2 different schedules \u2013 a coarse grain schedule that records a new snapshot every so often based on time (we do every 2 minutes currently) and a fine grain limited set of snapshots that move around depending on where you are currently working on the timeline. That\u2019s why the initial reverse debugger step causes a brief pause and then becomes fast \u2013 the first one seeks back to the most recent coarse grain snapshot, simulates forward creating fine grained snapshots that are exponentially spaced out backwards from your seek target, and then the subsequent steps will tend to have a snapshot that is right on the frame you need (or very close \u2013 unless you step back far enough to need to go create more snapshots but that is the rare case.)\nThe state capture is mostly just a memcpy of the game\u2019s heap (snapshots only happen on frame boundaries so the stack is never needed.) It for sure could be too big to keep as many snapshots as we currently do \u2013 that will just be game dependent. Something to use to calibrate what you expect is possible though is to remember that games like Metroid Prime, LOZ The Wind Waker, RE4, Mario Sunshine, etc. all ran on a system that basically had 24MB of RAM to use for your game. And it wasn\u2019t just game state filling up that 24MB, it was your code and other read only resources \u2013 the kind of stuff that we don\u2019t have to include in our snapshots. So while it\u2019s true that this system is not a general purpose solution for any and all kinds of games, it\u2019s also true that you can make some pretty incredible games with not a ton of actual game state.\nYes in theory you could totally fork the timeline in the past and create a new session based off of the old one up to that point. That is a feature that I had in the reverse engineering debugger I made before this because it was good for creating what were basically tool assisted speed run videos for code coverage purposes. For our current system though it hasn\u2019t been something that I thought we would actually use enough to justify spending the time to implement it.\nThe code gen is totally custom but keep in mind that this toolchain only needs to run on our development platform which is Windows. To ship the finished game we will transpile the code to C and then compile it with the native toolchains on whatever platforms we\u2019re targeting.\"",
        "team": "T5TCAFTA9",
        "thread_ts": "1714416805.041219",
        "parent_user_id": "UUQ2EQW21",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "F38dX",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "There's a little more detail in a response on their blog ("
                            },
                            {
                                "type": "link",
                                "url": "https://tomorrowcorporation.com/posts/how-we-make-games-at-tomorrow-corp-our-custom-tools-tech-demo"
                            },
                            {
                                "type": "text",
                                "text": ")\n\n\"The act of going forward and back is not itself recorded \u2013 just the evolution of the game\u2019s state.\nThe snapshots happen according to 2 different schedules \u2013 a coarse grain schedule that records a new snapshot every so often based on time (we do every 2 minutes currently) and a fine grain limited set of snapshots that move around depending on where you are currently working on the timeline. That\u2019s why the initial reverse debugger step causes a brief pause and then becomes fast \u2013 the first one seeks back to the most recent coarse grain snapshot, simulates forward creating fine grained snapshots that are exponentially spaced out backwards from your seek target, and then the subsequent steps will tend to have a snapshot that is right on the frame you need (or very close \u2013 unless you step back far enough to need to go create more snapshots but that is the rare case.)\nThe state capture is mostly just a memcpy of the game\u2019s heap (snapshots only happen on frame boundaries so the stack is never needed.) It for sure could be too big to keep as many snapshots as we currently do \u2013 that will just be game dependent. Something to use to calibrate what you expect is possible though is to remember that games like Metroid Prime, LOZ The Wind Waker, RE4, Mario Sunshine, etc. all ran on a system that basically had 24MB of RAM to use for your game. And it wasn\u2019t just game state filling up that 24MB, it was your code and other read only resources \u2013 the kind of stuff that we don\u2019t have to include in our snapshots. So while it\u2019s true that this system is not a general purpose solution for any and all kinds of games, it\u2019s also true that you can make some pretty incredible games with not a ton of actual game state.\nYes in theory you could totally fork the timeline in the past and create a new session based off of the old one up to that point. That is a feature that I had in the reverse engineering debugger I made before this because it was good for creating what were basically tool assisted speed run videos for code coverage purposes. For our current system though it hasn\u2019t been something that I thought we would actually use enough to justify spending the time to implement it.\nThe code gen is totally custom but keep in mind that this toolchain only needs to run on our development platform which is Windows. To ship the finished game we will transpile the code to C and then compile it with the native toolchains on whatever platforms we\u2019re targeting.\""
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "cake",
                "users": [
                    "UC2A2ARPT",
                    "U05TJD2V4P2"
                ],
                "count": 2
            }
        ]
    },
    {
        "text": "Was thinking about motion today and thought if this thread. Frames with changing opacity is a nice way to visualize the past and the future (bret victor style). This is psuedo-design but you can imagine some system that could enable/disable shadows of the future, past, or both. Using a high numbers of frames making smooth gradients and using lower numbers both seems interesting. Could also imagine color delineating past v future if both are enabled. Very interesting thread to pull.",
        "files": [
            {
                "id": "F0716Q5JZK8",
                "created": 1714500495,
                "timestamp": 1714500495,
                "name": "Screenshot 2024-04-30 at 2.07.31\u202fPM.png",
                "title": "Screenshot 2024-04-30 at 2.07.31\u202fPM.png",
                "mimetype": "image/png",
                "filetype": "png",
                "pretty_type": "PNG",
                "user": "U06BUK2M2RH",
                "user_team": "T5TCAFTA9",
                "editable": false,
                "size": 25922,
                "mode": "hosted",
                "is_external": false,
                "external_type": "",
                "is_public": true,
                "public_url_shared": false,
                "display_as_bot": false,
                "username": "",
                "url_private": "https://files.slack.com/files-pri/T5TCAFTA9-F0716Q5JZK8/screenshot_2024-04-30_at_2.07.31___pm.png",
                "url_private_download": "https://files.slack.com/files-pri/T5TCAFTA9-F0716Q5JZK8/download/screenshot_2024-04-30_at_2.07.31___pm.png",
                "media_display_type": "unknown",
                "thumb_64": "https://files.slack.com/files-tmb/T5TCAFTA9-F0716Q5JZK8-774a36f463/screenshot_2024-04-30_at_2.07.31___pm_64.png",
                "thumb_80": "https://files.slack.com/files-tmb/T5TCAFTA9-F0716Q5JZK8-774a36f463/screenshot_2024-04-30_at_2.07.31___pm_80.png",
                "thumb_360": "https://files.slack.com/files-tmb/T5TCAFTA9-F0716Q5JZK8-774a36f463/screenshot_2024-04-30_at_2.07.31___pm_360.png",
                "thumb_360_w": 360,
                "thumb_360_h": 92,
                "thumb_480": "https://files.slack.com/files-tmb/T5TCAFTA9-F0716Q5JZK8-774a36f463/screenshot_2024-04-30_at_2.07.31___pm_480.png",
                "thumb_480_w": 480,
                "thumb_480_h": 123,
                "thumb_160": "https://files.slack.com/files-tmb/T5TCAFTA9-F0716Q5JZK8-774a36f463/screenshot_2024-04-30_at_2.07.31___pm_160.png",
                "thumb_720": "https://files.slack.com/files-tmb/T5TCAFTA9-F0716Q5JZK8-774a36f463/screenshot_2024-04-30_at_2.07.31___pm_720.png",
                "thumb_720_w": 720,
                "thumb_720_h": 185,
                "thumb_800": "https://files.slack.com/files-tmb/T5TCAFTA9-F0716Q5JZK8-774a36f463/screenshot_2024-04-30_at_2.07.31___pm_800.png",
                "thumb_800_w": 800,
                "thumb_800_h": 205,
                "original_w": 954,
                "original_h": 245,
                "thumb_tiny": "AwAMADDRJAx6npSEkAdM96dRQAikkZOPwpN2Tx0HWnUUAM3NnAC/nThnvj8KWigD/9k=",
                "permalink": "https://futureofcoding.slack.com/files/U06BUK2M2RH/F0716Q5JZK8/screenshot_2024-04-30_at_2.07.31___pm.png",
                "permalink_public": "https://slack-files.com/T5TCAFTA9-F0716Q5JZK8-d270d165d4",
                "is_starred": false,
                "has_rich_preview": false,
                "file_access": "visible"
            }
        ],
        "upload": false,
        "user": "U06BUK2M2RH",
        "display_as_bot": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "vXT4E",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Was thinking about motion today and thought if this thread. Frames with changing opacity is a nice way to visualize the past and the future (bret victor style). This is psuedo-design but you can imagine some system that could enable/disable shadows of the future, past, or both. Using a high numbers of frames making smooth gradients and using lower numbers both seems interesting. Could also imagine color delineating past v future if both are enabled. Very interesting thread to pull."
                            }
                        ]
                    }
                ]
            }
        ],
        "type": "message",
        "ts": "1714500826.436869",
        "client_msg_id": "0c2464e2-a36c-4ab9-b305-8fa99c18d963",
        "thread_ts": "1714410953.740979",
        "parent_user_id": "U06SS0DHZD1",
        "reactions": [
            {
                "name": "cake",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U06BUK2M2RH",
        "type": "message",
        "ts": "1714501352.089899",
        "client_msg_id": "6a4064ca-690c-44bf-b81d-c25a5d0c1967",
        "text": "In rereading this thread- i suppose it's less 'depth' oriented since subsequent shadows aren't scaling, but useful nonetheless with just the changing opacity in the 'trail'",
        "team": "T5TCAFTA9",
        "thread_ts": "1714410953.740979",
        "parent_user_id": "U06SS0DHZD1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "yDkW1",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "In rereading this thread- i suppose it's less 'depth' oriented since subsequent shadows aren't scaling, but useful nonetheless with just the changing opacity in the 'trail'"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UDQBTJ211",
        "type": "message",
        "ts": "1714504479.008349",
        "client_msg_id": "0079b64d-fee4-49bb-8622-45f39be22171",
        "text": "I made a toy time travel debugger for python that used a similar technique. You could run a much simpler simulation when calculating state forward from the snapshot because it didn't need to do any conditional tests. You could just save the series of mutations and reapply them. On a modern CPU it's very fast because there's no branch prediction failures.",
        "team": "T5TCAFTA9",
        "thread_ts": "1714416805.041219",
        "parent_user_id": "UUQ2EQW21",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "W+j76",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I made a toy time travel debugger for python that used a similar technique. You could run a much simpler simulation when calculating state forward from the snapshot because it didn't need to do any conditional tests. You could just save the series of mutations and reapply them. On a modern CPU it's very fast because there's no branch prediction failures."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05TJD2V4P2",
        "type": "message",
        "ts": "1714686804.540689",
        "client_msg_id": "b0d722d0-e0e9-409d-8818-bcc2aefe56c3",
        "text": "This is really amazing! Great share",
        "team": "T5TCAFTA9",
        "thread_ts": "1714416805.041219",
        "parent_user_id": "UUQ2EQW21",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "niuik",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "This is really amazing! Great share"
                            }
                        ]
                    }
                ]
            }
        ]
    }
]