[
    {
        "client_msg_id": "26D275A7-4AAA-45BB-915C-E34CBF7FE112",
        "type": "message",
        "text": "<@UCGAK10LS> Oh, interesting! Do you have any other pointers to more technical resources from them or about other “AI chips”? Their FAQ isn’t going very deep and the website strikes me as very marketing\/VC oriented.\n\nI don’t get the sense that their programming model is “very different” to that of GPUs, more like they’re building on top of that model, but maybe that’s what you mean? And they clearly know about what makes GPU programming complicated and try to differentiate themselves from it — I’m vary of their marketing lingo…\n\nAs they mention PyTorch one way to leverage multiple independent units could be <https:\/\/pytorch.org\/docs\/stable\/notes\/ddp.html|https:\/\/pytorch.org\/docs\/stable\/notes\/ddp.html>.\n\nThis also points towards things like <https:\/\/mlir.llvm.org\/|https:\/\/mlir.llvm.org\/>. In other words, more power to the compiler (and yes, fancy type systems)! :) ",
        "user": "U5STGTB3J",
        "ts": "1624518279.165800",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "649181907e06",
            "image_72": "https:\/\/avatars.slack-edge.com\/2017-08-20\/228447816352_649181907e06ec450c64_72.jpg",
            "first_name": "Stefan",
            "real_name": "Stefan Lesser",
            "display_name": "Stefan",
            "team": "T5TCAFTA9",
            "name": "stefanlesser",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "attachments": [
            {
                "title": "MLIR",
                "title_link": "https:\/\/mlir.llvm.org\/",
                "text": "Multi-Level IR Compiler Framework",
                "fallback": "MLIR",
                "from_url": "https:\/\/mlir.llvm.org\/",
                "service_icon": "https:\/\/mlir.llvm.org\/favicon.ico",
                "service_name": "mlir.llvm.org",
                "id": 1,
                "original_url": "https:\/\/mlir.llvm.org\/"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "MYG3g",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UCGAK10LS"
                            },
                            {
                                "type": "text",
                                "text": " Oh, interesting! Do you have any other pointers to more technical resources from them or about other “AI chips”? Their FAQ isn’t going very deep and the website strikes me as very marketing\/VC oriented.\n\nI don’t get the sense that their programming model is “very different” to that of GPUs, more like they’re building on top of that model, but maybe that’s what you mean? And they clearly know about what makes GPU programming complicated and try to differentiate themselves from it — I’m vary of their marketing lingo…\n\nAs they mention PyTorch one way to leverage multiple independent units could be "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/pytorch.org\/docs\/stable\/notes\/ddp.html",
                                "text": "https:\/\/pytorch.org\/docs\/stable\/notes\/ddp.html"
                            },
                            {
                                "type": "text",
                                "text": ".\n\nThis also points towards things like "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/mlir.llvm.org\/",
                                "text": "https:\/\/mlir.llvm.org\/"
                            },
                            {
                                "type": "text",
                                "text": ". In other words, more power to the compiler (and yes, fancy type systems)! :) "
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "AA5F579E-4016-4CEB-8EC3-C429A658C35D",
        "type": "message",
        "text": "I keep hearing about how Common Lisp has insanely cool tooling but struggling to find examples. Anyone have any links?",
        "user": "U01R76LELBT",
        "ts": "1624541467.166400",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "9751078823a2",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-03-10\/1846261486882_9751078823a2ecfe91c4_72.jpg",
            "first_name": "Rob",
            "real_name": "Rob Haisfield",
            "display_name": "Rob Haisfield",
            "team": "T5TCAFTA9",
            "name": "rob969",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "2\/JhA",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I keep hearing about how Common Lisp has insanely cool tooling but struggling to find examples. Anyone have any links?"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624541467.166400",
        "reply_count": 6,
        "reply_users_count": 5,
        "latest_reply": "1624857650.173400",
        "reply_users": [
            "U01362XBSNA",
            "UGWUJUZHT",
            "UUQ2EQW21",
            "UT60XSVCN",
            "USH01JEDQ"
        ],
        "replies": [
            {
                "user": "U01362XBSNA",
                "ts": "1624543332.167000"
            },
            {
                "user": "UGWUJUZHT",
                "ts": "1624590750.168700"
            },
            {
                "user": "UUQ2EQW21",
                "ts": "1624632804.169400"
            },
            {
                "user": "UUQ2EQW21",
                "ts": "1624632817.169700"
            },
            {
                "user": "UT60XSVCN",
                "ts": "1624717227.170700"
            },
            {
                "user": "USH01JEDQ",
                "ts": "1624857650.173400"
            }
        ],
        "is_locked": false,
        "subscribed": false
    },
    {
        "client_msg_id": "a4732edf-0d46-4ded-bc62-f0c4482c418d",
        "type": "message",
        "text": "Do you have an example application in mind? For instance if you want a generally responsive language, memory use efficiency, perhaps some convenience routines for objects going out of scope (e.g. automatic closing of file descriptors, sockets), predictable runtime and memory use, then reference counting seems like a better fit. OTOH:: scope exit becomes slower, and is potentially unbounded (imagine reclaiming a giant graph of data), overall runtime is higher because of all the accounting busywork and cpu cache disruption (can be as much as ~30% slower but it's complicated), and concurrency becomes harder: child processes will trigger copy on write (you can minimize the impact by storing the refcount in a small object header and storing all headers in a contiguous memory block), refcounts are also a contention issue for POSIX threads.",
        "user": "U025PBD75TM",
        "ts": "1624541626.166500",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "d0f48a5cbd36",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-06-21\/2186437719222_d0f48a5cbd367fc3a50b_72.jpg",
            "first_name": "dnmfarrell",
            "real_name": "dnmfarrell",
            "display_name": "dnmfarrell",
            "team": "T5TCAFTA9",
            "name": "davidnmfarrell",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "edited": {
            "user": "U025PBD75TM",
            "ts": "1624541793.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "A1n",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Do you have an example application in mind? For instance if you want a generally responsive language, memory use efficiency, perhaps some convenience routines for objects going out of scope (e.g. automatic closing of file descriptors, sockets), predictable runtime and memory use, then reference counting seems like a better fit. OTOH:: scope exit becomes slower, and is potentially unbounded (imagine reclaiming a giant graph of data), overall runtime is higher because of all the accounting busywork and cpu cache disruption (can be as much as ~30% slower but it's complicated), and concurrency becomes harder: child processes will trigger copy on write (you can minimize the impact by storing the refcount in a small object header and storing all headers in a contiguous memory block), refcounts are also a contention issue for POSIX threads."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "d8a11850-f29b-46dd-a31e-f1eff7ef133e",
        "type": "message",
        "text": "SLY (<https:\/\/github.com\/joaotavora\/sly>) and SLIME is a good place to start. I played around a bit with SLY last year and it has some pretty cool features such as stickers",
        "user": "U01362XBSNA",
        "ts": "1624543332.167000",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gd8f441f024b",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/d8f441f024bb5bd813214b368cfc1f97.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png",
            "first_name": "",
            "real_name": "Haakon HR",
            "display_name": "Haakon HR",
            "team": "T5TCAFTA9",
            "name": "haakonhr",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "attachments": [
            {
                "service_name": "GitHub",
                "title": "joaotavora\/sly",
                "title_link": "https:\/\/github.com\/joaotavora\/sly",
                "text": "Sylvester the Cat's Common Lisp IDE. Contribute to joaotavora\/sly development by creating an account on GitHub.",
                "fallback": "GitHub: joaotavora\/sly",
                "image_url": "https:\/\/opengraph.githubassets.com\/b0ef10f8183ef0d9a3ed2a5a85b9d648b6cc339294146ef61fc90f08e6f7593a\/joaotavora\/sly",
                "image_width": 500,
                "image_height": 250,
                "from_url": "https:\/\/github.com\/joaotavora\/sly",
                "image_bytes": 126771,
                "service_icon": "https:\/\/a.slack-edge.com\/80588\/img\/unfurl_icons\/github.png",
                "id": 1,
                "original_url": "https:\/\/github.com\/joaotavora\/sly"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "PJPn",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "SLY ("
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/github.com\/joaotavora\/sly"
                            },
                            {
                                "type": "text",
                                "text": ") and SLIME is a good place to start. I played around a bit with SLY last year and it has some pretty cool features such as stickers"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624541467.166400",
        "parent_user_id": "U01R76LELBT"
    },
    {
        "client_msg_id": "7c3a9a60-025a-4bd7-816e-bd7cd51017f5",
        "type": "message",
        "text": "You might want to read up on the various languages designed for the <https:\/\/en.wikipedia.org\/wiki\/Thinking_Machines_Corporation|Thinking Machines> CM series, including *Lisp and CM Lisp. I worked on one of these with 768 cores, but the top models had 65,000+ cores running in a parallel machine with perfectly pleasant high level language support.",
        "user": "U013ZLJARC7",
        "ts": "1624545723.167300",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gf4ae9e5b293",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/f4ae9e5b29386489b18b3bc6b1f41a22.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png",
            "first_name": "",
            "real_name": "Jack Rusher",
            "display_name": "Jack Rusher",
            "team": "T5TCAFTA9",
            "name": "jack529",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "lNO2N",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "You might want to read up on the various languages designed for the "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/en.wikipedia.org\/wiki\/Thinking_Machines_Corporation",
                                "text": "Thinking Machines"
                            },
                            {
                                "type": "text",
                                "text": " CM series, including *Lisp and CM Lisp. I worked on one of these with 768 cores, but the top models had 65,000+ cores running in a parallel machine with perfectly pleasant high level language support."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS",
        "reactions": [
            {
                "name": "bulb",
                "users": [
                    "U025PBD75TM"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "53163e44-2380-4037-bd39-55e4cecb73cf",
        "type": "message",
        "text": "<@U5STGTB3J> There are some interviews and videos of Tenstorrent online. Here's a recent one <https:\/\/www.anandtech.com\/show\/16709\/an-interview-with-tenstorrent-ceo-ljubisa-bajic-and-cto-jim-keller|with Anandtech>. Here's a long <https:\/\/www.youtube.com\/watch?v=G4hL5Om4IJ4|podcast episode with the CTO> where he talks about a bunch of computing-related stuff, including hardware architectures for AI. Here's <https:\/\/www.youtube.com\/watch?v=Uls3-UWm-sY|a short technical presentation> on how their chips work.",
        "user": "UCGAK10LS",
        "ts": "1624575554.167800",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "770c193fd379",
            "image_72": "https:\/\/avatars.slack-edge.com\/2020-04-17\/1092364753072_770c193fd379ebbced3f_72.jpg",
            "first_name": "",
            "real_name": "Nick Smith",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "nmsmith65",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "attachments": [
            {
                "title": "An Interview with Tenstorrent: CEO Ljubisa Bajic and CTO Jim Keller",
                "title_link": "https:\/\/www.anandtech.com\/show\/16709\/an-interview-with-tenstorrent-ceo-ljubisa-bajic-and-cto-jim-keller",
                "fallback": "An Interview with Tenstorrent: CEO Ljubisa Bajic and CTO Jim Keller",
                "image_url": "https:\/\/images.anandtech.com\/doci\/16709\/a3_678x452.png",
                "from_url": "https:\/\/www.anandtech.com\/show\/16709\/an-interview-with-tenstorrent-ceo-ljubisa-bajic-and-cto-jim-keller",
                "image_width": 569,
                "image_height": 250,
                "image_bytes": 176867,
                "service_icon": "https:\/\/www.anandtech.com\/content\/images\/podcast_a_huge.png",
                "service_name": "AnandTech",
                "id": 1,
                "original_url": "https:\/\/www.anandtech.com\/show\/16709\/an-interview-with-tenstorrent-ceo-ljubisa-bajic-and-cto-jim-keller"
            },
            {
                "service_name": "YouTube",
                "service_url": "https:\/\/www.youtube.com\/",
                "title": "Jim Keller: The Future of Computing, AI, Life, and Consciousness | Lex Fridman Podcast #162",
                "title_link": "https:\/\/www.youtube.com\/watch?v=G4hL5Om4IJ4",
                "author_name": "Lex Fridman",
                "author_link": "https:\/\/www.youtube.com\/c\/lexfridman",
                "thumb_url": "https:\/\/i.ytimg.com\/vi\/G4hL5Om4IJ4\/hqdefault.jpg",
                "thumb_width": 480,
                "thumb_height": 360,
                "fallback": "YouTube Video: Jim Keller: The Future of Computing, AI, Life, and Consciousness | Lex Fridman Podcast #162",
                "video_html": "<iframe width=\"400\" height=\"225\" src=\"https:\/\/www.youtube.com\/embed\/G4hL5Om4IJ4?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>",
                "video_html_width": 400,
                "video_html_height": 225,
                "from_url": "https:\/\/www.youtube.com\/watch?v=G4hL5Om4IJ4",
                "service_icon": "https:\/\/a.slack-edge.com\/80588\/img\/unfurl_icons\/youtube.png",
                "id": 2,
                "original_url": "https:\/\/www.youtube.com\/watch?v=G4hL5Om4IJ4"
            },
            {
                "service_name": "YouTube",
                "service_url": "https:\/\/www.youtube.com\/",
                "title": "Tenstorrent: Relegating the Important Stuff to the Compiler",
                "title_link": "https:\/\/www.youtube.com\/watch?v=Uls3-UWm-sY",
                "author_name": "The Linley Group",
                "author_link": "https:\/\/www.youtube.com\/c\/LinleygroupVideos",
                "thumb_url": "https:\/\/i.ytimg.com\/vi\/Uls3-UWm-sY\/hqdefault.jpg",
                "thumb_width": 480,
                "thumb_height": 360,
                "fallback": "YouTube Video: Tenstorrent: Relegating the Important Stuff to the Compiler",
                "video_html": "<iframe width=\"400\" height=\"225\" src=\"https:\/\/www.youtube.com\/embed\/Uls3-UWm-sY?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>",
                "video_html_width": 400,
                "video_html_height": 225,
                "from_url": "https:\/\/www.youtube.com\/watch?v=Uls3-UWm-sY",
                "service_icon": "https:\/\/a.slack-edge.com\/80588\/img\/unfurl_icons\/youtube.png",
                "id": 3,
                "original_url": "https:\/\/www.youtube.com\/watch?v=Uls3-UWm-sY"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "3TBl",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U5STGTB3J"
                            },
                            {
                                "type": "text",
                                "text": " There are some interviews and videos of Tenstorrent online. Here's a recent one "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/www.anandtech.com\/show\/16709\/an-interview-with-tenstorrent-ceo-ljubisa-bajic-and-cto-jim-keller",
                                "text": "with Anandtech"
                            },
                            {
                                "type": "text",
                                "text": ". Here's a long "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/www.youtube.com\/watch?v=G4hL5Om4IJ4",
                                "text": "podcast episode with the CTO"
                            },
                            {
                                "type": "text",
                                "text": " where he talks about a bunch of computing-related stuff, including hardware architectures for AI. Here's "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/www.youtube.com\/watch?v=Uls3-UWm-sY",
                                "text": "a short technical presentation"
                            },
                            {
                                "type": "text",
                                "text": " on how their chips work."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U5STGTB3J"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "4dd70ed7-a2cf-4acc-8fe0-a65bf6275a64",
        "type": "message",
        "text": "<@U025PBD75TM> You're mentioning a lot of issues on conventional hardware architectures (cache and thread contention) and sure, there are some trade-offs when choosing between reference counting and tracing GCs in that context. But I'm focusing more on massively-parallel architectures, which I think changes the rules a bit. For example, Tenstorrent's chips have no shared memory, no caches, and no threads. Instead they have a grid of compute units, each with a dedicated SRAM (not a cache) and capable of doing parallel matrix\/tensor operations. This is my \"application\" if you like: writing programs that can run on this type of machine. Why? Because they're going to offer up 100x the compute power of CPUs and are more suited to heterogeneous workloads than GPUs. From what I can see, they have a chance at obsoleting the whole idea of a CPU, as long as we can program them. There is insane amounts of money pouring into these companies (for their applications to AI), and some of these chips are going to become widely-deployed in data centers and (eventually) consumer devices.",
        "user": "UCGAK10LS",
        "ts": "1624576469.168200",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "770c193fd379",
            "image_72": "https:\/\/avatars.slack-edge.com\/2020-04-17\/1092364753072_770c193fd379ebbced3f_72.jpg",
            "first_name": "",
            "real_name": "Nick Smith",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "nmsmith65",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "2lZ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U025PBD75TM"
                            },
                            {
                                "type": "text",
                                "text": " You're mentioning a lot of issues on conventional hardware architectures (cache and thread contention) and sure, there are some trade-offs when choosing between reference counting and tracing GCs in that context. But I'm focusing more on massively-parallel architectures, which I think changes the rules a bit. For example, Tenstorrent's chips have no shared memory, no caches, and no threads. Instead they have a grid of compute units, each with a dedicated SRAM (not a cache) and capable of doing parallel matrix\/tensor operations. This is my \"application\" if you like: writing programs that can run on this type of machine. Why? Because they're going to offer up 100x the compute power of CPUs and are more suited to heterogeneous workloads than GPUs. From what I can see, they have a chance at obsoleting the whole idea of a CPU, as long as we can program them. There is insane amounts of money pouring into these companies (for their applications to AI), and some of these chips are going to become widely-deployed in data centers and (eventually) consumer devices."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U025PBD75TM",
                    "U019CPED6T1"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "de445f3f-273f-487e-8125-148077ec0905",
        "type": "message",
        "text": "<@U013ZLJARC7> I'll look them up, thank you :slightly_smiling_face:",
        "user": "UCGAK10LS",
        "ts": "1624576618.168400",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "770c193fd379",
            "image_72": "https:\/\/avatars.slack-edge.com\/2020-04-17\/1092364753072_770c193fd379ebbced3f_72.jpg",
            "first_name": "",
            "real_name": "Nick Smith",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "nmsmith65",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "bqm",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U013ZLJARC7"
                            },
                            {
                                "type": "text",
                                "text": " I'll look them up, thank you "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U013ZLJARC7"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "4448aee0-f9bd-4c9b-813f-1660146bfd3f",
        "type": "message",
        "text": "I would suggest looking at 3 lisp IDEs:\n\na) Lispworks (very well integrated set of tools)\nb) emacs + slime (contains *everything*, see, esp. org-mode)\nc) Racket\n\nThen, you need to know what it is that you want to accomplish: [+]\n1) rapid prototyping, or,\n2) compilation.\n\nEarly lisps emphasized 1, CL emphasizes 2 but has more 1 than most languages (see, for example, restarts).\n\n[Asides: Debugging is easier when the debugger language is the same as the language being debugged.  Debugging is facilitated when a language has no syntax and is expression-based. Debugging is facilitated when the debugger and the language being debugged are the same thing.]\n\n<http:\/\/www.lispworks.com\/products\/index.html>\n<https:\/\/orgmode.org\/>\n<https:\/\/racket-lang.org\/>\n\n[+] I contend that you don’t want both at once.  [IMO, 1 and 2 are different views on 0 (The Solution\/Design)].",
        "user": "UGWUJUZHT",
        "ts": "1624590750.168700",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g222ae5c0173",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/8222ae5c01730d4dba6a358e4d5f9031.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png",
            "first_name": "",
            "real_name": "Paul Tarvydas",
            "display_name": "guitarvydas",
            "team": "T5TCAFTA9",
            "name": "paultarvydas",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "attachments": [
            {
                "title": "Org Mode",
                "title_link": "https:\/\/orgmode.org\/",
                "text": "Org-mode. Complex so you don't have to be. A versatile organisational system with immense capabilities.",
                "fallback": "Org Mode",
                "image_url": "https:\/\/orgmode.org\/resources\/img\/social-card.png",
                "image_width": 500,
                "image_height": 250,
                "from_url": "https:\/\/orgmode.org\/",
                "image_bytes": 106184,
                "service_icon": "https:\/\/orgmode.org\/resources\/img\/favicons\/apple-touch-icon.png",
                "service_name": "orgmode.org",
                "id": 1,
                "original_url": "https:\/\/orgmode.org\/"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ZD0",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I would suggest looking at 3 lisp IDEs:\n\na) Lispworks (very well integrated set of tools)\nb) emacs + slime (contains *everything*, see, esp. org-mode)\nc) Racket\n\nThen, you need to know what it is that you want to accomplish: [+]\n1) rapid prototyping, or,\n2) compilation.\n\nEarly lisps emphasized 1, CL emphasizes 2 but has more 1 than most languages (see, for example, restarts).\n\n[Asides: Debugging is easier when the debugger language is the same as the language being debugged.  Debugging is facilitated when a language has no syntax and is expression-based. Debugging is facilitated when the debugger and the language being debugged are the same thing.]\n\n"
                            },
                            {
                                "type": "link",
                                "url": "http:\/\/www.lispworks.com\/products\/index.html"
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/orgmode.org\/"
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/racket-lang.org\/"
                            },
                            {
                                "type": "text",
                                "text": "\n\n[+] I contend that you don’t want both at once.  [IMO, 1 and 2 are different views on 0 (The Solution\/Design)]."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624541467.166400",
        "parent_user_id": "U01R76LELBT"
    },
    {
        "client_msg_id": "fb688662-9e35-41fe-a28a-d3892a2e7f16",
        "type": "message",
        "text": "Took longer than expected because we tied the announcement into a conference talk, but here's the first part of the work I mentioned above :slightly_smiling_face:  <https:\/\/futureofcoding.slack.com\/archives\/CCL5VVBAN\/p1624520177117600>",
        "user": "U013ZLJARC7",
        "ts": "1624599976.169100",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gf4ae9e5b293",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/f4ae9e5b29386489b18b3bc6b1f41a22.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png",
            "first_name": "",
            "real_name": "Jack Rusher",
            "display_name": "Jack Rusher",
            "team": "T5TCAFTA9",
            "name": "jack529",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "attachments": [
            {
                "from_url": "https:\/\/futureofcoding.slack.com\/archives\/CCL5VVBAN\/p1624520177117600",
                "fallback": "[June 24th, 2021 12:36 AM] jack529: One of two talks from this year's ClojureD (German Clojure conference) about work with which I've been helping the team at <https:\/\/nextjournal.com\/|Nextjournal>. This <https:\/\/www.youtube.com\/watch?v=A0TafHXszgM|talk focuses on a UI\/UX redesign> that updates context-driven, keyboard-friendly ideas from older environments (especially Lisp Machines!) with modern niceties. One thing we don't talk about here is that in the future the command subsystem will also be expandable and scriptable by end users. There's more Lisp Machine-related goodness coming in the next talk video, which should be released in the coming days. :slightly_smiling_face:",
                "ts": "1624520177.117600",
                "author_id": "U013ZLJARC7",
                "author_subname": "Jack Rusher",
                "channel_id": "CCL5VVBAN",
                "channel_name": "share-your-work",
                "is_msg_unfurl": true,
                "is_thread_root_unfurl": true,
                "text": "One of two talks from this year's ClojureD (German Clojure conference) about work with which I've been helping the team at <https:\/\/nextjournal.com\/|Nextjournal>. This <https:\/\/www.youtube.com\/watch?v=A0TafHXszgM|talk focuses on a UI\/UX redesign> that updates context-driven, keyboard-friendly ideas from older environments (especially Lisp Machines!) with modern niceties. One thing we don't talk about here is that in the future the command subsystem will also be expandable and scriptable by end users. There's more Lisp Machine-related goodness coming in the next talk video, which should be released in the coming days. :slightly_smiling_face:",
                "author_name": "Jack Rusher",
                "author_link": "https:\/\/futureofcoding.slack.com\/team\/U013ZLJARC7",
                "author_icon": "https:\/\/secure.gravatar.com\/avatar\/f4ae9e5b29386489b18b3bc6b1f41a22.jpg?s=48&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-48.png",
                "mrkdwn_in": [
                    "text"
                ],
                "id": 1,
                "original_url": "https:\/\/futureofcoding.slack.com\/archives\/CCL5VVBAN\/p1624520177117600",
                "footer": "Thread in #share-your-work"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "KUk7",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Took longer than expected because we tied the announcement into a conference talk, but here's the first part of the work I mentioned above "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face"
                            },
                            {
                                "type": "text",
                                "text": "  "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/futureofcoding.slack.com\/archives\/CCL5VVBAN\/p1624520177117600"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1613053771.151300",
        "parent_user_id": "UF5PAGQQ4",
        "reactions": [
            {
                "name": "pray",
                "users": [
                    "UF5PAGQQ4"
                ],
                "count": 1
            },
            {
                "name": "heart",
                "users": [
                    "UF5PAGQQ4"
                ],
                "count": 1
            }
        ]
    }
]