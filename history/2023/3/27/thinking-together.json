[
    {
        "client_msg_id": "f6c5c68b-63a7-4b04-b17f-07a4542bd0fa",
        "type": "message",
        "text": "Here's my perspective on LLMs and the future of programming.\n\nI don't believe that the introduction of LLMs that can write code is going to obviate programming. And I don't believe that it is now pointless to develop new programming languages. Instead, I think LLMs are going to make programming and FoC research _better_, by automating one of the least interesting parts of programming: fiddling with the minutiae of syntax, language constructs, and libraries.\n\nI think programmers will still have plenty of work to do. The profession is not doomed. But to justify this, we have to take a step back and consider all of the activities involved in programming.\n\nFirstly, what is a \"program\"? A program is nothing more than:\n\u2022 _A formal specification_ of the behaviour of an interactive system\n\u2022 ...that computer hardware can execute (after translating it into machine code).\nTo emphasise this, I will use the term \"formal spec\" in place of \"program\" for the remainder of this discussion.\n\nGPT-4 can understand formal specs, and also everyday English. Thus, if we can describe the functionality of a system in everyday English, GPT-4 can (attempt to) translate it into a formal spec. But writing the formal spec is just _one_ activity of programming.\n\nAltogether, programming (or perhaps \"software development\") involves several activities:\n1. Determining what functionality the system being developed \"should\" have. This is done either by talking with relevant stakeholders (e.g. the future users), or by directly observing deficiencies with their current practices.\n2. Expressing that functionality as a formal specification, i.e. \"coding\".\n3. Verifying that the specification correctly implements all of the functionality of step 1. This includes practices such as reading and reviewing the specification, as well as testing the software.\n4. Validating that the implemented functionality addresses the stakeholder's problems.\n5. Repeating the first 4 steps until the stakeholders are satisfied with what has been developed.\nHere's my hypothesis: *In the next 10 years, LLMs might radically reduce the amount of work required for step 2, but _only_ step 2.*\n\nSteps 1 and 4 are very human-centered, and thus can't be automated away \u2014 at least until we are at the point where we have an omnipresent AGI that observes all human practices and automatically develops solutions to improve them.\n\nSimilarly, step 3 will not be automated any time soon, because:\n\u2022 The plain English descriptions that we give to LLMs will often be ambiguous, underspecified, and maybe even inconsistent. Thus the LLMs will have to make educated _guesses_ at what we mean. (Even if they are able to ask clarifying questions, there will always be _some_ choices that are automatically made for us.)\n\u2022 LLMs will occasionally get confused or misinterpret what we say, even if we are clear and careful. We will not have _infallible_ AIs any time soon.\nSo let's assume that LLMs can automate most of step 2. What does this mean for those of us developing tools and technologies to improve programming? Is our work obsolete now? Will the AI researchers and AI startups be taking the reigns?\n\nI don't think so! There is still a huge opportunity to develop tools that address step 3, at the very least. (Steps 1 and 4 are harder to address with technology.)\n\nIn particular, *step 3 involves the task of _reading_ source code*. When an LLM spits out 1000 lines of JavaScript, how do you know that the code implements the functionality that you wanted? You have to _verify_ that it does, and for large programs, that will be an enormous amount of work!\n\nAs we all know, no amount of testing can prove that a program is correct. Thus, we cannot verify AI-generated programs just by _using_ them. Maybe the program has a subtle bug, such as a buffer overflow, that might only be triggered 5 years after the program is deployed. Or less insidiously: maybe the program just doesn't handle certain edge-cases in the way you would like it to. Either way, a human should probably read through the entire program with a keen eye, to check that all of the logic _makes sense_.\n\nThere's clearly an opportunity for FoC researchers here: we can make languages and tools that make _reading_ and _verifying_ the behaviour of programs easier! Some examples:\n\u2022 We can design programming languages that are vastly easier to _read_ than traditional languages. How might we do that? Well, \"higher-level\" languages are likely easier to read, since they are likely to be more concise and focus on the end-user functionality. So work on higher-level programming models will continue to be valuable. To complement this, we can (and IMO, we should) invent new syntaxes that are closer to plain English, such that the specifications that LLMs produce are accessible to a wider audience.\n\u2022 We can design programming languages where it is harder to write erroneous programs. For example, we can design programming languages that cannot crash or hang (i.e. Turing-incomplete languages), but which are still general-purpose. This reduces the kinds of errors that a human needs to consider as they verify a program.\n\u2022 We can design better tools for reading and interrogating source code. (For example, better IDE support for navigating and understanding the structure of large codebases.)\n\u2022 We can design better tools for exploring the space of behaviours of a running program. (Perhaps similar to the tools discussed in Bret Victor's <http://worrydream.com/#!2/LadderOfAbstraction|\"Ladder of Abstraction\"> essay.)\nOverall, I think the future is bright! I'm going to continue my own PL research project (a very high-level language) with as much vigor as ever.",
        "user": "UCGAK10LS",
        "ts": "1679892669.316079",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "HQR0r",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Here's my perspective on LLMs and the future of programming.\n\nI don't believe that the introduction of LLMs that can write code is going to obviate programming. And I don't believe that it is now pointless to develop new programming languages. Instead, I think LLMs are going to make programming and FoC research "
                            },
                            {
                                "type": "text",
                                "text": "better",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ", by automating one of the least interesting parts of programming: fiddling with the minutiae of syntax, language constructs, and libraries.\n\nI think programmers will still have plenty of work to do. The profession is not doomed. But to justify this, we have to take a step back and consider all of the activities involved in programming.\n\nFirstly, what is a \"program\"? A program is nothing more than:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "A formal specification",
                                        "style": {
                                            "italic": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " of the behaviour of an interactive system"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "...that computer hardware can execute (after translating it into machine code)."
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nTo emphasise this, I will use the term \"formal spec\" in place of \"program\" for the remainder of this discussion.\n\nGPT-4 can understand formal specs, and also everyday English. Thus, if we can describe the functionality of a system in everyday English, GPT-4 can (attempt to) translate it into a formal spec. But writing the formal spec is just "
                            },
                            {
                                "type": "text",
                                "text": "one",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " activity of programming.\n\nAltogether, programming (or perhaps \"software development\") involves several activities:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Determining what functionality the system being developed \"should\" have. This is done either by talking with relevant stakeholders (e.g. the future users), or by directly observing deficiencies with their current practices."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Expressing that functionality as a formal specification, i.e. \"coding\"."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Verifying that the specification correctly implements all of the functionality of step 1. This includes practices such as reading and reviewing the specification, as well as testing the software."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Validating that the implemented functionality addresses the stakeholder's problems."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Repeating the first 4 steps until the stakeholders are satisfied with what has been developed."
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nHere's my hypothesis: "
                            },
                            {
                                "type": "text",
                                "text": "In the next 10 years, LLMs might radically reduce the amount of work required for step 2, but ",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "only",
                                "style": {
                                    "bold": true,
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " step 2.",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n\nSteps 1 and 4 are very human-centered, and thus can't be automated away \u2014 at least until we are at the point where we have an omnipresent AGI that observes all human practices and automatically develops solutions to improve them.\n\nSimilarly, step 3 will not be automated any time soon, because:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "The plain English descriptions that we give to LLMs will often be ambiguous, underspecified, and maybe even inconsistent. Thus the LLMs will have to make educated "
                                    },
                                    {
                                        "type": "text",
                                        "text": "guesses",
                                        "style": {
                                            "italic": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " at what we mean. (Even if they are able to ask clarifying questions, there will always be "
                                    },
                                    {
                                        "type": "text",
                                        "text": "some",
                                        "style": {
                                            "italic": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " choices that are automatically made for us.)"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "LLMs will occasionally get confused or misinterpret what we say, even if we are clear and careful. We will not have "
                                    },
                                    {
                                        "type": "text",
                                        "text": "infallible",
                                        "style": {
                                            "italic": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " AIs any time soon."
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nSo let's assume that LLMs can automate most of step 2. What does this mean for those of us developing tools and technologies to improve programming? Is our work obsolete now? Will the AI researchers and AI startups be taking the reigns?\n\nI don't think so! There is still a huge opportunity to develop tools that address step 3, at the very least. (Steps 1 and 4 are harder to address with technology.)\n\nIn particular, "
                            },
                            {
                                "type": "text",
                                "text": "step 3 involves the task of ",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "reading",
                                "style": {
                                    "bold": true,
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " source code",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ". When an LLM spits out 1000 lines of JavaScript, how do you know that the code implements the functionality that you wanted? You have to "
                            },
                            {
                                "type": "text",
                                "text": "verify",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " that it does, and for large programs, that will be an enormous amount of work!\n\nAs we all know, no amount of testing can prove that a program is correct. Thus, we cannot verify AI-generated programs just by "
                            },
                            {
                                "type": "text",
                                "text": "using",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " them. Maybe the program has a subtle bug, such as a buffer overflow, that might only be triggered 5 years after the program is deployed. Or less insidiously: maybe the program just doesn't handle certain edge-cases in the way you would like it to. Either way, a human should probably read through the entire program with a keen eye, to check that all of the logic "
                            },
                            {
                                "type": "text",
                                "text": "makes sense",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ".\n\nThere's clearly an opportunity for FoC researchers here: we can make languages and tools that make "
                            },
                            {
                                "type": "text",
                                "text": "reading",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " and "
                            },
                            {
                                "type": "text",
                                "text": "verifying",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " the behaviour of programs easier! Some examples:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "We can design programming languages that are vastly easier to "
                                    },
                                    {
                                        "type": "text",
                                        "text": "read",
                                        "style": {
                                            "italic": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " than traditional languages. How might we do that? Well, \"higher-level\" languages are likely easier to read, since they are likely to be more concise and focus on the end-user functionality. So work on higher-level programming models will continue to be valuable. To complement this, we can (and IMO, we should) invent new syntaxes that are closer to plain English, such that the specifications that LLMs produce are accessible to a wider audience."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "We can design programming languages where it is harder to write erroneous programs. For example, we can design programming languages that cannot crash or hang (i.e. Turing-incomplete languages), but which are still general-purpose. This reduces the kinds of errors that a human needs to consider as they verify a program."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "We can design better tools for reading and interrogating source code. (For example, better IDE support for navigating and understanding the structure of large codebases.)"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "We can design better tools for exploring the space of behaviours of a running program. (Perhaps similar to the tools discussed in Bret Victor's "
                                    },
                                    {
                                        "type": "link",
                                        "url": "http://worrydream.com/#!2/LadderOfAbstraction",
                                        "text": "\"Ladder of Abstraction\""
                                    },
                                    {
                                        "type": "text",
                                        "text": " essay.)"
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nOverall, I think the future is bright! I'm going to continue my own PL research project (a very high-level language) with as much vigor as ever."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UCGAK10LS",
            "ts": "1679895554.000000"
        },
        "thread_ts": "1679892669.316079",
        "reply_count": 17,
        "reply_users_count": 7,
        "latest_reply": "1680218359.116989",
        "reply_users": [
            "UA14TGLTC",
            "UCGAK10LS",
            "U0296ACR13M",
            "U0112C10V4Y",
            "UNCP67JSK",
            "U04MTMF6Y4W",
            "UE6EFEPTQ"
        ],
        "is_locked": false,
        "subscribed": false,
        "reactions": [
            {
                "name": "100",
                "users": [
                    "UA14TGLTC",
                    "U0245E9RB2B",
                    "U0296ACR13M",
                    "U04E5QAD6DD",
                    "UC2A2ARPT"
                ],
                "count": 5
            },
            {
                "name": "sparkle",
                "users": [
                    "U04MTMF6Y4W"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "8f0f8fe3-036c-468a-8b9e-01a49c1ae845",
        "type": "message",
        "text": "Arguably with \"coding\" (2) assisted/automated, we can get on to the future part!  Certainly people are playing with (3), getting Chat to output Agda code for example.  But the simple fact is that if \"getting it working\" becomes easier, then we actually give attention to \"get it right.\"   I can also see AI potentially helping with the communication challenges of (4).",
        "user": "UA14TGLTC",
        "ts": "1679896298.612939",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Q8cY",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Arguably with \"coding\" (2) assisted/automated, we can get on to the future part!  Certainly people are playing with (3), getting Chat to output Agda code for example.  But the simple fact is that if \"getting it working\" becomes easier, then we actually give attention to \"get it right.\"   I can also see AI potentially helping with the communication challenges of (4)."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UCGAK10LS",
                    "U03JUAWDVSR"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "093293c2-033e-4429-a799-29b5f4a72aee",
        "type": "message",
        "text": "Your mention of Agda has me wanting to define the notion of \"verification\" a little more carefully. (I'm just thinking aloud here.)\n\nAgda and friends are often described as languages for writing \"verified programs\", but that term makes me uncomfortable, because it's prone to be misunderstood. (At the very least, it confused younger me.) No programming language can verify that the functionality a programmer desires has been implemented correctly. No programming language can _ever_ do that. The programmer can always specify a valid program that is different to the one they had _intended_ to specify, and the computer will happily accept it.\n\nThe best you can do is to ask the computer to verify that your program has a _particular_ property, e.g. \"this variable is never null\" or \"this program doesn't crash\". That's a merit of static typing in general.\n\nBut back to your comment: Yes I agree, Agda makes it easier for humans to verify LLM-generated code by reducing the kinds of errors that a program can have. It achieves this by having an expressive type system that can reject a lot of invalid programs. :slightly_smiling_face:\n\n(IMO, Agda's type system is too complicated for the average programmer. But I wholeheartedly believe that developing languages with expressive type systems is a worthy goal.)",
        "user": "UCGAK10LS",
        "ts": "1679896811.824169",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "RjFkO",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Your mention of Agda has me wanting to define the notion of \"verification\" a little more carefully. (I'm just thinking aloud here.)\n\nAgda and friends are often described as languages for writing \"verified programs\", but that term makes me uncomfortable, because it's prone to be misunderstood. (At the very least, it confused younger me.) No programming language can verify that the functionality a programmer desires has been implemented correctly. No programming language can "
                            },
                            {
                                "type": "text",
                                "text": "ever",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " do that. The programmer can always specify a valid program that is different to the one they had "
                            },
                            {
                                "type": "text",
                                "text": "intended",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " to specify, and the computer will happily accept it.\n\nThe best you can do is to ask the computer to verify that your program has a "
                            },
                            {
                                "type": "text",
                                "text": "particular",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " property, e.g. \"this variable is never null\" or \"this program doesn't crash\". That's a merit of static typing in general.\n\nBut back to your comment: Yes I agree, Agda makes it easier for humans to verify LLM-generated code by reducing the kinds of errors that a program can have. It achieves this by having an expressive type system that can reject a lot of invalid programs. "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face",
                                "unicode": "1f642"
                            },
                            {
                                "type": "text",
                                "text": "\n\n(IMO, Agda's type system is too complicated for the average programmer. But I wholeheartedly believe that developing languages with expressive type systems is a worthy goal.)"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UCGAK10LS",
            "ts": "1679899023.000000"
        },
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "6a34bf5e-303f-4ff0-a86d-119ba55831ef",
        "type": "message",
        "text": "Most of the software development work is maintaining large codebases and I'd say it's still largely unproven that LLMs can offer much help in these settings. Currently the limiting factors are at least the allowed input sizes and the cost and speed of the queries. It seems that iterating on large codebases would be very slow and difficult. Overtime, it's of course very likely that these issues will be solved, but hard to say if it will take two years or twenty years.\n\nI think LLMs will certainly increase the productivity of software development and therefore make it cheaper. This will lead into software becoming economical in more use cases, so the demand for software will increase. Hard to say how this will balance out with the increase in the supply from the productivity increase. But it could also be that LLMs increase the demand for software developers, which could in turn increase the market opportunity for FoC tools.\n\nAnd as discussed, generating traditional code with LLMs still, at the very least, requires professional programming skills to verify the output. A (good) low/no-code tool would not.",
        "user": "U0296ACR13M",
        "ts": "1679897153.979009",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "b1C",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Most of the software development work is maintaining large codebases and I'd say it's still largely unproven that LLMs can offer much help in these settings. Currently the limiting factors are at least the allowed input sizes and the cost and speed of the queries. It seems that iterating on large codebases would be very slow and difficult. Overtime, it's of course very likely that these issues will be solved, but hard to say if it will take two years or twenty years.\n\nI think LLMs will certainly increase the productivity of software development and therefore make it cheaper. This will lead into software becoming economical in more use cases, so the demand for software will increase. Hard to say how this will balance out with the increase in the supply from the productivity increase. But it could also be that LLMs increase the demand for software developers, which could in turn increase the market opportunity for FoC tools.\n\nAnd as discussed, generating traditional code with LLMs still, at the very least, requires professional programming skills to verify the output. A (good) low/no-code tool would not."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "U0296ACR13M",
            "ts": "1679897885.000000"
        },
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UCGAK10LS"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "700ef05e-3cb4-44f0-9b4b-0e4ee65e64ac",
        "type": "message",
        "text": "But of course, if a LLM already performs better in the use case, and for the audience of your foc tool, it's probably a good idea to pivot.. You could still try to compete with price, but it's difficult to say what will the price of LLM queries be in a year.",
        "user": "U0296ACR13M",
        "ts": "1679898374.858229",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "zAa",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "But of course, if a LLM already performs better in the use case, and for the audience of your foc tool, it's probably a good idea to pivot.. You could still try to compete with price, but it's difficult to say what will the price of LLM queries be in a year."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "f4e09a8c-b02f-4cf5-aec4-31e39b1361c4",
        "type": "message",
        "text": "On the heels of the \"LLMs and the future of programming\" discussion (<https://futureofcoding.slack.com/archives/C5T9GPWFL/p1679642239661619>, <https://futureofcoding.slack.com/archives/C5T9GPWFL/p1679892669316079>), I'd like to start a more concentrated discussion around their effect on Future of Coding projects. There was already some sentiment that LLMs are going to kill FoC projects. Some yes, but certainly not all. So what kind of FoC projects LLMs will not kill?",
        "user": "U0296ACR13M",
        "ts": "1679902227.016569",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Vvnq",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "On the heels of the \"LLMs and the future of programming\" discussion ("
                            },
                            {
                                "type": "link",
                                "url": "https://futureofcoding.slack.com/archives/C5T9GPWFL/p1679642239661619"
                            },
                            {
                                "type": "text",
                                "text": ", "
                            },
                            {
                                "type": "link",
                                "url": "https://futureofcoding.slack.com/archives/C5T9GPWFL/p1679892669316079"
                            },
                            {
                                "type": "text",
                                "text": "), I'd like to start a more concentrated discussion around their effect on Future of Coding projects. There was already some sentiment that LLMs are going to kill FoC projects. Some yes, but certainly not all. So what kind of FoC projects LLMs will not kill?"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "U0296ACR13M",
            "ts": "1679904038.000000"
        },
        "thread_ts": "1679902227.016569",
        "reply_count": 4,
        "reply_users_count": 2,
        "latest_reply": "1679982547.990119",
        "reply_users": [
            "U0296ACR13M",
            "UCGAK10LS"
        ],
        "is_locked": false,
        "subscribed": false
    },
    {
        "client_msg_id": "9e75b372-2579-40f1-872b-c6a7eb7d9ba0",
        "type": "message",
        "text": "To kick off the discussion I did the only logical thing and asked ChatGPT.\n\n_what are the strengths of low-code and no-code tools against programming with the help of an LLM?_:\n\n`Low-code and no-code tools, as well as Language Models (LLMs) like GPT-4, each have their own strengths in software development. Here, we will focus on the strengths of low-code and no-code tools when compared to programming with the help of an LLM.`\n1. `Accessibility: Low-code and no-code platforms are designed to be accessible to non-technical users, enabling more people to create software applications without needing extensive programming knowledge. LLMs, while powerful, still require a basic understanding of programming concepts to be used effectively.`\n2. `Visual Interface: Low-code and no-code tools often provide a visual, drag-and-drop interface, making it easy to design applications and see the structure of the application. This can be more intuitive than using an LLM, which generally requires text-based communication and code editing.`\n3. `Standardization: Low-code and no-code platforms typically enforce standardized coding practices and patterns, which can result in more maintainable and organized code. On the other hand, LLMs might generate code with different styles and conventions depending on the input.`\n4. `Integration: Low-code and no-code platforms often provide pre-built integrations with popular services, databases, and APIs. While LLMs can also help generate code to interact with various services, they might require more manual work to integrate and configure the connections.`\n5. `Speed of Development: Low-code and no-code tools can significantly speed up the development process, as they automate repetitive tasks and allow users to focus on the overall application design. LLMs can also speed up development, but the improvement might not be as dramatic, especially for simpler applications.`\n6. `Collaboration: Low-code and no-code platforms often have built-in collaboration features, allowing multiple team members to work on the same project simultaneously. While it's possible to collaborate using LLMs, it might not be as streamlined as using dedicated low-code/no-code tools.`\n7. `Predictability: Low-code and no-code platforms provide a more predictable development environment, as they consist of predefined components and actions. LLMs can sometimes generate unexpected or inconsistent code, depending on the input and training data.`\n`While low-code and no-code tools have these strengths, it's important to remember that they also have limitations, such as less flexibility in terms of customization, and potential issues with scaling or performance. The choice between using low-code/no-code tools and an LLM depends on the specific project requirements, the technical expertise of the team, and the desired level of customization.`\n\n_How about if we expand the scope to the whole process of software development_\n\n`Expanding the scope to the entire software development process allows us to compare low-code/no-code tools and LLMs across various aspects of the development lifecycle. The following comparison highlights the strengths of low-code/no-code tools in the broader context of software development.`\n1. `Requirement gathering and prototyping: Low-code/no-code platforms excel at quickly creating prototypes and mockups, which can help in gathering and refining requirements. LLMs can be used for generating code snippets, but they might not provide a complete solution for creating interactive prototypes.`\n2. `Development and implementation: Low-code/no-code tools can speed up the development process by automating repetitive tasks and providing pre-built components. However, they may lack the flexibility needed for highly customized or complex applications. LLMs can help generate code, but developers still need to manage the overall application structure and logic.`\n3. `Testing: Low-code/no-code platforms often include built-in testing tools or features, making it easy to validate the application's functionality. While LLMs can help generate test cases or test code, they are not a complete solution for software testing.`\n4. `Deployment and maintenance: Low-code/no-code platforms usually have straightforward deployment and maintenance processes, often with built-in support for continuous integration and delivery. LLMs can help automate parts of the deployment process, but developers still need to manage the overall infrastructure and maintenance.`\n5. `Documentation: Low-code/no-code tools often automatically generate documentation based on the application's structure and components. LLMs can be used to generate code comments or external documentation, but they might require more manual effort to ensure that the documentation is accurate and comprehensive.`\n6. `Collaboration and project management: Low-code/no-code platforms often include collaboration and project management features, allowing teams to work together more efficiently. While LLMs can be used in a collaborative context, they may not provide the same level of support for project management.`\n7. `Training and onboarding: Low-code/no-code tools generally have a lower learning curve, enabling new team members to become productive more quickly. LLMs can be helpful for generating code samples or answering programming-related questions, but they might not be as effective for onboarding new developers who are not familiar with programming concepts.`\n`While low-code and no-code tools have these strengths in the software development process, they also have limitations. For example, they might not be suitable for highly customized applications or for situations where performance is critical. Moreover, they might result in vendor lock-in, which can limit flexibility and long-term scalability.`\n`Ultimately, the choice between using low-code/no-code tools and an LLM depends on the specific project requirements, the technical expertise of the team, and the desired level of customization and flexibility. In some cases, a combination of low-code/no-code tools and LLMs might be the most effective approach to software development.`\n\n_so, if I'm working on a low-code/no-code tool and I'm worried that LLMs will make the tool obsolete or significantly decrease it's market potential, what should I concentrate on?_\n\n`If you're working on a low-code/no-code tool and concerned about the impact of LLMs on your market potential, you should focus on several aspects that can help differentiate your product and provide value to users beyond what an LLM can offer:`\n1. `User Experience: Create a user-friendly, intuitive, and visually appealing interface that makes it easy for users to build applications without prior programming knowledge. This will help your tool stand out from LLM-based solutions, which often require more programming expertise to use effectively.`\n2. `Integrations and Ecosystem: Offer seamless integrations with popular third-party services, databases, and APIs. By providing a rich ecosystem of pre-built connectors and integrations, you can save users time and effort, making your tool more attractive than working with LLMs alone.`\n3. `Collaboration Features: Build in features that facilitate collaboration and communication among team members, making it easier for them to work together on projects. This can provide a significant advantage over LLMs, which may not inherently support collaborative development.`\n4. `Customization and Extensibility: While low-code/no-code tools are often associated with less flexibility, you can differentiate your product by offering customization options and extensibility features that cater to various use cases and industries. This could include allowing users to create custom components, use scripting languages, or integrate with external code.`\n5. `Education and Support: Provide comprehensive documentation, tutorials, and support to help users get the most out of your tool. By offering exceptional customer service and resources, you can create a loyal user base and distinguish your product from LLM-based solutions.`\n6. `Performance and Scalability: Focus on optimizing your platform for performance and scalability, ensuring that it can handle the demands of larger and more complex applications. This will help attract users who require high-performance solutions that might not be achievable with LLM-generated code.`\n7. `Security and Compliance: Address security and compliance concerns by incorporating features that ensure data privacy, secure user authentication, and adherence to industry-specific regulations. This can be an essential differentiator for customers in regulated industries.`\n8. `Target Niche Markets: Identify specific industries or use cases where your low-code/no-code tool can provide unique value, and tailor your features and marketing efforts towards those niches. By becoming a specialized solution, you can carve out a market segment less affected by LLMs.`\n9. `Community Building: Foster a community around your low-code/no-code tool, encouraging users to share their experiences, tips, and best practices. A strong community can help drive user adoption and increase your product's visibility.`\n`By focusing on these aspects, you can create a competitive low-code/no-code tool that offers value beyond what an LLM can provide, ensuring that your product remains relevant and successful in the market.`\n\nI would like to add that programming using LLMs still suffers from all of the possible pain points of the chosen programming language, beyond the act of writing code. Such as debugging experience and compilation or deployment times. This is where live programming tools excel for example.\n\nOf course, some of the LLM weaknesses will be fixed. Which ones will be fixed first? Which ones last or never? Are there niches (user groups, industries or domains) in which the strengths of LLMs don't apply or are decreased? Are there domains in which LLMs can't/will not be utilized for some (political, financial, social, security, emotional, ..) reason?",
        "user": "U0296ACR13M",
        "ts": "1679903697.650859",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "McmA",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "To kick off the discussion I did the only logical thing and asked ChatGPT.\n\n"
                            },
                            {
                                "type": "text",
                                "text": "what are the strengths of low-code and no-code tools against programming with the help of an LLM?",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ":\n\n"
                            },
                            {
                                "type": "text",
                                "text": "Low-code and no-code tools, as well as Language Models (LLMs) like GPT-4, each have their own strengths in software development. Here, we will focus on the strengths of low-code and no-code tools when compared to programming with the help of an LLM.",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Accessibility: Low-code and no-code platforms are designed to be accessible to non-technical users, enabling more people to create software applications without needing extensive programming knowledge. LLMs, while powerful, still require a basic understanding of programming concepts to be used effectively.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Visual Interface: Low-code and no-code tools often provide a visual, drag-and-drop interface, making it easy to design applications and see the structure of the application. This can be more intuitive than using an LLM, which generally requires text-based communication and code editing.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Standardization: Low-code and no-code platforms typically enforce standardized coding practices and patterns, which can result in more maintainable and organized code. On the other hand, LLMs might generate code with different styles and conventions depending on the input.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Integration: Low-code and no-code platforms often provide pre-built integrations with popular services, databases, and APIs. While LLMs can also help generate code to interact with various services, they might require more manual work to integrate and configure the connections.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Speed of Development: Low-code and no-code tools can significantly speed up the development process, as they automate repetitive tasks and allow users to focus on the overall application design. LLMs can also speed up development, but the improvement might not be as dramatic, especially for simpler applications.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Collaboration: Low-code and no-code platforms often have built-in collaboration features, allowing multiple team members to work on the same project simultaneously. While it's possible to collaborate using LLMs, it might not be as streamlined as using dedicated low-code/no-code tools.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Predictability: Low-code and no-code platforms provide a more predictable development environment, as they consist of predefined components and actions. LLMs can sometimes generate unexpected or inconsistent code, depending on the input and training data.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "While low-code and no-code tools have these strengths, it's important to remember that they also have limitations, such as less flexibility in terms of customization, and potential issues with scaling or performance. The choice between using low-code/no-code tools and an LLM depends on the specific project requirements, the technical expertise of the team, and the desired level of customization.",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n\n"
                            },
                            {
                                "type": "text",
                                "text": "How about if we expand the scope to the whole process of software development",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n\n"
                            },
                            {
                                "type": "text",
                                "text": "Expanding the scope to the entire software development process allows us to compare low-code/no-code tools and LLMs across various aspects of the development lifecycle. The following comparison highlights the strengths of low-code/no-code tools in the broader context of software development.",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Requirement gathering and prototyping: Low-code/no-code platforms excel at quickly creating prototypes and mockups, which can help in gathering and refining requirements. LLMs can be used for generating code snippets, but they might not provide a complete solution for creating interactive prototypes.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Development and implementation: Low-code/no-code tools can speed up the development process by automating repetitive tasks and providing pre-built components. However, they may lack the flexibility needed for highly customized or complex applications. LLMs can help generate code, but developers still need to manage the overall application structure and logic.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Testing: Low-code/no-code platforms often include built-in testing tools or features, making it easy to validate the application's functionality. While LLMs can help generate test cases or test code, they are not a complete solution for software testing.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Deployment and maintenance: Low-code/no-code platforms usually have straightforward deployment and maintenance processes, often with built-in support for continuous integration and delivery. LLMs can help automate parts of the deployment process, but developers still need to manage the overall infrastructure and maintenance.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Documentation: Low-code/no-code tools often automatically generate documentation based on the application's structure and components. LLMs can be used to generate code comments or external documentation, but they might require more manual effort to ensure that the documentation is accurate and comprehensive.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Collaboration and project management: Low-code/no-code platforms often include collaboration and project management features, allowing teams to work together more efficiently. While LLMs can be used in a collaborative context, they may not provide the same level of support for project management.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Training and onboarding: Low-code/no-code tools generally have a lower learning curve, enabling new team members to become productive more quickly. LLMs can be helpful for generating code samples or answering programming-related questions, but they might not be as effective for onboarding new developers who are not familiar with programming concepts.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "While low-code and no-code tools have these strengths in the software development process, they also have limitations. For example, they might not be suitable for highly customized applications or for situations where performance is critical. Moreover, they might result in vendor lock-in, which can limit flexibility and long-term scalability.",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "text",
                                "text": "Ultimately, the choice between using low-code/no-code tools and an LLM depends on the specific project requirements, the technical expertise of the team, and the desired level of customization and flexibility. In some cases, a combination of low-code/no-code tools and LLMs might be the most effective approach to software development.",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n\n"
                            },
                            {
                                "type": "text",
                                "text": "so, if I'm working on a low-code/no-code tool and I'm worried that LLMs will make the tool obsolete or significantly decrease it's market potential, what should I concentrate on?",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n\n"
                            },
                            {
                                "type": "text",
                                "text": "If you're working on a low-code/no-code tool and concerned about the impact of LLMs on your market potential, you should focus on several aspects that can help differentiate your product and provide value to users beyond what an LLM can offer:",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "User Experience: Create a user-friendly, intuitive, and visually appealing interface that makes it easy for users to build applications without prior programming knowledge. This will help your tool stand out from LLM-based solutions, which often require more programming expertise to use effectively.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Integrations and Ecosystem: Offer seamless integrations with popular third-party services, databases, and APIs. By providing a rich ecosystem of pre-built connectors and integrations, you can save users time and effort, making your tool more attractive than working with LLMs alone.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Collaboration Features: Build in features that facilitate collaboration and communication among team members, making it easier for them to work together on projects. This can provide a significant advantage over LLMs, which may not inherently support collaborative development.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Customization and Extensibility: While low-code/no-code tools are often associated with less flexibility, you can differentiate your product by offering customization options and extensibility features that cater to various use cases and industries. This could include allowing users to create custom components, use scripting languages, or integrate with external code.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Education and Support: Provide comprehensive documentation, tutorials, and support to help users get the most out of your tool. By offering exceptional customer service and resources, you can create a loyal user base and distinguish your product from LLM-based solutions.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Performance and Scalability: Focus on optimizing your platform for performance and scalability, ensuring that it can handle the demands of larger and more complex applications. This will help attract users who require high-performance solutions that might not be achievable with LLM-generated code.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Security and Compliance: Address security and compliance concerns by incorporating features that ensure data privacy, secure user authentication, and adherence to industry-specific regulations. This can be an essential differentiator for customers in regulated industries.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Target Niche Markets: Identify specific industries or use cases where your low-code/no-code tool can provide unique value, and tailor your features and marketing efforts towards those niches. By becoming a specialized solution, you can carve out a market segment less affected by LLMs.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Community Building: Foster a community around your low-code/no-code tool, encouraging users to share their experiences, tips, and best practices. A strong community can help drive user adoption and increase your product's visibility.",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "By focusing on these aspects, you can create a competitive low-code/no-code tool that offers value beyond what an LLM can provide, ensuring that your product remains relevant and successful in the market.",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n\nI would like to add that programming using LLMs still suffers from all of the possible pain points of the chosen programming language, beyond the act of writing code. Such as debugging experience and compilation or deployment times. This is where live programming tools excel for example.\n\nOf course, some of the LLM weaknesses will be fixed. Which ones will be fixed first? Which ones last or never? Are there niches (user groups, industries or domains) in which the strengths of LLMs don't apply or are decreased? Are there domains in which LLMs can't/will not be utilized for some (political, financial, social, security, emotional, ..) reason?"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679902227.016569",
        "parent_user_id": "U0296ACR13M"
    },
    {
        "client_msg_id": "9A64F82D-6ED4-4E29-B293-5E891ED552A6",
        "type": "message",
        "text": "Has anyone tried to square \u201ccomputing is a metamedium\u201d (able to simulate all other mediums) with \u201cmedium is the message\u201d school? I can think of a number of places where existing mediums can\u2019t be emulated by a computer. But curious where people might say that\u2019s an inherent limit vs a stage of expression computers have not yet reached (I think probably a mix of both). Is thinking there\u2019s a limit \u201cbad\u201d if you are interested in the Future of Coding or does it help in some way with maximizing on strengths?",
        "user": "U04MTMF6Y4W",
        "ts": "1679927549.898479",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "+jT",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Has anyone tried to square \u201ccomputing is a metamedium\u201d (able to simulate all other mediums) with \u201cmedium is the message\u201d school? I can think of a number of places where existing mediums "
                            },
                            {
                                "type": "text",
                                "text": "can\u2019t"
                            },
                            {
                                "type": "text",
                                "text": " be emulated by a computer. But curious where people might say "
                            },
                            {
                                "type": "text",
                                "text": "that\u2019s"
                            },
                            {
                                "type": "text",
                                "text": " an inherent limit vs a stage of expression computers have not yet reached (I think probably a mix of both). Is thinking "
                            },
                            {
                                "type": "text",
                                "text": "there\u2019s"
                            },
                            {
                                "type": "text",
                                "text": " a limit \u201cbad\u201d if you are interested in the Future of Coding or does it help in some way with maximizing on strengths?"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679927549.898479",
        "reply_count": 10,
        "reply_users_count": 2,
        "latest_reply": "1680196155.914259",
        "reply_users": [
            "UE6EFEPTQ",
            "U04MTMF6Y4W"
        ],
        "is_locked": false,
        "subscribed": false,
        "reactions": [
            {
                "name": "joy",
                "users": [
                    "U03JUAWDVSR"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "d0443f66-897d-4ce0-8402-0ce6f70750c5",
        "type": "message",
        "text": "Why can't an AI skip the intermediate step and just output direct machine code? After all, do you verify what your compiler is spitting out?",
        "user": "U0112C10V4Y",
        "ts": "1679929542.004789",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "30S",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Why can't an AI skip the intermediate step and just output direct machine code? After all, do you verify what your compiler is spitting out?"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "ed808f00-7d46-45f8-af6f-9b8bf6faa722",
        "type": "message",
        "text": "People are still thinking in terms of the old paradigm of write, compile, run program. But a computer system where you can interact with an AI that is able to directly access input and output pretty much removes the need for any sort of programming. Programming is in the end a roundabout way of getting a computer to perform some action/compute some result.",
        "user": "U0112C10V4Y",
        "ts": "1679929692.502719",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "kExBR",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "People are still thinking in terms of the old paradigm of write, compile, run program. But a computer system where you can interact with an AI that is able to directly access input and output pretty much removes the need for any sort of programming. Programming is in the end a roundabout way of getting a computer to perform some action/compute some result."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "28E4201F-A908-4B68-812A-E8C2A3BC9362",
        "type": "message",
        "text": "gpt4 excerpt:\n&gt;&gt; LLMs for bridging the gap between domain experts and developers: LLMs can help facilitate communication between domain experts and developers by translating domain-specific requirements into programming constructs or even generating code prototypes. This can reduce miscommunications and speed up the development process, especially for interdisciplinary projects.",
        "user": "UNCP67JSK",
        "ts": "1679936905.902369",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "oeRyZ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "gpt4 excerpt:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "LLMs for bridging the gap between domain experts and developers: LLMs can help facilitate communication between domain experts and developers by translating domain-specific requirements into programming constructs or even generating code prototypes. This can reduce miscommunications and speed up the development process, especially for interdisciplinary projects."
                            }
                        ],
                        "border": 1
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "7AA6A812-5700-4D5E-9600-5BEE061E4497",
        "type": "message",
        "text": "<@UCGAK10LS> LLM's is now an essential component in most tools for thoughts; the interface and information organization/representation (eg. higher order language, pkm/graph, etc) to facilitate both the LLM-tft side and the tft-human side is still up for a huuuge improvement. Feeling pretty good about working just in that zone :)) ",
        "user": "UNCP67JSK",
        "ts": "1679937330.895309",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "RsP8P",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UCGAK10LS"
                            },
                            {
                                "type": "text",
                                "text": " LLM's is now an essential component in most tools for thoughts; the interface and information organization/representation (eg. higher order language, pkm/graph, etc) to facilitate both the LLM-tft side and the tft-human side is still up for a huuuge improvement. Feeling pretty good about working just in that zone :)) "
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS",
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "UCGAK10LS"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "F2850C2A-B770-4BEB-BFF0-F835FD6DF125",
        "type": "message",
        "text": "Porting my reply from <@U0296ACR13M> \u2018s question to build of what was already said here. I think there\u2019s broadly two categories of software \u201cconsumer\u201d, adapters and users. Users want it to just work and adapters are interested in how. Maybe we could even map it to wanting the right thing vs worse is better. For users LLMs could be a more natural interface to existing tools, APIs, automation. There the question might be, \u201cIs this a better interface than what you get from other methods of interaction?\u201d Sometimes?\n\nFor adapters, visibility and clarity are as important as the end product. As far as I\u2019ve seen, using prompts to program a system builds a different skill from doing it manually . Similar to using an existing library or hiring a developer you abstract the process by outsourcing to a third-party. If that\u2019s valuable depends on what the task is. But good abstraction, comes from being able to peel that back if needed. With current AI tools the person writing is also responsible for defining those layers. So speed could improve, but required skill would still be similar.\n\nPessimist take: Tooling tailored to AI programming seems more likely than them using existing ones. Historically that means a split, probably with more mainstream effort on the AI language side. But people tend to do this a lot: cities rebuilt for cars, modern assembly areas are too dangerous to walk around, optimized javascript limits view source\u2019s benefits. Billion dollar SaaS black box as the best option for improving usability of existing tools software seems like digging deeper into present coding\u2019s problems.",
        "user": "U04MTMF6Y4W",
        "ts": "1679941681.352839",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Vk7A7",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Porting my reply from "
                            },
                            {
                                "type": "user",
                                "user_id": "U0296ACR13M"
                            },
                            {
                                "type": "text",
                                "text": " \u2018s question to build of what was already said here. I think there\u2019s broadly two categories of software \u201cconsumer\u201d, adapters and users. Users want it to just work and adapters are interested in how. Maybe we could even map it to wanting the right thing vs worse is better. For users LLMs could be a more natural interface to existing tools, APIs, automation. There the question might be, \u201cIs this a better interface than what you get from other methods of interaction?\u201d Sometimes?\n\nFor adapters, visibility and clarity are as important as the end product. "
                            },
                            {
                                "type": "text",
                                "text": "As far as I\u2019ve seen, using prompts to program a system builds a different skill from doing it"
                            },
                            {
                                "type": "text",
                                "text": " manually "
                            },
                            {
                                "type": "text",
                                "text": ". Similar to using an "
                            },
                            {
                                "type": "text",
                                "text": "existing"
                            },
                            {
                                "type": "text",
                                "text": " library or "
                            },
                            {
                                "type": "text",
                                "text": "hiring"
                            },
                            {
                                "type": "text",
                                "text": " a developer you abstract the process by outsourcing to a third-party. If that\u2019s valuable depends on what the task is. "
                            },
                            {
                                "type": "text",
                                "text": "But good abstraction, comes from being able to peel that back if needed. With current AI tools the person writing is also responsible for defining those layers. So speed could improve, but required skill would still be similar.\n\nPessimist take: Tooling tailored to AI programming seems more likely than them using existing ones. Historically that means a split, probably with more mainstream effort on the AI language side. But people tend to do this a lot: cities rebuilt for cars, modern assembly areas are too dangerous to walk around, optimized javascript limits view source\u2019s benefits. Billion dollar SaaS black box as the best option for improving usability of existing tools software seems like digging deeper into present coding\u2019s problems."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "0adb6b06-9067-4b07-9881-afae4be146c4",
        "type": "message",
        "text": "The points that ChatGPT produced above are quite reasonable. However, the comparison being made is between:\n\u2022 Low-code/no-code tools\n\u2022 LLMs that generate code in traditional programming languages (e.g. Python code)\nMany of the listed benefits of no-code tools can be hypothetically be achieved through conventional language design as well. For example, the \"opportunities for FoC researchers\" that I listed in my previous <#C5T9GPWFL|thinking-together> post focus on how to make LLM-generated code easier to understand, accessible to a wider audience, and less error-prone. Those qualities (amongst others) are major selling points of low-code/no-code tools. My contention is that we \u2014 as FoC researchers \u2014 can develop new general-purpose programming languages that continue to close the gap between *no-code* and *code* while _embracing_ LLMs as a valuable tool in our tool belt.",
        "user": "UCGAK10LS",
        "ts": "1679958556.634899",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "czL",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The points that ChatGPT produced above are quite reasonable. However, the comparison being made is between:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Low-code/no-code tools"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "LLMs that generate code in traditional programming languages (e.g. Python code)"
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nMany of the listed benefits of no-code tools can be hypothetically be achieved through conventional language design as well. For example, the \"opportunities for FoC researchers\" that I listed in my previous "
                            },
                            {
                                "type": "channel",
                                "channel_id": "C5T9GPWFL"
                            },
                            {
                                "type": "text",
                                "text": " post focus on how to make LLM-generated code easier to understand, accessible to a wider audience, and less error-prone. Those qualities (amongst others) are major selling points of low-code/no-code tools. My contention is that we \u2014 as FoC researchers \u2014 can develop new general-purpose programming languages that continue to close the gap between "
                            },
                            {
                                "type": "text",
                                "text": "no-code",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " and "
                            },
                            {
                                "type": "text",
                                "text": "code",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " while "
                            },
                            {
                                "type": "text",
                                "text": "embracing",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " LLMs as a valuable tool in our tool belt."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679902227.016569",
        "parent_user_id": "U0296ACR13M"
    },
    {
        "client_msg_id": "fcc4b513-4088-4454-a5d1-81cfc70f40bf",
        "type": "message",
        "text": "<@U0112C10V4Y> You're asking \"what is the value of reading a program that somebody else has written?\", i.e. what is the value of code review. The answer is well-known, and the second half of my post addresses it in detail.",
        "user": "UCGAK10LS",
        "ts": "1679959060.869239",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "h1M",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U0112C10V4Y"
                            },
                            {
                                "type": "text",
                                "text": " You're asking \"what is the value of reading a program that somebody else has written?\", i.e. what is the value of code review. The answer is well-known, and the second half of my post addresses it in detail."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "a7da686f-ae0b-4e00-bc61-33fc77ddbb00",
        "type": "message",
        "text": "Very good points. Yes, certainly there are other FoC projects than low-code/no-code tools and I'm very interested in involving them in this discussion. I just happened to phrase the prompts like that..\n\nValidation is certainly a good aspect to focus on. LLMs can help with validation as well, but the question is whose validation do we trust. It will be a long road to build the trust even after LLMs have the capability to (never?) make mistakes and somehow always understand our intent from ambiguous natural language.. However, the level of validation we currently require for purely human written code varies case by case. I guess it must be the same for AI written code. For a hobby game project you might be fine if the AI generated game just appears to work, for a medical/military/aviation device not so much. So I think that if efficiency of validation is the competitive advantage your FoC project relies on, make sure that your project targets domains in which correctness is important.",
        "user": "U0296ACR13M",
        "ts": "1679982392.919849",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "oNt1A",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Very good points. Yes, certainly there are other FoC projects than low-code/no-code tools and I'm very interested in involving them in this discussion. I just happened to phrase the prompts like that..\n\nValidation is certainly a good aspect to focus on. LLMs can help with validation as well, but the question is whose validation do we trust. It will be a long road to build the trust even after LLMs have the capability to (never?) make mistakes and somehow always understand our intent from ambiguous natural language.. However, the level of validation we currently require for purely human written code varies case by case. I guess it must be the same for AI written code. For a hobby game project you might be fine if the AI generated game just appears to work, for a medical/military/aviation device not so much. So I think that if efficiency of validation is the competitive advantage your FoC project relies on, make sure that your project targets domains in which correctness is important."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "U0296ACR13M",
            "ts": "1679982748.000000"
        },
        "thread_ts": "1679902227.016569",
        "parent_user_id": "U0296ACR13M"
    },
    {
        "client_msg_id": "c3f2e0d8-aedc-4824-b49c-04ce2b56358a",
        "type": "message",
        "text": "In one of these LLM threads someone wrote about the room for improvement in some interface (text interface?) and felt confident working on that problem regardless the onslaught of LLMs. I can't find the message anymore, but if someone could point the person this way, I would love to hear more :slightly_smiling_face:",
        "user": "U0296ACR13M",
        "ts": "1679982547.990119",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "4M1",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "In one of these LLM threads someone wrote about the room for improvement in some interface (text interface?) and felt confident working on that problem regardless the onslaught of LLMs. I can't find the message anymore, but if someone could point the person this way, I would love to hear more "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face",
                                "unicode": "1f642"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679902227.016569",
        "parent_user_id": "U0296ACR13M"
    },
    {
        "client_msg_id": "df49f5fd-644b-438f-9853-78b0a5053586",
        "type": "message",
        "text": "Sorry I didn't make my point that clearly. What I'm saying is that if an AI is good enough to write code for a compiler (by code I mean an end to end system, not just a snippet of code similar to a stack overflow answer), it is probably good enough to write code for a machine architecture directly. In that case there is no code to review.",
        "user": "U0112C10V4Y",
        "ts": "1680020008.516259",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "rnPmt",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Sorry I didn't make my point that clearly. What I'm saying is that if an AI is good enough to write code for a compiler (by code I mean an end to end system, not just a snippet of code similar to a stack overflow answer), it is probably good enough to write code for a machine architecture directly. In that case there is no code to review."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "953a961b-0941-4966-a74a-69c8db4fb8dd",
        "type": "message",
        "text": "I got stuck on the \"'medium is the message' school\" aspect in your post - please elaborate!",
        "user": "UE6EFEPTQ",
        "ts": "1680043116.983189",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "n=mDO",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I got stuck on the \"'medium is the message' school\" aspect in your post - please elaborate!"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679927549.898479",
        "parent_user_id": "U04MTMF6Y4W"
    },
    {
        "client_msg_id": "b57c1167-d411-44e2-a4c9-706b8228aaff",
        "type": "message",
        "text": "&gt; In that case there is no code to review.\nThat's simply not true though. There is still code to review, the difference is that it's now much harder to understand. In general, we're not going to want AI to write opaque binary programs whose behaviour cannot be inspected. (Though it might be fine for certain toy or hobbyist programs.)",
        "user": "UCGAK10LS",
        "ts": "1680043249.104769",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "fOS",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "In that case there is no code to review."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nThat's simply not true though. There is still code to review, the difference is that it's now much harder to understand. In general, we're not going to want AI to write opaque binary programs whose behaviour cannot be inspected. (Though it might be fine for certain toy or hobbyist programs.)"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UCGAK10LS",
            "ts": "1680043558.000000"
        },
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS",
        "reactions": [
            {
                "name": "point_up_2",
                "users": [
                    "U03JUAWDVSR"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "858CBE05-DFDC-4A4B-B2EC-E56BBCBD8EAC",
        "type": "message",
        "text": "Sure. It\u2019s an idea from Marshall McLuhan, started early-mid 1900s, that a communication medium has a stronger affect than the message it carries. As an example, news heard on Twitter vs TV vs a podcast would have different effects regardless of its events. \n\nSo today there\u2019s email mimicking the medium of letters, but they have very different feelings to them. And I\u2019m wondering if that\u2019s something which:\n\u2022 can be fixed with some future tech\n\u2022 a digital \u201cletter feeling\u201d comes from something that looks completely different\n\u2022 or it\u2019s not possible / will always make something new",
        "user": "U04MTMF6Y4W",
        "ts": "1680085791.707429",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "gej",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Sure. It\u2019s an idea from Marshall McLuhan, started early-mid 1900s, that a communication medium has a stronger affect than the message it carries. As an example, news heard on Twitter vs TV vs a podcast would have different effects regardless of its events. \n\nSo today "
                            },
                            {
                                "type": "text",
                                "text": "there\u2019s"
                            },
                            {
                                "type": "text",
                                "text": " email mimicking the medium of letters, but they have very different feelings to them. And I\u2019m wondering if "
                            },
                            {
                                "type": "text",
                                "text": "that\u2019s"
                            },
                            {
                                "type": "text",
                                "text": " something which:"
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "can be fixed with some future tech"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "a digital \u201cletter feeling\u201d comes from something that looks completely different"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "or "
                                    },
                                    {
                                        "type": "text",
                                        "text": "it\u2019s"
                                    },
                                    {
                                        "type": "text",
                                        "text": " not possible / will always make something new"
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "offset": 0,
                        "border": 0
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679927549.898479",
        "parent_user_id": "U04MTMF6Y4W"
    },
    {
        "client_msg_id": "ED12DB7D-FD5A-43B2-9FAC-9D2EBA107EBA",
        "type": "message",
        "text": "\u2022 Or some other option I haven\u2019t thought of ",
        "user": "U04MTMF6Y4W",
        "ts": "1680085826.178509",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "v/D86",
                "elements": [
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Or some other option I "
                                    },
                                    {
                                        "type": "text",
                                        "text": "haven\u2019t"
                                    },
                                    {
                                        "type": "text",
                                        "text": " thought of "
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "offset": 0,
                        "border": 0
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679927549.898479",
        "parent_user_id": "U04MTMF6Y4W"
    },
    {
        "client_msg_id": "c289ffc3-9b07-4151-b48a-6d2e4aad737d",
        "type": "message",
        "text": "My view of what programming is is \"casting spells to affect reality\", so computers are basically reality manifestors. Having to go through screens, apart from IoT i/o, is a current constraint that gets slacker over time. AR and VR is a way to easily do that for visual realities, but it's not quite ready yet. 3D printing is somewhere along the axis, but you need items that are able to continue to shape shift!",
        "user": "UE6EFEPTQ",
        "ts": "1680104500.834899",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "AOO",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "My view of what programming is is \"casting spells to affect reality\", so computers are basically reality manifestors. Having to go through screens, apart from IoT i/o, is a current constraint that gets slacker over time. AR and VR is a way to easily do that for visual realities, but it's not quite ready yet. 3D printing is somewhere along the axis, but you need items that are able to continue to shape shift!"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679927549.898479",
        "parent_user_id": "U04MTMF6Y4W"
    },
    {
        "client_msg_id": "544dcd1b-2b5d-41ae-9a46-ed7bc405751c",
        "type": "message",
        "text": "The letter is actually an example that is redundant, pure medium. Compare a letter with the letter knife, which has many physical uses, including self defence! (I suppose you /could/ paper cut someone to death...) As long as you have a screen and scrollable text, you never need return to that mediums physical properties, like foldable, turnable.",
        "user": "UE6EFEPTQ",
        "ts": "1680104648.988199",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "BXhN",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The letter is actually an example that is redundant, pure medium. Compare a letter with the letter knife, which has many physical uses, including self defence! (I suppose you /could/ paper cut someone to death...) As long as you have a screen and scrollable text, you never need return to that mediums physical properties, like foldable, turnable."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UE6EFEPTQ",
            "ts": "1680104773.000000"
        },
        "thread_ts": "1679927549.898479",
        "parent_user_id": "U04MTMF6Y4W"
    },
    {
        "client_msg_id": "b868a4cd-8eb9-4507-bc5c-cd1cb2ec17d0",
        "type": "message",
        "text": "Well, it's possible that AI will earn our trust and we will indeed settle on machine code output. We trust programmers after all. But even then, we have to be able to build and iterate on a shared mental model with the AI as we see the result executing. So we could see what we think of as high level languages today splitting in two directions: the machine code part down and the dialogue-driven modelling up.",
        "user": "UE6EFEPTQ",
        "ts": "1680165758.277559",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "rADpy",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Well, it's possible that AI will earn our trust and we will indeed settle on machine code output. We trust programmers after all. But even then, we have to be able to build and iterate on a shared mental model with the AI as we see the result executing. So we could see what we think of as high level languages today splitting in two directions: the machine code part down and the dialogue-driven modelling up."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "4a09ce34-96e0-4c55-8838-ae150a04fc17",
        "type": "message",
        "text": "&gt; it's possible that AI will earn our trust and we will indeed settle on machine code output. We trust programmers after all.\nThat's true, but I suspect that won't happen until we have \"full AGI\" (whatever that means). We won't be able to _trust_ an AI to do the right thing for us until it is able to have detailed conversations with us about general requirements and come away with a _true_ and _complete_ understanding of what needs to be done \u2014 not just a smoke-and-mirrors \"best guess\", as happens with LLMs today.\n\nAt the point where we have such AGI, there will be far more dramatic ramifications for society than the automation of programming jobs. We will likely have automated the vast majority of human labour. :face_with_open_eyes_and_hand_over_mouth:",
        "user": "UCGAK10LS",
        "ts": "1680177208.040789",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "=hX",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "it's possible that AI will earn our trust and we will indeed settle on machine code output. We trust programmers after all."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nThat's true, but I suspect that won't happen until we have \"full AGI\" (whatever that means). We won't be able to "
                            },
                            {
                                "type": "text",
                                "text": "trust",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " an AI to do the right thing for us until it is able to have detailed conversations with us about general requirements and come away with a "
                            },
                            {
                                "type": "text",
                                "text": "true ",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "and "
                            },
                            {
                                "type": "text",
                                "text": "complete ",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "understanding of what needs to be done \u2014 not just a smoke-and-mirrors \"best guess\", as happens with LLMs today.\n\nAt the point where we have such AGI, there will be far more dramatic ramifications for society than the automation of programming jobs. We will likely have automated the vast majority of human labour. "
                            },
                            {
                                "type": "emoji",
                                "name": "face_with_open_eyes_and_hand_over_mouth",
                                "unicode": "1fae2"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UCGAK10LS",
            "ts": "1680177466.000000"
        },
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "6604861f-85c4-46ba-a690-ade688ed7277",
        "type": "message",
        "text": "Yup :+1:",
        "user": "UE6EFEPTQ",
        "ts": "1680181366.670179",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "sbW",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yup "
                            },
                            {
                                "type": "emoji",
                                "name": "+1",
                                "unicode": "1f44d"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "2001bf07-e18d-4b8f-b0bb-9326d8686fb6",
        "type": "message",
        "text": "But anyway, the other half of my point is the issue of the nature of a formalism used to evolve a shared mental model with the AI ... One way or another we won't have to think about NFRs - either that's dealt with in the \"AI's compile and commit latest machine code\" loop or the modelling language is already good enough to be able to take pure domain functionality descriptions and pull together all the machine stuff needed to make it directly executable, optimising along the way.  So what \"cognitive modelling formalisms\" are there for expressing pure domain structures and behaviours, that we can use to give robustness to our chat threads with an AI?",
        "user": "UE6EFEPTQ",
        "ts": "1680181816.402269",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "hKYSM",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "But anyway, the other half of my point is the issue of the nature of a formalism used to evolve a shared mental model with the AI ... One way or another we won't have to think about NFRs - either that's dealt with in the \"AI's compile and commit latest machine code\" loop or the modelling language is already good enough to be able to take pure domain functionality descriptions and pull together all the machine stuff needed to make it directly executable, optimising along the way.  So what \"cognitive modelling formalisms\" are there for expressing pure domain structures and behaviours, that we can use to give robustness to our chat threads with an AI?"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UE6EFEPTQ",
            "ts": "1680181915.000000"
        },
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "ACC02CA1-FB5D-4DCA-A991-CED65BA7EE38",
        "type": "message",
        "text": "\u201cCasting spells\u201d is a really nice way of describing it. I\u2019d disagree on scrollable text though. There\u2019s ink, handwriting (meticulous or rushed?), paper quality, scent, paper type (legal paper vs a postcard), presence (save it as a memento or use as a reminder in your periphery), along with other assumptions because, \u201cit\u2019s 2023 and someone just sent a _letter_?\u201d My opinion\u2019s probably somewhere between two and three. Maybe letters are video calls now and emails are something else? ",
        "user": "U04MTMF6Y4W",
        "ts": "1680193691.864459",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "2XSX",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\u201cCasting spells\u201d is a really nice way of describing it. I\u2019d disagree on scrollable text though. There\u2019s ink, handwriting (meticulous or rushed?), paper quality, scent, paper type (legal paper vs a postcard), presence (save it as a memento or use as a reminder in your periphery), along with other assumptions because, \u201cit\u2019s 2023 and someone just sent a "
                            },
                            {
                                "type": "text",
                                "text": "letter",
                                "style": {
                                    "bold": false,
                                    "italic": true,
                                    "strike": false
                                }
                            },
                            {
                                "type": "text",
                                "text": "?\u201d My opinion\u2019s probably somewhere between two and three. Maybe letters are video calls now and emails are something else? "
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679927549.898479",
        "parent_user_id": "U04MTMF6Y4W"
    },
    {
        "client_msg_id": "fee8c98e-9674-4182-85c9-090afc450cfb",
        "type": "message",
        "text": "OK, but the original intention was simply to \"say stuff\" over a distance: all the other aspects are subsequent side effects of this medium, which of course have indeed become valuable in and of themselves. So if you want to cast a letter spell (no paper smell, sorry!) then that's fine too.",
        "user": "UE6EFEPTQ",
        "ts": "1680194214.148599",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "gmAj",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "OK, but the original intention was simply to \"say stuff\" over a distance: all the other aspects are subsequent side effects of this medium, which of course have indeed become valuable in and of themselves. So if you want to cast a letter spell (no paper smell, sorry!) then that's fine too."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679927549.898479",
        "parent_user_id": "U04MTMF6Y4W",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U04MTMF6Y4W"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "C44072EB-C866-4AF4-BAA9-7F044D67025D",
        "type": "message",
        "text": "Yeah, I realized halfway through a lot of its value today comes from having been replaced. I still think there\u2019s something off with email (as a stand-in for pdigital emulation type things). Actually maybe *because* programming can \u201ccast spells\u201d / is a \u201c dynamic medium\u201d, static forms of communication (with or through computers) become less interesting. ",
        "user": "U04MTMF6Y4W",
        "ts": "1680195012.354479",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "H6Ff",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yeah, I realized halfway through a lot of its value today comes from having been replaced. I still think there\u2019s something off with email (as a stand-in for pdigital emulation type things). "
                            },
                            {
                                "type": "text",
                                "text": "Actually maybe "
                            },
                            {
                                "type": "text",
                                "text": "because",
                                "style": {
                                    "bold": true,
                                    "italic": false,
                                    "strike": false
                                }
                            },
                            {
                                "type": "text",
                                "text": " programming can \u201ccast spells\u201d / is"
                            },
                            {
                                "type": "text",
                                "text": " a \u201c dynamic medium\u201d, static forms of communication (with or through computers) become less interesting. "
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679927549.898479",
        "parent_user_id": "U04MTMF6Y4W"
    },
    {
        "client_msg_id": "0ED8D9A4-B79F-4E63-8D8B-C599E4D7A602",
        "type": "message",
        "text": "\u201cStop Drawing Dead Software\u201d :drum_with_drumsticks: ",
        "user": "U04MTMF6Y4W",
        "ts": "1680195096.859449",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "+3uH",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\u201cStop Drawing Dead Software\u201d "
                            },
                            {
                                "type": "emoji",
                                "name": "drum_with_drumsticks",
                                "unicode": "1f941"
                            },
                            {
                                "type": "text",
                                "text": " "
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679927549.898479",
        "parent_user_id": "U04MTMF6Y4W"
    },
    {
        "client_msg_id": "28ab7605-ddc7-4e71-af69-4a11c1ced632",
        "type": "message",
        "text": ":grin::+1:",
        "user": "UE6EFEPTQ",
        "ts": "1680196155.914259",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "vkqJc",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "emoji",
                                "name": "grin",
                                "unicode": "1f601"
                            },
                            {
                                "type": "emoji",
                                "name": "+1",
                                "unicode": "1f44d"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679927549.898479",
        "parent_user_id": "U04MTMF6Y4W"
    },
    {
        "client_msg_id": "4743ab23-933a-41fd-8c42-3e2f491b55af",
        "type": "message",
        "text": "I still have hope that a high-level programming language can serve as the \"cognitive modelling formalism\". Indeed, as we speak, I'm working on a high-level PL whose syntax is more-or-less a formal subset of English, combined with some mathematical notation such as function calls `f(x, y)`.",
        "user": "UCGAK10LS",
        "ts": "1680218359.116989",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ImaU6",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I still have hope that a high-level programming language can serve as the \"cognitive modelling formalism\". Indeed, as we speak, I'm working on a high-level PL whose syntax is more-or-less a formal subset of English, combined with some mathematical notation such as function calls "
                            },
                            {
                                "type": "text",
                                "text": "f(x, y)",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UCGAK10LS",
            "ts": "1680218479.000000"
        },
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS",
        "reactions": [
            {
                "name": "ok_hand",
                "users": [
                    "U03JUAWDVSR"
                ],
                "count": 1
            }
        ]
    }
]