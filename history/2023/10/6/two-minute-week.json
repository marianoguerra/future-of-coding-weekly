[
    {
        "client_msg_id": "498aa90e-269b-4663-a003-762ba965c689",
        "type": "message",
        "text": "Lately I've been <https://photos.app.goo.gl/Pxpyok4TDNsuWs1d6|experimenting with recognition of hand-drawn symbols in embedded structures>, working with Luke Iannini in Realtalk\n\nThinking about how perceptually salient properties (such as spikiness/roundness, wonkiness) could be taken into account in a kind of analogue interpretation of the shapes alongside discrete symbol recognition as 'signposts' in feature space.\n\nand what happens to those features when some symbols are marked out as higher order functions.\n\nThinking about syntax based on proximity and containment rather than adjacency.\n\nalso what happens when the parser itself is part of the scene.. e.g. how does its orientation change the parsing of the symbols?\n\nWould love to hear about other projects that have explored this kind of area!",
        "user": "U05SU27S1M2",
        "ts": "1696588167.703199",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "VD+N6",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Lately I've been "
                            },
                            {
                                "type": "link",
                                "url": "https://photos.app.goo.gl/Pxpyok4TDNsuWs1d6",
                                "text": "experimenting with recognition of hand-drawn symbols in embedded structures"
                            },
                            {
                                "type": "text",
                                "text": ", working with Luke Iannini in Realtalk\n\nThinking about how perceptually salient properties (such as spikiness/roundness, wonkiness) could be taken into account in a kind of analogue interpretation of the shapes alongside discrete symbol recognition as 'signposts' in feature space.\n\nand what happens to those features when some symbols are marked out as higher order functions.\n\nThinking about syntax based on proximity and containment rather than adjacency.\n\nalso what happens when the parser itself is part of the scene.. e.g. how does its orientation change the parsing of the symbols?\n\nWould love to hear about other projects that have explored this kind of area!"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "image_url": "https://lh3.googleusercontent.com/pw/ADCreHeIlr7YLqcKhpXczRjxkoAvsHNraG4kMdIxo3MHz_Dz99pQTDPs5XEi8qRecdoZtRhdSTJgGC72dY0WsVbnm9okz61nheOsNE0k5Vvo5pkyJh4MeQCv",
                "image_width": 288,
                "image_height": 512,
                "image_bytes": 41089,
                "from_url": "https://photos.app.goo.gl/Pxpyok4TDNsuWs1d6",
                "service_icon": "http://ssl.gstatic.com/social/photosui/images/logo/1x/photos_512dp.png",
                "id": 1,
                "original_url": "https://photos.app.goo.gl/Pxpyok4TDNsuWs1d6",
                "fallback": "Google Photos: New video by Alex McLean",
                "title": "New video by Alex McLean",
                "title_link": "https://photos.app.goo.gl/Pxpyok4TDNsuWs1d6",
                "service_name": "Google Photos"
            }
        ],
        "thread_ts": "1696588167.703199",
        "reply_count": 5,
        "reply_users_count": 5,
        "latest_reply": "1696674415.111859",
        "reply_users": [
            "UCUSW7WVD",
            "UF6RLAL7J",
            "UGWUJUZHT",
            "U0378MDUG1Y",
            "U05SU27S1M2"
        ],
        "is_locked": false,
        "subscribed": false,
        "reactions": [
            {
                "name": "heartbeat",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            },
            {
                "name": "heart",
                "users": [
                    "UQ2P2BYJU"
                ],
                "count": 1
            },
            {
                "name": "cake",
                "users": [
                    "U013ZLJARC7",
                    "U0378MDUG1Y"
                ],
                "count": 2
            },
            {
                "name": "eight_pointed_black_star",
                "users": [
                    "U05UK5T7LPP"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "b4806399-1b49-4f0b-aa58-0738dcefc02a",
        "type": "message",
        "text": "I'm just starting to dip my toes into recognizing gestures on a touchscreen, which feels like a kiddie pool for your project.",
        "user": "UCUSW7WVD",
        "ts": "1696605515.498129",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "paS2k",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I'm just starting to dip my toes into recognizing gestures on a touchscreen, which feels like a kiddie pool for your project."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696588167.703199",
        "parent_user_id": "U05SU27S1M2"
    },
    {
        "client_msg_id": "3a8f58ca-2635-4c67-bfe7-1ba2641af565",
        "type": "message",
        "text": "We\u2019re trying to put together a bunch of *research tools in one place*\u2014web search, images search, all sorts of AI thingies.\nIt\u2019s now possible to try some of this *<https://nette.io/#try-generate|straight from the homepage>\u2014no login, no nothing.*\nPlease check it out if it sounds interesting at all and as always comments appreciated :pray:\n\nHere\u2019s a little video for your viewing pleasure :film_projector: \u2014 have a great Friday and wonderful weekend!\n\n<https://youtu.be/dqwUkz7GTRE?si=JdiN0ULxxEs4VR6L>",
        "user": "UQ2P2BYJU",
        "ts": "1696606429.786849",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "okSYX",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "We\u2019re trying to put together a bunch of "
                            },
                            {
                                "type": "text",
                                "text": "research tools in one place",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\u2014web search, images search, all sorts of AI thingies.\nIt\u2019s now possible to try some of this "
                            },
                            {
                                "type": "link",
                                "url": "https://nette.io/#try-generate",
                                "text": "straight from the homepage",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\u2014no login, no nothing.",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\nPlease check it out if it sounds interesting at all and as always comments appreciated "
                            },
                            {
                                "type": "emoji",
                                "name": "pray",
                                "unicode": "1f64f"
                            },
                            {
                                "type": "text",
                                "text": "\n\nHere\u2019s a little video for your viewing pleasure "
                            },
                            {
                                "type": "emoji",
                                "name": "film_projector",
                                "unicode": "1f4fd-fe0f"
                            },
                            {
                                "type": "text",
                                "text": " \u2014 have a great Friday and wonderful weekend!\n\n"
                            },
                            {
                                "type": "link",
                                "url": "https://youtu.be/dqwUkz7GTRE?si=JdiN0ULxxEs4VR6L"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UQ2P2BYJU",
            "ts": "1696606678.000000"
        },
        "attachments": [
            {
                "from_url": "https://youtu.be/dqwUkz7GTRE?si=JdiN0ULxxEs4VR6L",
                "thumb_url": "https://i.ytimg.com/vi/dqwUkz7GTRE/hqdefault.jpg",
                "thumb_width": 480,
                "thumb_height": 360,
                "video_html": "<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/dqwUkz7GTRE?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Try \u2014 \u2726 Generate: A One Click Research Dashboard\"></iframe>",
                "video_html_width": 400,
                "video_html_height": 225,
                "service_icon": "https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png",
                "id": 1,
                "original_url": "https://youtu.be/dqwUkz7GTRE?si=JdiN0ULxxEs4VR6L",
                "fallback": "YouTube Video: Try \u2014 \u2726 Generate: A One Click Research Dashboard",
                "title": "Try \u2014 \u2726 Generate: A One Click Research Dashboard",
                "title_link": "https://youtu.be/dqwUkz7GTRE?si=JdiN0ULxxEs4VR6L",
                "author_name": "Pawel Ceranka",
                "author_link": "https://www.youtube.com/@pawelceranka",
                "service_name": "YouTube",
                "service_url": "https://www.youtube.com/"
            }
        ],
        "thread_ts": "1696606429.786849",
        "reply_count": 7,
        "reply_users_count": 2,
        "latest_reply": "1696673547.276829",
        "reply_users": [
            "U05SU27S1M2",
            "UQ2P2BYJU"
        ],
        "is_locked": false,
        "subscribed": false
    },
    {
        "client_msg_id": "c4d93dc0-c5c1-4355-8987-bb1eec3583a2",
        "type": "message",
        "text": "CC <@UAJ9DV971> <@UC2A2ARPT>",
        "user": "UF6RLAL7J",
        "ts": "1696607500.027919",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "0eVPG",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "CC "
                            },
                            {
                                "type": "user",
                                "user_id": "UAJ9DV971"
                            },
                            {
                                "type": "text",
                                "text": " "
                            },
                            {
                                "type": "user",
                                "user_id": "UC2A2ARPT"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696588167.703199",
        "parent_user_id": "U05SU27S1M2",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UC2A2ARPT",
                    "UAJ9DV971"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "91eb13ce-38ca-4192-8f57-42584876d23c",
        "type": "message",
        "text": "FWIW: I\u2019ve been playing with parsing non-textual language.  Conclusion: grade school math plus relational languages (PROLOG in my case) plus only a small handful of relations goes a long way towards something usable:\n\u2022 /recognizing/ symbols and gestures is orthogonal to /parsing/ symbol-based languages ; \u201cediting\u201d and \u201cparsing\u201d and \u201csemantics checking\u201d should be completely orthogonal (accidental complexity abounds when the above is conflated together)\n\u2022 containment\n\u2022 connections\n\u2022 bigger/smaller\n\u2022 colour/shape/etc\n\u2022 SVG has just everything needed (in fact, I ignore a lot of SVG, no swoopy art, just boxes and arrows and ellipses)\n\u2022 blocks of text are \u201csymbols\u201d, their contents can be written in any 3GL, then parsed as black boxes along with the above\n\u2022 real humans think of rectangles as isolated, stand-alone thingies --&gt; isolation is key (I call it \u201c0D\u201d)\n\u2022 currently using <http://draw.io|draw.io> to edit drawings, then manually-written code to parse (e.g. hand-written semantics code using XML parser which sucks symbols (and some relationships) out of diagrams)\n\u2022 ignore stuff that is hard to parse (swoopy stuff can remain in the diagrams, but is treated like comments)\n\u2022 I transpile the hybrid diagrams to code in some existing language(s), or, run them directly without transpilation\n\u2022 my friends: Ohm-JS, PROLOG, PEG, backtracking parsing, (I think miniKanren would work, too)",
        "user": "UGWUJUZHT",
        "ts": "1696609341.735319",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "P4EbY",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "FWIW: I\u2019ve been playing with parsing non-textual language.  Conclusion: grade school math plus relational languages (PROLOG in my case) plus only a small handful of relations goes a long way towards something usable:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "/recognizing/ symbols and gestures is orthogonal to /parsing/ symbol-based languages ; \u201cediting\u201d and \u201cparsing\u201d and \u201csemantics checking\u201d should be completely orthogonal (accidental complexity abounds when the above is conflated together)"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "containment"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "connections"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "bigger/smaller"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "colour/shape/etc"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "SVG has just everything needed (in fact, I ignore a lot of SVG, no swoopy art, just boxes and arrows and ellipses)"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "blocks of text are \u201csymbols\u201d, their contents can be written in any 3GL, then parsed as black boxes along with the above"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "real humans think of rectangles as isolated, stand-alone thingies --> isolation is key (I call it \u201c0D\u201d)"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "currently using "
                                    },
                                    {
                                        "type": "link",
                                        "url": "http://draw.io",
                                        "text": "draw.io"
                                    },
                                    {
                                        "type": "text",
                                        "text": " to edit drawings, then manually-written code to parse (e.g. hand-written semantics code using XML parser which sucks symbols (and some relationships) out of diagrams)"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "ignore stuff that is hard to parse (swoopy stuff can remain in the diagrams, but is treated like comments)"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "I transpile the hybrid diagrams to code in some existing language(s), or, run them directly without transpilation"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "my friends: Ohm-JS, PROLOG, PEG, backtracking parsing, (I think miniKanren would work, too)"
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696588167.703199",
        "parent_user_id": "U05SU27S1M2"
    },
    {
        "client_msg_id": "2d7725a8-b049-405c-b694-7d0da1f357a1",
        "type": "message",
        "text": "Hmm, first try and it attributes my work to someone else as a 'key fact' :thinking_face:",
        "user": "U05SU27S1M2",
        "ts": "1696614161.289159",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "nBTXd",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Hmm, first try and it attributes my work to someone else as a 'key fact' "
                            },
                            {
                                "type": "emoji",
                                "name": "thinking_face",
                                "unicode": "1f914"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696606429.786849",
        "parent_user_id": "UQ2P2BYJU"
    },
    {
        "client_msg_id": "55433567-4490-42e9-99ec-332f6e7b1f48",
        "type": "message",
        "text": "and the second try. my fault for searching up my own projects I guess..",
        "user": "U05SU27S1M2",
        "ts": "1696614547.283159",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "KS5wV",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "and the second try. my fault for searching up my own projects I guess.."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696606429.786849",
        "parent_user_id": "UQ2P2BYJU"
    },
    {
        "client_msg_id": "f127c60a-7927-490f-8e95-644676b767d9",
        "type": "message",
        "text": "Yeah, it\u2019s LLM based \u2014 it is hinted at during generation, but I guess it should be much clearer that\u2019s the case and that it might be prone to some hallucination \u2014 sorry about that :pray:\n\nThanks for trying it out though!",
        "user": "UQ2P2BYJU",
        "ts": "1696622524.053639",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "RBVg8",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yeah, it\u2019s LLM based \u2014 it is hinted at during generation, but I guess it should be much clearer that\u2019s the case and that it might be prone to some hallucination \u2014 sorry about that "
                            },
                            {
                                "type": "emoji",
                                "name": "pray",
                                "unicode": "1f64f"
                            },
                            {
                                "type": "text",
                                "text": "\n\nThanks for trying it out though!"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UQ2P2BYJU",
            "ts": "1696622551.000000"
        },
        "thread_ts": "1696606429.786849",
        "parent_user_id": "UQ2P2BYJU",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U05SU27S1M2"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "c28fd54c-5fc3-4198-be32-ed4675171f1a",
        "type": "message",
        "text": "I struggled to make it give a list of key facts that didn't contain lies, and of course they're all unsourced. Do you think LLMs have a place in research?",
        "user": "U05SU27S1M2",
        "ts": "1696623147.262639",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "maj17",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I struggled to make it give a list of key facts that didn't contain lies, and of course they're all unsourced. Do you think LLMs have a place in research?"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696606429.786849",
        "parent_user_id": "UQ2P2BYJU"
    },
    {
        "client_msg_id": "54e39551-0b2b-4ed2-bac3-1810bdb90471",
        "type": "message",
        "text": "As it is, it seems dangerous to me.",
        "user": "U05SU27S1M2",
        "ts": "1696623216.221109",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "MRZHo",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "As it is, it seems dangerous to me."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696606429.786849",
        "parent_user_id": "UQ2P2BYJU"
    },
    {
        "client_msg_id": "aa7ab666-fbe2-476a-8a9d-904b47e67844",
        "type": "message",
        "text": "With this experiment we\u2019re trying to learn if this kind of usage pattern i.e. generating interactive initial content for a spatial workspace would be an interesting thing to explore further and what are the trade-offs.\nThe quality of generated results could be improved even now, as e.g. the models we are using at the moment are not the best possible.\nBefore we determine, if it\u2019s worth doubling down on this effort we\u2019re trading of that quality for price and speed.\n\nThis generative aspect is mostly for getting you started on exploring some topic, there are other little tools and features in the app that should take you bit further.\n\nThere might even an argument made that an inclusion of some more sophisticated verification tool for the generated content would be beneficial\u2014that is the kind of thing I\u2019m interested to learn, so thank you!\n\nI think the LLMs most likely are going to be widely used for research whether we like it or not. Given that I think it\u2019s worth exploring the tools and interactions around them to find what\u2019s useful, humane and fun :slightly_smiling_face:",
        "user": "UQ2P2BYJU",
        "ts": "1696624136.441269",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "HOQuE",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "With this experiment we\u2019re trying to learn if this kind of usage pattern i.e. generating interactive initial content for a spatial workspace would be an interesting thing to explore further and what are the trade-offs.\nThe quality of generated results could be improved even now, as e.g. the models we are using at the moment are not the best possible.\nBefore we determine, if it\u2019s worth doubling down on this effort we\u2019re trading of that quality for price and speed.\n\nThis generative aspect is mostly for getting you started on exploring some topic, there are other little tools and features in the app that should take you bit further.\n\nThere might even an argument made that an inclusion of some more sophisticated verification tool for the generated content would be beneficial\u2014that is the kind of thing I\u2019m interested to learn, so thank you!\n\nI think the LLMs most likely are going to be widely used for research whether we like it or not. Given that I think it\u2019s worth exploring the tools and interactions around them to find what\u2019s useful, humane and fun "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face",
                                "unicode": "1f642"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696606429.786849",
        "parent_user_id": "UQ2P2BYJU"
    },
    {
        "client_msg_id": "31036B95-6410-46D6-A45A-DE93A2C016D2",
        "type": "message",
        "text": "&gt; Thinking about syntax based on proximity and containment rather than adjacency.\nCould you expand on the difference and/or tension here?",
        "user": "U0378MDUG1Y",
        "ts": "1696656697.046439",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "i0Nrl",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Thinking about syntax based on proximity and containment rather than adjacency."
                            }
                        ],
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nCould you expand on the difference and/or tension here?"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696588167.703199",
        "parent_user_id": "U05SU27S1M2"
    },
    {
        "client_msg_id": "0983687d-3276-4e8e-bcea-3adcdbdd0763",
        "type": "message",
        "text": "Yes sure LLMs could be useful for researchers, but I think labeling statistical jumbles as key facts isn't humane, and in the world of research will result in embarrassing retractions and probably legal issues. Sorry to be so down on this, I'm sure there are nice aspects to this work too, but I don't find it a nice experience to be presented with falsehoods like this.",
        "user": "U05SU27S1M2",
        "ts": "1696673547.276829",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "t/jBJ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yes sure LLMs could be useful for researchers, but I think labeling statistical jumbles as key facts isn't humane, and in the world of research will result in embarrassing retractions and probably legal issues. Sorry to be so down on this, I'm sure there are nice aspects to this work too, but I don't find it a nice experience to be presented with falsehoods like this."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696606429.786849",
        "parent_user_id": "UQ2P2BYJU",
        "reactions": [
            {
                "name": "heavy_plus_sign",
                "users": [
                    "U04QB9V2RNG"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "b1915c1a-465f-4069-a264-aefc303e32aa",
        "type": "message",
        "text": "<@U0378MDUG1Y> Yes definitely! Conventional text-based programming languages are generally built on adjacency. This is a visual property in a way but I suppose a discrete one -- two things (characters, or words) are either adjacent or not -- so we don't tend to think of it as visuospatial.\nBox-and-wire dataflow languages like max/pure data are built on connectedness, another discrete property. We tend to think of these as more visuospatial because you can arrange things how you like in a 2d arrangement, but this is all secondary notation rather than syntactical or semantic.\nProximity is where the arrangement enters the core language - things connect if they are proximal. This means you can assign additional meaning from _how_ proximal things are. A really nice, successful example of this is <http://reactable.com/|the reactable>. I'm not exploring this in the particular demo at the top of the thread, but think there are a lot of possibilities here. I explored this sort of thing some years ago with <https://slab.org/2013/09/13/colourful-texture/|a haskell-based FRP front-end>.\nContainment I guess is actually a separate issue. In this demo I'm exploring just drawing around groups of glyphs. In text-based systems we use parenthesis for this.\nOne nice thing about exploring proximity is the possibilities for collaboration. The reactable is again a really nice case study for this - they made it circular so there's no way 'up' and people can collaborate by standing around it. Way ahead of its time really.",
        "user": "U05SU27S1M2",
        "ts": "1696674415.111859",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "vpqNX",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U0378MDUG1Y"
                            },
                            {
                                "type": "text",
                                "text": " Yes definitely! Conventional text-based programming languages are generally built on adjacency. This is a visual property in a way but I suppose a discrete one -- two things (characters, or words) are either adjacent or not -- so we don't tend to think of it as visuospatial.\nBox-and-wire dataflow languages like max/pure data are built on connectedness, another discrete property. We tend to think of these as more visuospatial because you can arrange things how you like in a 2d arrangement, but this is all secondary notation rather than syntactical or semantic.\nProximity is where the arrangement enters the core language - things connect if they are proximal. This means you can assign additional meaning from "
                            },
                            {
                                "type": "text",
                                "text": "how",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " proximal things are. A really nice, successful example of this is "
                            },
                            {
                                "type": "link",
                                "url": "http://reactable.com/",
                                "text": "the reactable"
                            },
                            {
                                "type": "text",
                                "text": ". I'm not exploring this in the particular demo at the top of the thread, but think there are a lot of possibilities here. I explored this sort of thing some years ago with "
                            },
                            {
                                "type": "link",
                                "url": "https://slab.org/2013/09/13/colourful-texture/",
                                "text": "a haskell-based FRP front-end"
                            },
                            {
                                "type": "text",
                                "text": ".\nContainment I guess is actually a separate issue. In this demo I'm exploring just drawing around groups of glyphs. In text-based systems we use parenthesis for this.\nOne nice thing about exploring proximity is the possibilities for collaboration. The reactable is again a really nice case study for this - they made it circular so there's no way 'up' and people can collaborate by standing around it. Way ahead of its time really."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696588167.703199",
        "parent_user_id": "U05SU27S1M2"
    }
]