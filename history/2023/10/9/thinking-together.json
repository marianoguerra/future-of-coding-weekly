[
    {
        "client_msg_id": "b413ebb6-74b8-420f-bb80-67aa6ff9343e",
        "type": "message",
        "text": "Has anyone thought about or written about malleable software + LLM:s? I feel that it is an area that could be quite interesting, but I haven't got yet a clear understanding on what this will lead to.\n\nI think that pretty soon most of end-user code will be generated with the help of LLM:s. Some thoughts/questions I've been thinking about:\n1. How to generate programming languages, libraries and abstractions that LLM:s can use well? Is that different from generating libraries etc for humans?\n    a. LLM:s are faster than humans in processing data, so API:s can be really wide and probably more complex than what would be practical for devs. \n    b. LLM:s can probably handle more condensed/optimized representation better, too. \n    c. And be able to infer system affordances directly from code.\n2. How to support creating good and maintainable code from LLM:s? And will that matter? Or will actual code become irrelevant?\n3. How to modularize apps so that they can be easily composed by LLM:s?\n    a. My hunch: making apps modular and composable would work really well with LLM:s already now and even better in the future. Doesn't matter if functional or OOP, as long as the LLM can understand the logic.\n4. What kinds of new apps and malleable software will LLM:s enable?\n5. Also: LLM:s could finally enable removing some boundaries between different programming tools, library ecosystems, etc, by enabling translations/bridges automatically.\nAny thoughts?",
        "user": "UEQ7QL15F",
        "ts": "1696845341.002639",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "FTlY+",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Has anyone thought about or written about malleable software + LLM:s? I feel that it is an area that could be quite interesting, but I haven't got yet a clear understanding on what this will lead to.\n\nI think that pretty soon most of end-user code will be generated with the help of LLM:s. Some thoughts/questions I've been thinking about:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "How to generate programming languages, libraries and abstractions that LLM:s can use well? Is that different from generating libraries etc for humans?"
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "LLM:s are faster than humans in processing data, so API:s can be really wide and probably more complex than what would be practical for devs. "
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "LLM:s can probably handle more condensed/optimized representation better, too. "
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "And be able to infer system affordances directly from code."
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 1,
                        "border": 0
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "How to support creating good and maintainable code from LLM:s? And will that matter? Or will actual code become irrelevant?"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "How to modularize apps so that they can be easily composed by LLM:s?"
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "offset": 1,
                        "border": 0
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "My hunch: making apps modular and composable would work really well with LLM:s already now and even better in the future. Doesn't matter if functional or OOP, as long as the LLM can understand the logic."
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 1,
                        "border": 0
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "What kinds of new apps and malleable software will LLM:s enable?"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Also: LLM:s could finally enable removing some boundaries between different programming tools, library ecosystems, etc, by enabling translations/bridges automatically."
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "offset": 3,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nAny thoughts?"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UEQ7QL15F",
            "ts": "1696848497.000000"
        },
        "thread_ts": "1696845341.002639",
        "reply_count": 16,
        "reply_users_count": 7,
        "latest_reply": "1696949882.249399",
        "reply_users": [
            "UAZT04VT4",
            "UJBAJNFLK",
            "UEQ7QL15F",
            "UNS7QDKFV",
            "UCUSW7WVD",
            "UFEQUBNNT",
            "U04JY2BF24E"
        ],
        "is_locked": false,
        "subscribed": false
    },
    {
        "client_msg_id": "fb0e9c02-0061-4bea-b198-1405d41149d8",
        "type": "message",
        "text": "<https://www.geoffreylitt.com/2023/03/25/llm-end-user-programming>",
        "user": "UAZT04VT4",
        "ts": "1696856872.883759",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "2AuoQ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "link",
                                "url": "https://www.geoffreylitt.com/2023/03/25/llm-end-user-programming"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "from_url": "https://www.geoffreylitt.com/2023/03/25/llm-end-user-programming",
                "id": 1,
                "original_url": "https://www.geoffreylitt.com/2023/03/25/llm-end-user-programming",
                "fallback": "Malleable software in the age of LLMs",
                "text": "All computer users may soon have the ability to author small bits of code. What structural changes does this imply for the production and distribution of software?",
                "title": "Malleable software in the age of LLMs",
                "title_link": "https://www.geoffreylitt.com/2023/03/25/llm-end-user-programming",
                "service_name": "geoffreylitt.com"
            }
        ],
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F",
        "reactions": [
            {
                "name": "cake",
                "users": [
                    "UC2A2ARPT",
                    "UCUSW7WVD"
                ],
                "count": 2
            },
            {
                "name": "+1",
                "users": [
                    "UEQ7QL15F"
                ],
                "count": 1
            },
            {
                "name": "the_horns::skin-tone-3",
                "users": [
                    "UFEQUBNNT"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "af18c8db-c3bb-489c-9504-9753e2cdd0c0",
        "type": "message",
        "text": "One big question I see is: will anyone actually make an LLM that will do this job well? Are there economic incentives?\n\nToday's LLMs are not up to the task. Whatever they produce, code or prose, needs to be checked by a human if precision matters (which is almost always does in code).\n\nAlso, today's LLMs are not up to the taks of maintaining anything, because they themselves evolve too quickly. It's very much \"move quickly and break things\". If you write end-user code in a natural language and count on an LLM to turn it into precise instructions, at the very least you want those precise instructions to be reproducible over time.",
        "user": "UJBAJNFLK",
        "ts": "1696865948.141189",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "zyMTP",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "One big question I see is: will anyone actually make an LLM that will do this job well? Are there economic incentives?\n\nToday's LLMs are not up to the task. Whatever they produce, code or prose, needs to be checked by a human if precision matters (which is almost always does in code).\n\nAlso, today's LLMs are not up to the taks of maintaining anything, because they themselves evolve too quickly. It's very much \"move quickly and break things\". If you write end-user code in a natural language and count on an LLM to turn it into precise instructions, at the very least you want those precise instructions to be reproducible over time."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UEQ7QL15F"
                ],
                "count": 1
            },
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "471fa00e-b5ab-4dcc-8616-5c2f69dce962",
        "type": "message",
        "text": "Thanks <@UAZT04VT4>, this is pretty much exactly the kind of thing I was looking for and thinking about!",
        "user": "UEQ7QL15F",
        "ts": "1696866838.238209",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "OOKrF",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Thanks "
                            },
                            {
                                "type": "user",
                                "user_id": "UAZT04VT4"
                            },
                            {
                                "type": "text",
                                "text": ", this is pretty much exactly the kind of thing I was looking for and thinking about!"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F"
    },
    {
        "client_msg_id": "bd453298-5194-4467-841f-1c4dd019b1f5",
        "type": "message",
        "text": "<@UJBAJNFLK>, good points! My hunch is that LLM:s will still improve a lot. Also model versioning, open-source models and fine-tuning will help at overcoming some of the other current bottle-necks. But we'll see. :man-shrugging:",
        "user": "UEQ7QL15F",
        "ts": "1696867174.255229",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "MhPmN",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UJBAJNFLK"
                            },
                            {
                                "type": "text",
                                "text": ", good points! My hunch is that LLM:s will still improve a lot. Also model versioning, open-source models and fine-tuning will help at overcoming some of the other current bottle-necks. But we'll see. "
                            },
                            {
                                "type": "emoji",
                                "name": "man-shrugging",
                                "unicode": "1f937-200d-2642-fe0f"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UEQ7QL15F",
            "ts": "1696867765.000000"
        },
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F"
    },
    {
        "client_msg_id": "4f77b61a-26af-4552-bbf3-0cc39851db69",
        "type": "message",
        "text": "LLMs are good a producing a first draft, since they do require a lot of human oversight of the output.  I'm partial to modifying programs by describing the transformation of the code.  LLMs might be useful for writing the first draft of those transformations.  That helps with the reproducibility issue because the LLM is describing the changes to the code in more structured way, not the code itself.  Unfortunately, as far as I know, there is no widely recognized syntax or system for describing program transformations.",
        "user": "UNS7QDKFV",
        "ts": "1696871268.775599",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "oqjKN",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "LLMs are good a producing a first draft, since they do require a lot of human oversight of the output.  I'm partial to modifying programs by describing the transformation of the code.  LLMs might be useful for writing the first draft of those transformations.  That helps with the reproducibility issue because the LLM is describing the changes to the code in more structured way, not the code itself.  Unfortunately, as far as I know, there is no widely recognized syntax or system for describing program transformations."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UEQ7QL15F"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "a799facb-ecc0-458c-95a8-f7a1406a3641",
        "type": "message",
        "text": "Right. Instead or in addition to editing raw low-level imperative code, I think LLM:s could be useful in altering module-level code/structure, such as which objects/panels are visible where, how they are interconnected, etc. And then create minimal required glue to bind them together. I think this kind of use-case could be interesting to explore and perhaps even more interesting than just creating for loops, if-statements, etc.",
        "user": "UEQ7QL15F",
        "ts": "1696872816.032239",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "e5RRZ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Right. Instead or in addition to editing raw low-level imperative code, I think LLM:s could be useful in altering module-level code/structure, such as which objects/panels are visible where, how they are interconnected, etc. And then create minimal required glue to bind them together. I think this kind of use-case could be interesting to explore and perhaps even more interesting than just creating for loops, if-statements, etc."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F"
    },
    {
        "client_msg_id": "5a6d7180-c0f1-4dff-b1de-0d2c9b830b9a",
        "type": "message",
        "text": "At least in my filter bubble, I'm seeing a lot of ferment in the area of local-only models. I think they go a long way towards addressing concerns of incentives as well as LLM evolution.",
        "user": "UCUSW7WVD",
        "ts": "1696872877.922299",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ccKgc",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "At least in my filter bubble, I'm seeing a lot of ferment in the area of local-only models. I think they go a long way towards addressing concerns of incentives as well as LLM evolution."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UEQ7QL15F"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "02e3442b-bcc2-4884-bb88-c3ed99a65b91",
        "type": "message",
        "text": "Interesting idea of having LLM:s describe transformations of code <@UNS7QDKFV>, btw. Using an LLM to create a transpiler from one language to another would be something like this. Perhaps also LLM creating glue code between API layers. Or are you thinking of something different. :thinking_face:",
        "user": "UEQ7QL15F",
        "ts": "1696873043.779909",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "WYZQF",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Interesting idea of having LLM:s describe transformations of code "
                            },
                            {
                                "type": "user",
                                "user_id": "UNS7QDKFV"
                            },
                            {
                                "type": "text",
                                "text": ", btw. Using an LLM to create a transpiler from one language to another would be something like this. Perhaps also LLM creating glue code between API layers. Or are you thinking of something different. "
                            },
                            {
                                "type": "emoji",
                                "name": "thinking_face",
                                "unicode": "1f914"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F"
    },
    {
        "client_msg_id": "6D3E3FDF-7CD6-4F30-A33E-553DFC6B44EA",
        "type": "message",
        "text": "OpenAI had a first-class \u201cedit\u201d API where you\u2019d send it (for example) code and a description of a change, and it would return the modified version. They deprecated it this summer because it was just as reliable to use the chat API. Even without a transformation language, I find it easy to work with because I can examine the diff just like if another human made the change.",
        "user": "UFEQUBNNT",
        "ts": "1696873468.339889",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Fyi6S",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "OpenAI had a first-class \u201cedit\u201d API where you\u2019d send it (for example) code and a description of a change, and it would return the modified version"
                            },
                            {
                                "type": "text",
                                "text": "."
                            },
                            {
                                "type": "text",
                                "text": " They deprecated it this summer because it was just as reliable to use the chat API. Even without a transformation language, I find it easy to work with because I can examine the diff just like if another human made the change."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F",
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            },
            {
                "name": "+1",
                "users": [
                    "UEQ7QL15F",
                    "UNS7QDKFV"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "711cb838-8df8-49d0-9782-774b07ade516",
        "type": "message",
        "text": "<@UCUSW7WVD>'s draft programmer's pledge reminded me of Ursula Franklin's checklist for technology projects, which is a bit hidden in one of her really excellent 1986 lectures on the \"real world of technology\"\n&gt; \u201c\u2026 whether it:\n&gt;  (1) promotes justice;\n&gt;  (2) restores reciprocity;\n&gt;  (3) confers divisible or indivisible benefits;\n&gt;  (4) favours people over machines;\n&gt;  (5) whether its strategy maximizes gain or minimizes disaster;\n&gt;  (6) whether conservation is favoured over waste; and\n&gt;  (7), whether the reversible is favoured over the irreversible?\u201d\nI tried to <https://slab.org/2022/02/11/ursula-franklins-tech-project-checklist/|summarise these points in a blog post here> or you can <https://archive.org/details/the-real-world-of-technology|listen to the lectures> directly, or <https://archive.org/details/realworldoftechn0000fran_u9w8/page/n9/mode/2up|read it in book form>.\n\nI'll pull out a couple of quotes, first on 3) divisible/indivisible benefits:\n&gt; \u201cIf you have a garden and your friends help you to grow a tremendous tomato crop, you can share it out among those who helped. What you have obtained is a divisible benefit and the right to distribute it. Whoever didn\u2019t help you, may not get anything. On the other hand, if you work hard to fight pollution and you and your friends succeed in changing the practices of the battery-recycling plant down the street, those who helped you get the benefits, but those who didn\u2019t get them too. What you and your friends have obtained are indivisible benefits.\u201d\nand on 7) reversible vs irreversible:\n&gt; \u201cThe last item is obviously important. Considering that most projects do not work out as planned, it would be helpful if they proceeded in a way that allowed revision and learning, that is, in small reversible steps.\u201d\n5) on maximising gain vs minimising disaster is also a really interesting point, where she argues against planning, and for finding the right conditions for something to grow, at its own rate.",
        "user": "U05SU27S1M2",
        "ts": "1696882769.295459",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "+y4JL",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UCUSW7WVD"
                            },
                            {
                                "type": "text",
                                "text": "'s draft programmer's pledge reminded me of Ursula Franklin's checklist for technology projects, which is a bit hidden in one of her really excellent 1986 lectures on the \"real world of technology\"\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\u201c\u2026 whether it:\n (1) promotes justice;\n (2) restores reciprocity;\n (3) confers divisible or indivisible benefits;\n (4) favours people over machines;\n (5) whether its strategy maximizes gain or minimizes disaster;\n (6) whether conservation is favoured over waste; and\n (7), whether the reversible is favoured over the irreversible?\u201d"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nI tried to "
                            },
                            {
                                "type": "link",
                                "url": "https://slab.org/2022/02/11/ursula-franklins-tech-project-checklist/",
                                "text": "summarise these points in a blog post here"
                            },
                            {
                                "type": "text",
                                "text": " or you can "
                            },
                            {
                                "type": "link",
                                "url": "https://archive.org/details/the-real-world-of-technology",
                                "text": "listen to the lectures"
                            },
                            {
                                "type": "text",
                                "text": " directly, or "
                            },
                            {
                                "type": "link",
                                "url": "https://archive.org/details/realworldoftechn0000fran_u9w8/page/n9/mode/2up",
                                "text": "read it in book form"
                            },
                            {
                                "type": "text",
                                "text": ".\n\nI'll pull out a couple of quotes, first on 3) divisible/indivisible benefits:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\u201cIf you have a garden and your friends help you to grow a tremendous tomato crop, you can share it out among those who helped. What you have obtained is a divisible benefit and the right to distribute it. Whoever didn\u2019t help you, may not get anything. On the other hand, if you work hard to fight pollution and you and your friends succeed in changing the practices of the battery-recycling plant down the street, those who helped you get the benefits, but those who didn\u2019t get them too. What you and your friends have obtained are indivisible benefits.\u201d"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nand on 7) reversible vs irreversible:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\u201cThe last item is obviously important. Considering that most projects do not work out as planned, it would be helpful if they proceeded in a way that allowed revision and learning, that is, in small reversible steps.\u201d"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\n5) on maximising gain vs minimising disaster is also a really interesting point, where she argues against planning, and for finding the right conditions for something to grow, at its own rate."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696882769.295459",
        "reply_count": 3,
        "reply_users_count": 3,
        "latest_reply": "1696952282.069179",
        "reply_users": [
            "UCUSW7WVD",
            "U05SU27S1M2",
            "U05597GCDDK"
        ],
        "is_locked": false,
        "subscribed": false,
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "UCUSW7WVD",
                    "U023V63MF6V",
                    "U05G29UQHKK",
                    "UML4ZEKDK",
                    "UJBAJNFLK",
                    "URKQXRCAC"
                ],
                "count": 6
            },
            {
                "name": "boom",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            },
            {
                "name": "eyes",
                "users": [
                    "U023V63MF6V"
                ],
                "count": 1
            },
            {
                "name": "+1",
                "users": [
                    "UEQ7QL15F",
                    "U052S2NHZFU"
                ],
                "count": 2
            },
            {
                "name": "cake",
                "users": [
                    "UC2A2ARPT",
                    "U05597GCDDK"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "f76df641-3d1f-420f-bd44-6a71370a0dfe",
        "type": "message",
        "text": "You may enjoy this: nothing concrete yet but a vision for the future: \"LLM As Compiler\": <https://medium.com/redsquirrel-tech/llm-as-compiler-2a2f79d30f0b>",
        "user": "U04JY2BF24E",
        "ts": "1696883025.497729",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "c9gOG",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "You may enjoy this: nothing concrete yet but a vision for the future: \"LLM As Compiler\": "
                            },
                            {
                                "type": "link",
                                "url": "https://medium.com/redsquirrel-tech/llm-as-compiler-2a2f79d30f0b"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F"
    },
    {
        "client_msg_id": "1d78bab6-fe53-4442-a8e4-aec3dda29211",
        "type": "message",
        "text": "Interesting, thanks <@U04JY2BF24E>! So if I get this correctly, the idea is that users will do coding in high-level pseudo-language, compile it to the actual target language and then verify that it works as intended.",
        "user": "UEQ7QL15F",
        "ts": "1696884151.992949",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "zcw7s",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Interesting, thanks "
                            },
                            {
                                "type": "user",
                                "user_id": "U04JY2BF24E"
                            },
                            {
                                "type": "text",
                                "text": "! So if I get this correctly, the idea is that users will do coding in high-level pseudo-language, compile it to the actual target language and then verify that it works as intended."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F"
    },
    {
        "client_msg_id": "b39e0a87-13ff-4e94-9497-db9d378e4436",
        "type": "message",
        "text": "Something I'd like to see (but don't expect to) is the use of controlled natural languages as the intermediate layer. Generated by an LLM, checked by a human. Controlled natural languages are hard to write but easy to read, so they look like just the right level.\nProblem: there is no big corpus of any controlled natural language that could be used to train LLMs. And such a corpus would be very expensive to create, because these languages are a pain to write.",
        "user": "UJBAJNFLK",
        "ts": "1696929453.580749",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "kmzG5",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Something I'd like to see (but don't expect to) is the use of controlled natural languages as the intermediate layer. Generated by an LLM, checked by a human. Controlled natural languages are hard to write but easy to read, so they look like just the right level.\nProblem: there is no big corpus of any controlled natural language that could be used to train LLMs. And such a corpus would be very expensive to create, because these languages are a pain to write."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UEQ7QL15F"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "450d895f-d079-44c1-8663-b924278f6360",
        "type": "message",
        "text": "I've seen some posts about enforcing constraints on LLM output. Not sure what was the one I saw on Twitter, but perhaps this is something related: <https://github.com/IsaacRe/Syntactically-Constrained-Sampling>\n\nSomething like this might work even for a controlled natural language, as long as you can formalize/validate the language?\n\nAnd I really hope that some type of forced constraints will be in all LLM:s soon.",
        "user": "UEQ7QL15F",
        "ts": "1696933279.121379",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "A9m9y",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I've seen some posts about enforcing constraints on LLM output. Not sure what was the one I saw on Twitter, but perhaps this is something related: "
                            },
                            {
                                "type": "link",
                                "url": "https://github.com/IsaacRe/Syntactically-Constrained-Sampling"
                            },
                            {
                                "type": "text",
                                "text": "\n\nSomething like this might work even for a controlled natural language, as long as you can formalize/validate the language?\n\nAnd I really hope that some type of forced constraints will be in all LLM:s soon."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F"
    },
    {
        "client_msg_id": "45eae00b-ce10-49fb-8dae-67754efa5104",
        "type": "message",
        "text": "100% on the constraints. For now, we attempt to accomplish through prompting, like \"put your answer in the following JSON structure\"... When it neglects to do so, we have to remind it via \"now put your answer in the following JSON structure\". Obviously not robust, but so far \"good enough\" for our use case. Another change that would help: eliminating the non-determinism in the reply. Can anyone explain why today's LLMs are not deterministic? Has non-determinism been added as a \"feature\" to avoid repetitive responses? Or is it somehow fundamental to the inference algorithm itself?",
        "user": "U04JY2BF24E",
        "ts": "1696937107.877229",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "MXNd2",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "100% on the constraints. For now, we attempt to accomplish through prompting, like \"put your answer in the following JSON structure\"... When it neglects to do so, we have to remind it via \"now put your answer in the following JSON structure\". Obviously not robust, but so far \"good enough\" for our use case. Another change that would help: eliminating the non-determinism in the reply. Can anyone explain why today's LLMs are not deterministic? Has non-determinism been added as a \"feature\" to avoid repetitive responses? Or is it somehow fundamental to the inference algorithm itself?"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UEQ7QL15F"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "be44b5af-d005-4a1b-8e11-6a86dc14f37c",
        "type": "message",
        "text": "It's a feature. And as long as LLM output is not reliable, I don't see the point of making it determinstic.",
        "user": "UJBAJNFLK",
        "ts": "1696937952.202249",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "CZbQG",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "It's a feature. And as long as LLM output is not reliable, I don't see the point of making it determinstic."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F"
    },
    {
        "client_msg_id": "BB197360-84DE-4C63-BA01-86FE8CEE893E",
        "type": "message",
        "text": "<@U04JY2BF24E> <https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/|https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/> touches on it.\n\n\u201cThe basic issue is that current neural nets operate with approximate real numbers, and occasionally roundoff in those numbers can be critical to \u201cdecisions\u201d made by the neural net (typically because the application of the activation function for the neural net can lead to a bifurcation between results from numerically nearby values). And so, for example, if different LLMFunction evaluations happen on servers with different hardware and different roundoff characteristics, the results can be different.\u201d\n\nThe next few paragraphs go into how GPU parallelism inserts nondeterminism too.\n\nBut that\u2019s just an explanation of why it\u2019s difficult to remove entirely. Most systems do insert it intentionally to produce variation in the responses.",
        "user": "UFEQUBNNT",
        "ts": "1696949882.249399",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "BAwoZ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U04JY2BF24E"
                            },
                            {
                                "type": "text",
                                "text": " "
                            },
                            {
                                "type": "link",
                                "url": "https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/",
                                "text": "https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/"
                            },
                            {
                                "type": "text",
                                "text": " touches on it.\n\n\u201cThe basic issue is that current neural nets operate with approximate real numbers, and occasionally roundoff in those numbers can be critical to \u201cdecisions\u201d made by the neural net (typically because the application of the activation function for the neural net can lead to a bifurcation between results from numerically nearby values). And so, for example, if different LLMFunction evaluations happen on servers with different hardware and different roundoff characteristics, the results can be different.\u201d\n\nThe next few paragraphs go into how GPU parallelism inserts nondeterminism too.\n\nBut that\u2019s just an explanation of why it\u2019s difficult to remove entirely"
                            },
                            {
                                "type": "text",
                                "text": "."
                            },
                            {
                                "type": "text",
                                "text": " Most systems do insert it intentionally to produce variation in the responses."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UFEQUBNNT",
            "ts": "1696949928.000000"
        },
        "attachments": [
            {
                "image_url": "https://content.wolfram.com/sites/43/2023/05/blog-hero-nestlist-llm-function.png",
                "image_width": 1240,
                "image_height": 792,
                "image_bytes": 646263,
                "from_url": "https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/",
                "service_icon": "https://writings.stephenwolfram.com/favicon.ico",
                "id": 1,
                "original_url": "https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/",
                "fallback": "The New World of LLM Functions: Integrating LLM Technology into the Wolfram Language",
                "text": "How to install and use Wolfram's instant LLM-powered functions. Stephen Wolfram shares dozens of examples and explains how the functions work. Also download",
                "title": "The New World of LLM Functions: Integrating LLM Technology into the Wolfram Language",
                "title_link": "https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/",
                "service_name": "writings.stephenwolfram.com"
            }
        ],
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U04JY2BF24E",
                    "UEQ7QL15F"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "715efb00-65ef-4408-a946-fd00d49ef421",
        "type": "message",
        "text": "I thought I'd watched _real world of technology_, but looking again I think I only watched the first episode. That might be why I was utterly ignorant of this list. Goes on top of Todo stack.",
        "user": "UCUSW7WVD",
        "ts": "1696950280.588299",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "uRlXi",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I thought I'd watched "
                            },
                            {
                                "type": "text",
                                "text": "real world of technology",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ", but looking again I think I only watched the first episode. That might be why I was utterly ignorant of this list. Goes on top of Todo stack."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UCUSW7WVD",
            "ts": "1696950317.000000"
        },
        "thread_ts": "1696882769.295459",
        "parent_user_id": "U05SU27S1M2"
    },
    {
        "client_msg_id": "b173b5e0-d504-476b-bf5a-b0d5cc06f2a0",
        "type": "message",
        "text": "Note that the second lecture seems to be missing from the audio recordings on <http://archive.org|archive.org>",
        "user": "U05SU27S1M2",
        "ts": "1696950590.284029",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "O+KaZ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Note that the second lecture seems to be missing from the audio recordings on "
                            },
                            {
                                "type": "link",
                                "url": "http://archive.org",
                                "text": "archive.org"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1696882769.295459",
        "parent_user_id": "U05SU27S1M2"
    },
    {
        "client_msg_id": "d39c682a-208b-455b-b5b2-fbaa8969a35c",
        "type": "message",
        "text": "In a similar vein, Jacques Ellul's 76 questions <https://76questions.neocities.org/>. there are 76 of them because Ellul has issues with concision",
        "user": "U05597GCDDK",
        "ts": "1696952282.069179",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "kF6vc",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "In a similar vein, Jacques Ellul's 76 questions "
                            },
                            {
                                "type": "link",
                                "url": "https://76questions.neocities.org/"
                            },
                            {
                                "type": "text",
                                "text": ". there are 76 of them because Ellul has issues with concision"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "from_url": "https://76questions.neocities.org/",
                "id": 1,
                "original_url": "https://76questions.neocities.org/",
                "fallback": "76 reasonable questions to ask about any technology",
                "text": "Dear technologist, Please keep these questions in mind as you consider your work and its potential implications. Instead of focusing only on efficiency, please expand your conscience's horizon and consider the human context around you.",
                "title": "76 reasonable questions to ask about any technology",
                "title_link": "https://76questions.neocities.org/",
                "service_name": "76questions.neocities.org"
            }
        ],
        "thread_ts": "1696882769.295459",
        "parent_user_id": "U05SU27S1M2",
        "reactions": [
            {
                "name": "eyes",
                "users": [
                    "U05SU27S1M2"
                ],
                "count": 1
            },
            {
                "name": "sweat_smile",
                "users": [
                    "U05SU27S1M2",
                    "UCUSW7WVD"
                ],
                "count": 2
            },
            {
                "name": "heart",
                "users": [
                    "URKQXRCAC"
                ],
                "count": 1
            }
        ]
    }
]