[
    {
        "client_msg_id": "3994d3e3-a29f-4892-b7ed-47a9949abd76",
        "type": "message",
        "text": "Thoughts on AI code assistants? <https://www.elegantthemes.com/blog/wordpress/best-ai-coding-assistan>\n\nIt doesn't seem that far off from easily prototyping things like games. An AI could understand what a screen is, a sprite/character, movement, etc. Heck, just tell it to generate a random game and fine tune it.",
        "user": "U05PESXCC2E",
        "ts": "1697733302.143859",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Y+UVc",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Thoughts on AI code assistants? "
                            },
                            {
                                "type": "link",
                                "url": "https://www.elegantthemes.com/blog/wordpress/best-ai-coding-assistan"
                            },
                            {
                                "type": "text",
                                "text": "\n\nIt doesn't seem that far off from easily prototyping things like games. An AI could understand what a screen is, a sprite/character, movement, etc. Heck, just tell it to generate a random game and fine tune it."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1697733302.143859",
        "reply_count": 6,
        "reply_users_count": 5,
        "latest_reply": "1697764001.875979",
        "reply_users": [
            "UMQ6LR9NZ",
            "UKVEBP5RD",
            "U05PESXCC2E",
            "UD31LGQKB",
            "UC2A2ARPT"
        ],
        "is_locked": false,
        "subscribed": false
    },
    {
        "client_msg_id": "a941396b-827d-4129-b125-02b37c8e2a1e",
        "type": "message",
        "text": "Not a solid thought, but a link to interesting research that just dropped.\n\nPluralsight <https://www.pluralsight.com/resource-center/guides/new-developer-research-paper|shared some interesting research they just completed>. The research seeks to validate a framework that can be used to understand developers\u2019 relationship to AI.\n\nQuoting from the data highlights of the landing page:\n\n&gt; \u2022 43-45% of developers studied showed evidence of worry, anxiety and fear about whether they could succeed in this era of rapid generative-AI adoption with their current technical skill sets.\n&gt; \u2022 Learning culture and belonging on software teams predicted a decrease in AI Skill Threat &amp; an increase in both individual developer productivity and overall team effectiveness.\n&gt; \u2022 74% of software developers are planning to upskill in AI-assisted coding. However, there are important emerging equity gaps, with female developers and LGBTQ+ developers reporting significantly lower intent to upskill. On the other hand, Racially Minoritized developers reported significantly higher intentions to upskill. \n&gt; \u2022 56% of Racially Minoritized developers reported a negative perception of AI Quality, compared with 28% of all developers.",
        "user": "UMQ6LR9NZ",
        "ts": "1697733507.632339",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Uqz1F",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Not a solid thought, but a link to interesting research that just dropped.\n\nPluralsight "
                            },
                            {
                                "type": "link",
                                "url": "https://www.pluralsight.com/resource-center/guides/new-developer-research-paper",
                                "text": "shared some interesting research they just completed"
                            },
                            {
                                "type": "text",
                                "text": ". The research seeks to validate a framework that can be used to understand developers\u2019 relationship to AI.\n\nQuoting from the data highlights of the landing page:\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "43-45% of developers studied showed evidence of worry, anxiety and fear about whether they could succeed in this era of rapid generative-AI adoption with their current technical skill sets."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Learning culture and belonging on software teams predicted a decrease in AI Skill Threat & an increase in both individual developer productivity and overall team effectiveness."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "74% of software developers are planning to upskill in AI-assisted coding. However, there are important emerging equity gaps, with female developers and LGBTQ+ developers reporting significantly lower intent to upskill. On the other hand, Racially Minoritized developers reported significantly higher intentions to upskill. "
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "56% of Racially Minoritized developers reported a negative perception of AI Quality, compared with 28% of all developers."
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 1
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1697733302.143859",
        "parent_user_id": "U05PESXCC2E",
        "reactions": [
            {
                "name": "brain",
                "users": [
                    "U05PESXCC2E"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "8deff784-7d4d-494b-a6a2-87218ad13df8",
        "type": "message",
        "text": "*Concatenative Programming Projection*\n\n2022 \u2013 ***Interleaved 2D Notation for Concatenative Programming*** \u2013 by <@U01ULCCJB7X>\n Some quickly enlightening demo videos here:\n *<https://michael.homer.nz/Publications/LIVE2022/article/> &lt;&lt;&lt; THIS IS GOOD*\n Landing page: <https://michael.homer.nz/Publications/PAINT2022>\n Tryable in the browser: <https://homepages.ecs.vuw.ac.nz/~mwh/demos/p22-2d-concat/>\n Direct link to the paper: <https://mwh.nz/pdf/paint2022>\n It's a concatenative language.\n It's not a stack based language. Slight differences I guess.\n Also questionably point free with with the values unnamed but live values still shown.\n\n*Comparison to stack based languages*\n\n\u2605 ***Similarities to a stack based language:***\n \u2013 also no variable names\n \u2013 also the typical operations: dup, swap, dig\n \u2013 also only variables with an arity of one or more (aka functions) are shown (and literals)\n \u2605 ***Differences:***\n \u2013 There's no reverse polish notation.\n \u2013 Unlike in in a stack based language there's no single stack.\n Rather the representation make opportunities for parallel evaluation quite obvious.\n \u2013 Variables have no names but are still displaying their live value like in a spreadsheet (not referring to the layout).\n\n :warning: ***It seems this is actually not a language but a projections style.***\n This is nice, meaning to some degree other language can potentially be projected into this representation.\n Well, plus-minus some issues. Syntactic sugar mostly not carrying over. Readability in other projections.\n Switching to a different projection one may want to give out human readable variable names though rather than assigning auto-generated ones.\n\n Maybe this would be a viable additional projection target for some other languages (unison)?\n No clue though how this would interact with algebraic effects.\n\n*Comparison to ALDs*\n*(* <http://apm.bplaced.net/w/index.php?title=Annotated_lambda_diagram> *)*\n\n***Relation of Michael Homers model to annotated lambda diagrams:***\n \u2605 ALDs give same obviousness of parallelity opportunities\n \u2605 Unclear which representation is visually denser but likely not the ALDs\n \u2605 ALDs (as in the current mockups) are not pointfree. Variable names do appear both \u2026\n \u2013 at the head of the function definition (and tops of let- and in- blocks) and\n \u2013 as annotations of the horizontal value lines (i.e. as the arguments to functions)\n \u2605 For Making the ALD code projection more aligned with Michael Homers model:\n \u2013 replace value names with live values\n \u2013 collapse let-in-blocks by substitution\n (live values could still be added as \"syngraphic\" sugar in extended value lines, I digress \u2026)\n \u2605 flip &amp; dig (argument permutators)\n \u2013 They both vanish in the ALD code projection no matter their location.\n \u2013 They are just permuting the arguments by swapping application lines and all preceding dependents.\n \u2605 dup\n \u2013 only vanishes at the top level as it turns into two forks.\n \u2013 otherwise less trivial as it induces an unavoidable let-in block.\n (Uncurrying into tuples is a bad alternative as it hides away ALD circuitry, the whole point of ALDs)",
        "user": "UKVEBP5RD",
        "ts": "1697733555.328719",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "m0Cc7",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Concatenative Programming Projection",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n\n2022 \u2013 "
                            },
                            {
                                "type": "text",
                                "text": "**Interleaved 2D Notation for Concatenative Programming**",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " \u2013 by "
                            },
                            {
                                "type": "user",
                                "user_id": "U01ULCCJB7X"
                            },
                            {
                                "type": "text",
                                "text": "\n Some quickly enlightening demo videos here:\n "
                            },
                            {
                                "type": "link",
                                "url": "https://michael.homer.nz/Publications/LIVE2022/article/",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " <<< THIS IS GOOD",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n Landing page: "
                            },
                            {
                                "type": "link",
                                "url": "https://michael.homer.nz/Publications/PAINT2022"
                            },
                            {
                                "type": "text",
                                "text": "\n Tryable in the browser: "
                            },
                            {
                                "type": "link",
                                "url": "https://homepages.ecs.vuw.ac.nz/~mwh/demos/p22-2d-concat/"
                            },
                            {
                                "type": "text",
                                "text": "\n Direct link to the paper: "
                            },
                            {
                                "type": "link",
                                "url": "https://mwh.nz/pdf/paint2022"
                            },
                            {
                                "type": "text",
                                "text": "\n It's a concatenative language.\n It's not a stack based language. Slight differences I guess.\n Also questionably point free with with the values unnamed but live values still shown.\n\n"
                            },
                            {
                                "type": "text",
                                "text": "Comparison to stack based languages",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n\n\u2605 "
                            },
                            {
                                "type": "text",
                                "text": "**Similarities to a stack based language:**",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n \u2013 also no variable names\n \u2013 also the typical operations: dup, swap, dig\n \u2013 also only variables with an arity of one or more (aka functions) are shown (and literals)\n \u2605 "
                            },
                            {
                                "type": "text",
                                "text": "**Differences:**",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n \u2013 There's no reverse polish notation.\n \u2013 Unlike in in a stack based language there's no single stack.\n Rather the representation make opportunities for parallel evaluation quite obvious.\n \u2013 Variables have no names but are still displaying their live value like in a spreadsheet (not referring to the layout).\n\n "
                            },
                            {
                                "type": "emoji",
                                "name": "warning",
                                "unicode": "26a0-fe0f"
                            },
                            {
                                "type": "text",
                                "text": " "
                            },
                            {
                                "type": "text",
                                "text": "**It seems this is actually not a language but a projections style.**",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n This is nice, meaning to some degree other language can potentially be projected into this representation.\n Well, plus-minus some issues. Syntactic sugar mostly not carrying over. Readability in other projections.\n Switching to a different projection one may want to give out human readable variable names though rather than assigning auto-generated ones.\n\n Maybe this would be a viable additional projection target for some other languages (unison)?\n No clue though how this would interact with algebraic effects.\n\n"
                            },
                            {
                                "type": "text",
                                "text": "Comparison to ALDs",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "text",
                                "text": "( ",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "link",
                                "url": "http://apm.bplaced.net/w/index.php?title=Annotated_lambda_diagram"
                            },
                            {
                                "type": "text",
                                "text": " )",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n\n"
                            },
                            {
                                "type": "text",
                                "text": "**Relation of Michael Homers model to annotated lambda diagrams:**",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n \u2605 ALDs give same obviousness of parallelity opportunities\n \u2605 Unclear which representation is visually denser but likely not the ALDs\n \u2605 ALDs (as in the current mockups) are not pointfree. Variable names do appear both \u2026\n \u2013 at the head of the function definition (and tops of let- and in- blocks) and\n \u2013 as annotations of the horizontal value lines (i.e. as the arguments to functions)\n \u2605 For Making the ALD code projection more aligned with Michael Homers model:\n \u2013 replace value names with live values\n \u2013 collapse let-in-blocks by substitution\n (live values could still be added as \"syngraphic\" sugar in extended value lines, I digress \u2026)\n \u2605 flip & dig (argument permutators)\n \u2013 They both vanish in the ALD code projection no matter their location.\n \u2013 They are just permuting the arguments by swapping application lines and all preceding dependents.\n \u2605 dup\n \u2013 only vanishes at the top level as it turns into two forks.\n \u2013 otherwise less trivial as it induces an unavoidable let-in block.\n (Uncurrying into tuples is a bad alternative as it hides away ALD circuitry, the whole point of ALDs)"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "reactions": [
            {
                "name": "fire",
                "users": [
                    "U015TBQ2091"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "358a5009-0b5b-4a0b-877e-b47a221010cd",
        "type": "message",
        "text": "Seems <@UD31LGQKB> gave a talk on AI as programming assistant recently.\nHazel system being the context.\n<https://andrewblinn.com/papers/2023-MWPLS-Type-directed-Prompt-Construction-for-LLM-powered-Programming-Assistants.pdf>\nNot aware of a recording ATM.",
        "user": "UKVEBP5RD",
        "ts": "1697733879.332169",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "N4zdC",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Seems "
                            },
                            {
                                "type": "user",
                                "user_id": "UD31LGQKB"
                            },
                            {
                                "type": "text",
                                "text": " gave a talk on AI as programming assistant recently.\nHazel system being the context.\n"
                            },
                            {
                                "type": "link",
                                "url": "https://andrewblinn.com/papers/2023-MWPLS-Type-directed-Prompt-Construction-for-LLM-powered-Programming-Assistants.pdf"
                            },
                            {
                                "type": "text",
                                "text": "\nNot aware of a recording ATM."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1697733302.143859",
        "parent_user_id": "U05PESXCC2E"
    },
    {
        "client_msg_id": "89503fe7-d336-4242-8412-ac2fefb673f1",
        "type": "message",
        "text": "I confuse AI with genetic algorithms sometimes, and I think my example was more GA unintentionally.",
        "user": "U05PESXCC2E",
        "ts": "1697733894.189169",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "3+baP",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I confuse AI with genetic algorithms sometimes, and I think my example was more GA unintentionally."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1697733302.143859",
        "parent_user_id": "U05PESXCC2E"
    },
    {
        "client_msg_id": "aeab80ac-893e-444a-9cc9-128dc284018a",
        "type": "message",
        "text": "I think that AI really really needs some memory beyond the current naive context window approach. Some non-AI smart (back)traceing of dependencies that helps filling that memory with what actually matters. \u2013 ATM I have not the first clue about vector databases beyond the name, if it's a good or bad idea.\nWouldn't one want model-weight-modifiers?\nOr are vector databases just that?\n\u2013 \u2013 \u2013\nIt's merely obvious to me that storing stuff in a re-read context window is (while most simple also) the most stupid approach possible.\n\u2013 \u2013 \u2013\nLocally running open source AI would also be nice not running into exploding fees (for just one thing).",
        "user": "UKVEBP5RD",
        "ts": "1697734655.265819",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Ok/9O",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I think that AI really really needs some memory beyond the current naive context window approach. Some non-AI smart (back)traceing of dependencies that helps filling that memory with what actually matters. \u2013 ATM I have not the first clue about vector databases beyond the name, if it's a good or bad idea.\nWouldn't one want model-weight-modifiers?\nOr are vector databases just that?\n\u2013 \u2013 \u2013\nIt's merely obvious to me that storing stuff in a re-read context window is (while most simple also) the most stupid approach possible.\n\u2013 \u2013 \u2013\nLocally running open source AI would also be nice not running into exploding fees (for just one thing)."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UKVEBP5RD",
            "ts": "1697734745.000000"
        },
        "thread_ts": "1697733302.143859",
        "parent_user_id": "U05PESXCC2E"
    },
    {
        "client_msg_id": "07f811b9-26bb-4841-99a6-12c1f8a7a7e0",
        "type": "message",
        "text": "no recording unfortunately. paper eventually though. in brief I think llms have huge potential here but also tons of failure cases, hence trying to deeply integrate them with some kind of structured semantic analysis. at the least retrieving similar code via embeddings feels both like under and overkill given that we could use types and variable binding instead to precisely source relevant code. there are certainly interesting hybrid options here, like if there's no code available having the relevant types, using a vector database of type embeddings to retrieve 'similar' types, and then proceed semantically. this all relies on being in a language withe nice, expressive types though, and being in a codebase that doesn't (say) just use strings for everything. in the broader sense of assistance, beyond simple code completion, we're looking into combining latozas work on programming strategies with type driven edit calculus based approaches to create scaffolded multi-stage processes to perform non-trivial multi-location codebase edits (2nd last slide has a very primitive mockup of what this might look like)",
        "user": "UD31LGQKB",
        "ts": "1697748259.059779",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "RvJ9X",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "no recording unfortunately. paper eventually though. in brief I think llms have huge potential here but also tons of failure cases, hence trying to deeply integrate them with some kind of structured semantic analysis. at the least retrieving similar code via embeddings feels both like under and overkill given that we could use types and variable binding instead to precisely source relevant code. there are certainly interesting hybrid options here, like if there's no code available having the relevant types, using a vector database of type embeddings to retrieve 'similar' types, and then proceed semantically. this all relies on being in a language withe nice, expressive types though, and being in a codebase that doesn't (say) just use strings for everything. in the broader sense of assistance, beyond simple code completion, we're looking into combining latozas work on programming strategies with type driven edit calculus based approaches to create scaffolded multi-stage processes to perform non-trivial multi-location codebase edits (2nd last slide has a very primitive mockup of what this might look like)"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1697733302.143859",
        "parent_user_id": "U05PESXCC2E",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UEQ7QL15F"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "2e6ae28d-b964-4d24-a9e7-d915f89d34f2",
        "type": "message",
        "text": "Mary Rose Cook (<https://futureofcoding.org/episodes/050|friend of the show>) is working on something exactly related to this, in the context of games. I don't think it's public yet, so I can't share specifics, but keep an eye on <https://twitter.com/maryrosecook|her twitter>.\n\nIn short, yes, a lot of the \"I think AI needs _____\" or \"AI could do ____, but ____\" ideas in this thread are things she's engaging with in this work.",
        "user": "UC2A2ARPT",
        "ts": "1697764001.875979",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "dOG8u",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Mary Rose Cook ("
                            },
                            {
                                "type": "link",
                                "url": "https://futureofcoding.org/episodes/050",
                                "text": "friend of the show"
                            },
                            {
                                "type": "text",
                                "text": ") is working on something exactly related to this, in the context of games. I don't think it's public yet, so I can't share specifics, but keep an eye on "
                            },
                            {
                                "type": "link",
                                "url": "https://twitter.com/maryrosecook",
                                "text": "her twitter"
                            },
                            {
                                "type": "text",
                                "text": ".\n\nIn short, yes, a lot of the \"I think AI needs _____\" or \"AI could do ____, but ____\" ideas in this thread are things she's engaging with in this work."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UC2A2ARPT",
            "ts": "1697764049.000000"
        },
        "thread_ts": "1697733302.143859",
        "parent_user_id": "U05PESXCC2E",
        "reactions": [
            {
                "name": "cool",
                "users": [
                    "UD31LGQKB"
                ],
                "count": 1
            },
            {
                "name": "face_with_monocle",
                "users": [
                    "U05PESXCC2E"
                ],
                "count": 1
            }
        ]
    }
]