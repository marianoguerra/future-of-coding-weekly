[
    {
        "client_msg_id": "ae99c55e-062e-47c4-9a04-9eb83a9fd050",
        "type": "message",
        "text": "I wonder if anyone has tried to use Rosie as a replacement for grep? <https://rosie-lang.org/doc/rosie.1.html?hidden=true>\n\nIMO, the problem with grep is that it based on regular expressions, whereas PEG is more powerful.  My favourite PEG is Ohm-JS but I am curious about Rosie...",
        "user": "UGWUJUZHT",
        "ts": "1686154247.250099",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "rgWJj",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I wonder if anyone has tried to use Rosie as a replacement for grep? "
                            },
                            {
                                "type": "link",
                                "url": "https://rosie-lang.org/doc/rosie.1.html?hidden=true"
                            },
                            {
                                "type": "text",
                                "text": "\n\nIMO, the problem with grep is that it based on regular expressions, whereas PEG is more powerful.  My favourite PEG is Ohm-JS but I am curious about Rosie..."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9"
    },
    {
        "client_msg_id": "d37625f5-ccaa-49ed-816d-eff37f702571",
        "type": "message",
        "text": "Hey all! I need a tool / stack suggestion. We'd like to track internal metrics for development like build performance stats, build size, source control size, etc. I'd like to be able to see these trends in a graph by date/commit.\n\u2022 CI tools can do some of this, but they only surface a small, inconfigurable set of metrics. Usually just test failures and build times.\n\u2022 There are monitoring solutions like Grafana Cloud, Datadog, but these all seem geared towards monitoring servers and cloud systems. They also assume you're ingesting massive amounts of data.\nWhat I really just want is a POST-able URL that I can spit metrics to, and a dashboard with some basic alerting. Is there something like this that exists?",
        "user": "UFS53UWE5",
        "ts": "1686164858.059869",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Pva",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Hey all! I need a tool / stack suggestion. We'd like to track internal metrics for development like build performance stats, build size, source control size, etc. I'd like to be able to see these trends in a graph by date/commit.\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "CI tools can do some of this, but they only surface a small, inconfigurable set of metrics. Usually just test failures and build times."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "There are monitoring solutions like Grafana Cloud, Datadog, but these all seem geared towards monitoring servers and cloud systems. They also assume you're ingesting massive amounts of data."
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nWhat I really just want is a POST-able URL that I can spit metrics to, and a dashboard with some basic alerting. Is there something like this that exists?"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UFS53UWE5",
            "ts": "1686164968.000000"
        },
        "thread_ts": "1686164858.059869",
        "reply_count": 10,
        "reply_users_count": 3,
        "latest_reply": "1686282694.153149",
        "reply_users": [
            "UP28ETUSE",
            "UFS53UWE5",
            "U016VUZGUUQ"
        ],
        "is_locked": false,
        "subscribed": false
    },
    {
        "client_msg_id": "27a91e2d-f621-4dd9-9ace-f47f5ace7e33",
        "type": "message",
        "text": "Maybe pushing data to Prometheus and having that as a data source in Grafana? <https://prometheus.io/docs/instrumenting/pushing/>",
        "user": "UP28ETUSE",
        "ts": "1686166399.663979",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "81zw",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Maybe pushing data to Prometheus and having that as a data source in Grafana? "
                            },
                            {
                                "type": "link",
                                "url": "https://prometheus.io/docs/instrumenting/pushing/"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "from_url": "https://prometheus.io/docs/instrumenting/pushing/",
                "service_icon": "https://prometheus.io/assets/favicons/apple-touch-icon-57x57.png",
                "thumb_url": "https://prometheus.io/assets/favicons/android-chrome-192x192.png",
                "thumb_width": 192,
                "thumb_height": 192,
                "id": 1,
                "original_url": "https://prometheus.io/docs/instrumenting/pushing/",
                "fallback": "Pushing metrics | Prometheus",
                "text": "An open-source monitoring system with a dimensional data model, flexible query language, efficient time series database and modern alerting approach.",
                "title": "Pushing metrics | Prometheus",
                "title_link": "https://prometheus.io/docs/instrumenting/pushing/",
                "service_name": "prometheus.io"
            }
        ],
        "thread_ts": "1686164858.059869",
        "parent_user_id": "UFS53UWE5"
    },
    {
        "client_msg_id": "4badaa9c-7a51-4c4e-a2f7-46122caabfbe",
        "type": "message",
        "text": "My understanding was that Prometheus doesn't have persistent storage? Essentially I want to retain this data forever. It's on the order of a few hundred data points per day.",
        "user": "UFS53UWE5",
        "ts": "1686167215.013279",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "GPny",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "My understanding was that Prometheus doesn't have persistent storage? Essentially I want to retain this data forever. It's on the order of a few hundred data points per day."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UFS53UWE5",
            "ts": "1686167676.000000"
        },
        "thread_ts": "1686164858.059869",
        "parent_user_id": "UFS53UWE5"
    },
    {
        "client_msg_id": "b6bd2e08-20d2-4e79-980f-24b7333b3dcf",
        "type": "message",
        "text": "Yeah, it might not be the best choice. Are you looking for an existent service or is it something that you can set up yourself? One possibly very stupid idea might be to just Google Sheets API and push data into a spreadsheet there. A small script could handle the notifications too.",
        "user": "UP28ETUSE",
        "ts": "1686168710.135689",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "L0bW",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yeah, it might not be the best choice. Are you looking for an existent service or is it something that you can set up yourself? One possibly very stupid idea might be to just Google Sheets API and push data into a spreadsheet there. A small script could handle the notifications too."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1686164858.059869",
        "parent_user_id": "UFS53UWE5"
    },
    {
        "client_msg_id": "32cfe766-b7a4-4175-953e-4487cae144aa",
        "type": "message",
        "text": "I guess I was hoping for an existing solution. :neutral_face: But if that fails I'm not above spinning up a couple of docker containers. What I'm trying to avoid is spending time doing sysadmin stuff down the road.",
        "user": "UFS53UWE5",
        "ts": "1686168784.625969",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "QI=I",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I guess I was hoping for an existing solution. "
                            },
                            {
                                "type": "emoji",
                                "name": "neutral_face",
                                "unicode": "1f610"
                            },
                            {
                                "type": "text",
                                "text": " But if that fails I'm not above spinning up a couple of docker containers. What I'm trying to avoid is spending time doing sysadmin stuff down the road."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1686164858.059869",
        "parent_user_id": "UFS53UWE5"
    },
    {
        "client_msg_id": "9efad13d-9ea3-4734-ba99-42bb0eecaca8",
        "type": "message",
        "text": "So far it seems like maybe I could use influxdb + grafana and maybe that would be persistent. Not sure...",
        "user": "UFS53UWE5",
        "ts": "1686168826.434419",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "cUG",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "So far it seems like maybe I could use influxdb + grafana and maybe that would be persistent. Not sure..."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1686164858.059869",
        "parent_user_id": "UFS53UWE5"
    },
    {
        "client_msg_id": "7b64f167-286e-43d4-a014-43fbe3061717",
        "type": "message",
        "text": "Attending a conference today and yesterday about Blockly, the visual code editing environment. Big push toward bi-drectionality between code and blocks. For integration with existing code-bases, AI generation, collaboration with people not using visual editors, etc. At least two different approaches being investigated or used, and I would be inclined to use a completely different one. They don't realize it, but some of their problems are solved by some of the tools people here are working on. Like how do you make it so that you can generate blocks when the text is in an invalid state? Much easier to just avoid invalid states, like Blockly does! How can you avoid invalid states if the person isn't finished typing, and there are mandatory subnodes in the AST? Much easier to fill holes by default, like Blockly does. Essentially, they can't get to bidirectionality, because the text editing experience is structurally unaware. It's not possible with VSCode, but it is possible with Tylr, or anything that imposes a structure. Even ProseMirror would work better. But there is no need to stop at two concrete syntaxes, if you can sacrifice interface specific details (e.g. whitespace in text, grid position in Blockly), or keep them where they live (linter settings, a database of block locations outside the AST), you can operate directly on the AST in whatever tool you want. Has anyone played with a \"headless\" AST that could be used that way? It feels like all structural editors need one, particularly if they hope to facilitate collaborative editing. Has anyone tried putting two different coding interfaces over the same shared AST?",
        "user": "U02U0AS3J49",
        "ts": "1686169579.523179",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "iGM",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Attending a conference today and yesterday about Blockly, the visual code editing environment. Big push toward bi-drectionality between code and blocks. For integration with existing code-bases, AI generation, collaboration with people not using visual editors, etc. At least two different approaches being investigated or used, and I would be inclined to use a completely different one. They don't realize it, but some of their problems are solved by some of the tools people here are working on. Like how do you make it so that you can generate blocks when the text is in an invalid state? Much easier to just avoid invalid states, like Blockly does! How can you avoid invalid states if the person isn't finished typing, and there are mandatory subnodes in the AST? Much easier to fill holes by default, like Blockly does. Essentially, they can't get to bidirectionality, because the text editing experience is structurally unaware. It's not possible with VSCode, but it is possible with Tylr, or anything that imposes a structure. Even ProseMirror would work better. But there is no need to stop at two concrete syntaxes, if you can sacrifice interface specific details (e.g. whitespace in text, grid position in Blockly), or keep them where they live (linter settings, a database of block locations outside the AST), you can operate directly on the AST in whatever tool you want. Has anyone played with a \"headless\" AST that could be used that way? It feels like all structural editors need one, particularly if they hope to facilitate collaborative editing. Has anyone tried putting two different coding interfaces over the same shared AST?"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1686169579.523179",
        "reply_count": 10,
        "reply_users_count": 4,
        "latest_reply": "1686330984.885939",
        "reply_users": [
            "U02U0AS3J49",
            "UGWUJUZHT",
            "U0296ACR13M",
            "U016VUZGUUQ"
        ],
        "is_locked": false,
        "subscribed": false,
        "reactions": [
            {
                "name": "thinking_face",
                "users": [
                    "UA14TGLTC"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "3248b518-f21b-494c-92cc-5cf6fcbd3523",
        "type": "message",
        "text": "Also, there was a suggestion that you could go from code to blocks by normalizing the code (standardizing whitespace, etc.) and then using some sort of evolutionary approach to build up a change to the block representation that has the same output as the text. Does that strike anyone else as WILDLY silly? The other approach I saw was adding the additional content relevant for the block language (e.g. X&amp;y coordinates) as comments, and writing a JavaScript AST to Blockly XML transpiler. More reasonable, but limited to those two specific syntaxes, which seems short-sighted, and there are things that you can change in the text that will not survive round trips, which seems like a usability problem. Their use case was only to let AI write code, though, so that doesn't matter to them.",
        "user": "U02U0AS3J49",
        "ts": "1686172647.343239",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "WO6X",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Also, there was a suggestion that you could go from code to blocks by normalizing the code (standardizing whitespace, etc.) and then using some sort of evolutionary approach to build up a change to the block representation that has the same output as the text. Does that strike anyone else as WILDLY silly? The other approach I saw was adding the additional content relevant for the block language (e.g. X&y coordinates) as comments, and writing a JavaScript AST to Blockly XML transpiler. More reasonable, but limited to those two specific syntaxes, which seems short-sighted, and there are things that you can change in the text that will not survive round trips, which seems like a usability problem. Their use case was only to let AI write code, though, so that doesn't matter to them."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1686169579.523179",
        "parent_user_id": "U02U0AS3J49",
        "reactions": [
            {
                "name": "100",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "072987ee-bb5b-4c90-9c2b-165bf22bfc72",
        "type": "message",
        "text": "It\u2019s a matter of semantic content and of discarding information.  It is easy to go from a language that has more semantic content to a language that has less semantic content.  But, it is difficult to go from a language that has less semantic content to a language that has more semantic content. Semantic content comes in forms other than sequences of characters (or sequences of vector graphics), e.g. structure and layout mean something to human readers.  Going from Haskell to assembler makes sense, but, going from assembler to Haskell does not make sense.  Likewise, if the VPL is any good, then going from VPL to code is easy, but going from code to VPL is difficult.  N.B. if code-&gt;VPL were easy, it would imply that that the VPL adds no new information and is, therefore, redundant.  A decent VPL should contain semantic meaning that is difficult to express in code.  Hence, IMO, it makes no sense to even try to \u201cround trip\u201d code-&gt;VPL.\nFor an example in a very different field - math - we are taught that we can multiply matrices, but, that we cannot divide matrices.  Robert Distinti has developed a way to divide matrices and blames previous failure to do so on the fact that too much information is discarded by current methods.\nAside: Note that, to me, a VPL is a hybrid of graphics and text (see SVG, for example).  There is/was a field called \u201cDesign Recovery\u201d that researched possible approaches to recovering semantic information (I witnessed such techniques being used for fixing Y2K problems, which would have been lessened if they had kept the source code and would not have equated \u201cdates\u201d with girls\u2019 names in some of the code).",
        "user": "UGWUJUZHT",
        "ts": "1686189824.274419",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "qKPAQ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "It\u2019s a matter of semantic content and of discarding information.  It is easy to go from a language that has more semantic content to a language that has less semantic content.  But, it is difficult to go from a language that has less semantic content to a language that has more semantic content. Semantic content comes in forms other than sequences of characters (or sequences of vector graphics), e.g. structure and layout mean something to human readers.  Going from Haskell to assembler makes sense, but, going from assembler to Haskell does not make sense.  Likewise, if the VPL is any good, then going from VPL to code is easy, but going from code to VPL is difficult.  N.B. if code->VPL were easy, it would imply that that the VPL adds no new information and is, therefore, redundant.  A decent VPL should contain semantic meaning that is difficult to express in code.  Hence, IMO, it makes no sense to even try to \u201cround trip\u201d code->VPL.\nFor an example in a very different field - math - we are taught that we can multiply matrices, but, that we cannot divide matrices.  Robert Distinti has developed a way to divide matrices and blames previous failure to do so on the fact that too much information is discarded by current methods.\nAside: Note that, to me, a VPL is a hybrid of graphics and text (see SVG, for example).  There is/was a field called \u201cDesign Recovery\u201d that researched possible approaches to recovering semantic information (I witnessed such techniques being used for fixing Y2K problems, which would have been lessened if they had kept the source code and would not have equated \u201cdates\u201d with girls\u2019 names in some of the code)."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1686169579.523179",
        "parent_user_id": "U02U0AS3J49"
    },
    {
        "client_msg_id": "f5af1893-a0d4-460e-b843-cd5bd07eee95",
        "type": "message",
        "text": "There are reasons to develop visually that don't have to do with adding semantic information. And the reason to be able to round trip might be to facilitate collaboration between people who prefer different interfaces, visual or text.",
        "user": "U02U0AS3J49",
        "ts": "1686196197.557409",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ZCwkA",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "There are reasons to develop visually that don't have to do with adding semantic information. And the reason to be able to round trip might be to facilitate collaboration between people who prefer different interfaces, visual or text."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1686169579.523179",
        "parent_user_id": "U02U0AS3J49",
        "reactions": [
            {
                "name": "heavy_plus_sign",
                "users": [
                    "U016VUZGUUQ"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "05d4ecd3-8d19-4c27-b323-d96e7bc56b02",
        "type": "message",
        "text": "At least JetBrains MPS has been used to create DSLs with both visual and textual projections as well as (at least) writing to text files. Also my \"projectional language workbench\" generates a \"headless\" \"AST editor engine\" which can then be used, as you said, anyway you like. It exposes both the linearized version (for textual projections) and the tree structure (for visual projections). Currently I've only been working on the textual projection (which is a lot harder issue), but adding a 'blocky' projection should be just about writing the UI code. To read and write actual text files to and from the AST, a parser and an unparser should be implemented. Certainly possible but there's extra challenge in keeping the whitespaces when parsing and only writing minimal changes when unparsing. When parsing, the whitespace info should be stored in the AST that is then modified by the projectional editor. Now, it would be quite a bit easier if you wouldn't care that reading a text file, doing a minimal change in the projectional editor and writing back to a text file might change formatting for the whole file.",
        "user": "U0296ACR13M",
        "ts": "1686207130.137449",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "NhP",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "At least JetBrains MPS has been used to create DSLs with both visual and textual projections as well as (at least) writing to text files. Also my \"projectional language workbench\" generates a \"headless\" \"AST editor engine\" which can then be used, as you said, anyway you like. It exposes both the linearized version (for textual projections) and the tree structure (for visual projections). Currently I've only been working on the textual projection (which is a lot harder issue), but adding a 'blocky' projection should be just about writing the UI code. To read and write actual text files to and from the AST, a parser and an unparser should be implemented. Certainly possible but there's extra challenge in keeping the whitespaces when parsing and only writing minimal changes when unparsing. When parsing, the whitespace info should be stored in the AST that is then modified by the projectional editor. Now, it would be quite a bit easier if you wouldn't care that reading a text file, doing a minimal change in the projectional editor and writing back to a text file might change formatting for the whole file."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1686169579.523179",
        "parent_user_id": "U02U0AS3J49"
    },
    {
        "client_msg_id": "e022cca9-36e1-42ea-b19e-576e1cbeec17",
        "type": "message",
        "text": "One approach to the text file round tripping could be to have the contents always follow strict formatting rules. Then the parser wouldn't need to care about formatting and the unparser would always just write according to those rules.",
        "user": "U0296ACR13M",
        "ts": "1686208034.870459",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "vTh+",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "One approach to the text file round tripping could be to have the contents always follow strict formatting rules. Then the parser wouldn't need to care about formatting and the unparser would always just write according to those rules."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1686169579.523179",
        "parent_user_id": "U02U0AS3J49",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U02U0AS3J49"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "56728bd1-58c5-475f-a8fd-396443b5d735",
        "type": "message",
        "text": "I've gotten as far as concluding that each projection, text or VPL or whatever, needs to have format-specific metadata associated with each abstract AST (that is, each individual document). eg the text projection will remember whitespace, the VPL projection might remember position constraints, color, etc. You need to handle defaults for the first time you project into a particular format, e.g. initial whitespacing. Probably there are also other hideous edge cases, the absolute worst intersection of naming things and cache invalidation; I'm sure the off-by-one errors are just waiting for their chance too. (I'm also thinking of this in the context of, say, bidirectional sync of documents in different formats).",
        "user": "U016VUZGUUQ",
        "ts": "1686282325.403339",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "jvQF3",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I've gotten as far as concluding that each projection, text or VPL or whatever, needs to have format-specific metadata associated with each abstract AST (that is, each individual document). eg the text projection will remember whitespace, the VPL projection might remember position constraints, color, etc. You need to handle defaults for the first time you project into a particular format, e.g. initial whitespacing. Probably there are also other hideous edge cases, the absolute worst intersection of naming things and cache invalidation; I'm sure the off-by-one errors are just waiting for their chance too. (I'm also thinking of this in the context of, say, bidirectional sync of documents in different formats)."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1686169579.523179",
        "parent_user_id": "U02U0AS3J49"
    },
    {
        "client_msg_id": "a1f5b0b4-6c7c-40ec-a584-875ca2a4340d",
        "type": "message",
        "text": "I haven't tried this, but maybe writing to postgrest wrapping a postgres db, with Grafana providing the graphs? Postgrest is a smidge intimidating, especially the auth situation, but maybe still easier than handrolling something. Otoh, a very small single-endpoint web server that writes to postgres, which is read from grafana, might be a good compromise... (Thinking out loud at this point)",
        "user": "U016VUZGUUQ",
        "ts": "1686282568.830969",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "dPa8g",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I haven't tried this, but maybe writing to postgrest wrapping a postgres db, with Grafana providing the graphs? Postgrest is a smidge intimidating, especially the auth situation, but maybe still easier than handrolling something. Otoh, a very small single-endpoint web server that writes to postgres, which is read from grafana, might be a good compromise... (Thinking out loud at this point)"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1686164858.059869",
        "parent_user_id": "UFS53UWE5"
    },
    {
        "client_msg_id": "29aef815-85ef-4bef-989f-855c7d3570b1",
        "type": "message",
        "text": "I ended up trying a *lot* of stuff. But ended with hosted InfluxDB + Grafana. Works well enough. Influx has a POST Rest API, and it's all pretty easy to query in Grafana.",
        "user": "UFS53UWE5",
        "ts": "1686282635.285699",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "etuPz",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I ended up trying a "
                            },
                            {
                                "type": "text",
                                "text": "lot",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " of stuff. But ended with hosted InfluxDB + Grafana. Works well enough. Influx has a POST Rest API, and it's all pretty easy to query in Grafana."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1686164858.059869",
        "parent_user_id": "UFS53UWE5",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U016VUZGUUQ"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "96630d5f-230c-4715-b474-e602f8b06ca6",
        "type": "message",
        "text": "Luckily Influx has a pay-as-you-go permanent storage option, too.",
        "user": "UFS53UWE5",
        "ts": "1686282649.287129",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "+rg7",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Luckily Influx has a pay-as-you-go permanent storage option, too."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1686164858.059869",
        "parent_user_id": "UFS53UWE5"
    },
    {
        "client_msg_id": "ce1d361b-c87d-4df1-bdcd-995ad0c77ec4",
        "type": "message",
        "text": "Hadn't tried postgrest, though! I considered TimescaleDB which is on Postgres, but it requires you to map out the schemas in advance.",
        "user": "UFS53UWE5",
        "ts": "1686282674.169299",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "LhkA",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Hadn't tried postgrest, though! I considered TimescaleDB which is on Postgres, but it requires you to map out the schemas in advance."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1686164858.059869",
        "parent_user_id": "UFS53UWE5"
    },
    {
        "client_msg_id": "fb7bde8a-3333-410f-b0b9-71c0c1f988b1",
        "type": "message",
        "text": "The other contender was Graphite, which is essentially built just for this purpose, but it's pretty old and kludgy.",
        "user": "UFS53UWE5",
        "ts": "1686282694.153149",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "OWdKx",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The other contender was Graphite, which is essentially built just for this purpose, but it's pretty old and kludgy."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1686164858.059869",
        "parent_user_id": "UFS53UWE5"
    },
    {
        "client_msg_id": "5a496f37-2ad7-46b2-bc0f-1c4c13617b01",
        "type": "message",
        "text": "\u201cThere are reasons to develop visually that don\u2019t have to do with adding semantic information.\u201d\nI would be grateful to learn more about this.",
        "user": "UGWUJUZHT",
        "ts": "1686303457.179749",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "3VjgC",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\u201cThere are reasons to develop visually that don\u2019t have to do with adding semantic information.\u201d\nI would be grateful to learn more about this."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1686169579.523179",
        "parent_user_id": "U02U0AS3J49"
    },
    {
        "client_msg_id": "88b89642-7859-4105-903f-b878534b4c5d",
        "type": "message",
        "text": "If your visual language is a one-for-one recreation of the text semantics, it may still, by virtue of being visual, allow you to use full words instead of symbols, illustrate the syntax structures, and make various kinds of syntactical errors impossible.",
        "user": "U02U0AS3J49",
        "ts": "1686316135.553889",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ul0z",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "If your visual language is a one-for-one recreation of the text semantics, it may still, by virtue of being visual, allow you to use full words instead of symbols, illustrate the syntax structures, and make various kinds of syntactical errors impossible."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1686169579.523179",
        "parent_user_id": "U02U0AS3J49"
    },
    {
        "client_msg_id": "66437382-bb8a-45cd-b652-939eeb04ca7c",
        "type": "message",
        "text": "<@U016VUZGUUQ> that's more or less where I have landed, too. But it feels easier to just say all that data is liable to be forgotten when you save and reload, because you aren't editing the interface, you are editing the AST, and those details have no meaning inside the AST, so just deal. But maybe that's too unfriendly.",
        "user": "U02U0AS3J49",
        "ts": "1686316350.117069",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "KKx6P",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U016VUZGUUQ"
                            },
                            {
                                "type": "text",
                                "text": " that's more or less where I have landed, too. But it feels easier to just say all that data is liable to be forgotten when you save and reload, because you aren't editing the interface, you are editing the AST, and those details have no meaning inside the AST, so just deal. But maybe that's too unfriendly."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1686169579.523179",
        "parent_user_id": "U02U0AS3J49"
    },
    {
        "client_msg_id": "4312aef9-97e5-43cd-8d1f-2d19dee121ed",
        "type": "message",
        "text": "As an answer to both <@U02U0AS3J49> and <@UGWUJUZHT>, friendliness is usually the core goal of a vpl. :) At least as far as I can tell. Otherwise we would just make people deal with syntax errors.",
        "user": "U016VUZGUUQ",
        "ts": "1686330984.885939",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "qMJf",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "As an answer to both "
                            },
                            {
                                "type": "user",
                                "user_id": "U02U0AS3J49"
                            },
                            {
                                "type": "text",
                                "text": " and "
                            },
                            {
                                "type": "user",
                                "user_id": "UGWUJUZHT"
                            },
                            {
                                "type": "text",
                                "text": ", friendliness is usually the core goal of a vpl. :) At least as far as I can tell. Otherwise we would just make people deal with syntax errors."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1686169579.523179",
        "parent_user_id": "U02U0AS3J49"
    }
]