[
    {
        "client_msg_id": "c800bcdb-16dd-4287-9d2c-12bf301056dd",
        "type": "message",
        "text": "I think that often the most difficult part of programming is debugging: humans aren't very good at \"seeing\" how an app operated when it failed. You get some log output that might or might not have references to the correct file locations.\n\nI don't see any reason, in the long term, why humans would be better than machines at debugging. How to make that happen? I assume somebody is building this already. Would it help if an AI with a large context window + access to the VM could see the whole call logs/tree and see exactly what is going on?  AI could learn from other users, see everything that happens in a run without debugger/console.logs, try multiple solutions in parallel, and fix issues while you sleep.\n\nThoughts on this?",
        "user": "UEQ7QL15F",
        "ts": "1700837030.649029",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Jpinl",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I think that often the most difficult part of programming is debugging: humans aren't very good at \"seeing\" how an app operated when it failed. You get some log output that might or might not have references to the correct file locations.\n\nI don't see any reason, in the long term, why humans would be better than machines at debugging. How to make that happen? I assume somebody is building this already. Would it help if an AI with a large context window + access to the VM could see the whole call logs/tree and see exactly what is going on?  AI could learn from other users, see everything that happens in a run without debugger/console.logs, try multiple solutions in parallel, and fix issues while you sleep.\n\nThoughts on this?"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UEQ7QL15F",
            "ts": "1700837040.000000"
        },
        "thread_ts": "1700837030.649029",
        "reply_count": 16,
        "reply_users_count": 8,
        "latest_reply": "1700992684.232459",
        "reply_users": [
            "UCUSW7WVD",
            "UKJGU23KP",
            "UE6EFEPTQ",
            "UE1JQM9HQ",
            "UJBAJNFLK",
            "UC2A2ARPT",
            "U0166ETPH61",
            "U016VUZGUUQ"
        ],
        "is_locked": false,
        "subscribed": false
    },
    {
        "client_msg_id": "38ab7707-5676-4853-b9d7-1b5fcee3ccc1",
        "type": "message",
        "text": "In principle, LLMs could help here if they make reliable inferences and stop hallucinating facts. It'll be interesting to see how far those preconditions are achieved. Without them, you'd constantly have to debug your debugger.",
        "user": "UCUSW7WVD",
        "ts": "1700838146.560819",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "16P8i",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "In principle, LLMs could help here if they make reliable inferences and stop hallucinating facts. It'll be interesting to see how far those preconditions are achieved. Without them, you'd constantly have to debug your debugger."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1700837030.649029",
        "parent_user_id": "UEQ7QL15F"
    },
    {
        "client_msg_id": "9496C7B1-3603-4136-B574-0D316DB567F2",
        "type": "message",
        "text": "A lot of the times I\u2019m most comfortable with LLMs is where I can easily check their output. Debugging is often going to work like that. ",
        "user": "UKJGU23KP",
        "ts": "1700845438.775949",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "8RuDO",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "A lot of the times "
                            },
                            {
                                "type": "text",
                                "text": "I\u2019m"
                            },
                            {
                                "type": "text",
                                "text": " most comfortable with LLMs is where I can easily check their output. Debugging is often going to work like that. "
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1700837030.649029",
        "parent_user_id": "UEQ7QL15F",
        "reactions": [
            {
                "name": "100",
                "users": [
                    "UCUSW7WVD",
                    "UEQ7QL15F",
                    "UC2A2ARPT",
                    "U05UBCXHWM6"
                ],
                "count": 4
            }
        ]
    },
    {
        "client_msg_id": "2413ac1e-daba-4d15-b070-5a40565ce6af",
        "type": "message",
        "text": "I agree with your first sentence but not your second. I've often made a bugfix that addressed the _specific_ scenario I was repeatedly manually testing without understanding why, and as a result not fixing some other situations (and often breaking additional ones). My \"explanations\" can be rationalizations. Debugging is a process of understanding. You can't really judge if a bug has been fixed without understanding why it happened.\n\nMy suspicion is that LLMs will be really good at making the \"letter\" of arbitrary tests pass without quite meeting the \"spirit\" of the tests.",
        "user": "UCUSW7WVD",
        "ts": "1700846323.336329",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "VYlS8",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I agree with your first sentence but not your second. I've often made a bugfix that addressed the "
                            },
                            {
                                "type": "text",
                                "text": "specific",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " scenario I was repeatedly manually testing without understanding why, and as a result not fixing some other situations (and often breaking additional ones). My \"explanations\" can be rationalizations. Debugging is a process of understanding. You can't really judge if a bug has been fixed without understanding why it happened.\n\nMy suspicion is that LLMs will be really good at making the \"letter\" of arbitrary tests pass without quite meeting the \"spirit\" of the tests."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1700837030.649029",
        "parent_user_id": "UEQ7QL15F",
        "reactions": [
            {
                "name": "pray",
                "users": [
                    "URKQXRCAC"
                ],
                "count": 1
            },
            {
                "name": "heavy_plus_sign",
                "users": [
                    "U05BRNRAC4V"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "13DF2F6D-9D0E-494F-8F4B-A5A842464968",
        "type": "message",
        "text": "I think I agree, but I meant \u201cif you had an LLM where it frequently gave the right fix a significant fraction of the time.\u201d I think that\u2019s a high bar, that they\u2019re not close to meeting yet. \n\nBut in my response, I didn\u2019t mean \u201ccheck\u201d merely as in \u201cthe tests pass\u201d, but that you understand the change. \n\nAnd I think that in that sense, it\u2019s true that you could imagine working with a not fully reliable AI and getting benefits from it. \n\nLeaving aside truly trivial bugs, I think in the majority of cases I work, finding the fix will take me noticeably longer than understanding why a candidate fix works. That\u2019s why I can code review a coworker\u2019s fix faster than I can make it myself (even if they don\u2019t comment their fix). \n\nSo I think the target isn\u2019t \u201cyou trust this checking things into your codebase\u201d, but \u201ccan often find the offending line/offer a fix that you can take or leave.\u201d",
        "user": "UKJGU23KP",
        "ts": "1700850005.253759",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "mg+vy",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I think I agree, but I meant \u201cif you had an LLM where it frequently gave the right fix a significant fraction of the time.\u201d I think "
                            },
                            {
                                "type": "text",
                                "text": "that\u2019s"
                            },
                            {
                                "type": "text",
                                "text": " a high bar, that "
                            },
                            {
                                "type": "text",
                                "text": "they\u2019re"
                            },
                            {
                                "type": "text",
                                "text": " not close to meeting yet. \n\nBut in my response, I "
                            },
                            {
                                "type": "text",
                                "text": "didn\u2019t"
                            },
                            {
                                "type": "text",
                                "text": " mean \u201ccheck\u201d merely as in \u201cthe tests pass\u201d, but that you understand the change. \n\nAnd I think that in that sense, "
                            },
                            {
                                "type": "text",
                                "text": "it\u2019s"
                            },
                            {
                                "type": "text",
                                "text": " true that you could imagine working with a not fully reliable AI and getting benefits from it. \n\nLeaving aside truly trivial bugs, I think in the majority of cases I work, finding the fix will take me noticeably longer than understanding why a candidate fix works. "
                            },
                            {
                                "type": "text",
                                "text": "That\u2019s"
                            },
                            {
                                "type": "text",
                                "text": " why I can code review a coworker\u2019s fix faster than I can make it myself (even if they "
                            },
                            {
                                "type": "text",
                                "text": "don\u2019t"
                            },
                            {
                                "type": "text",
                                "text": " comment their fix). \n\nSo I think the "
                            },
                            {
                                "type": "text",
                                "text": "target isn\u2019t"
                            },
                            {
                                "type": "text",
                                "text": " \u201cyou trust this checking things into your codebase\u201d, but \u201ccan often find the offending line/offer a fix that you can take or leave.\u201d"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1700837030.649029",
        "parent_user_id": "UEQ7QL15F"
    },
    {
        "client_msg_id": "6602356c-ec5c-451b-a881-9e07f3d60583",
        "type": "message",
        "text": "I see what you mean. The open question here seems to be about AI \"pragmatics\" in the sense of <https://en.wikiversity.org/wiki/Semantics_vs_pragmatics>. Perhaps I'm airing incompetence here, but I seldom check my coworkers' _logic_ in PRs. I mostly check product concerns (are we building the right thing?), process concerns (e.g. are the right things documented?) and architecture (does this PR change roughly the places I would expect?). For logic we rely on tests, and I build up trust over time in the people (entities) I work with (or give feedback to try to gain trust).\n\nI worry that an AI might be good at slipping through these heuristics of mine while performing its (automated or manual) tests in an antagonistic manner. Will it share my values and those of the broader culture I'm embedded in? Can I build up confidence over time that it shares my values, the way I can for the people I work with. Perhaps I'm still prejudiced because I don't live cheek by jowl with AIs yet :sweat_smile:",
        "user": "UCUSW7WVD",
        "ts": "1700852130.328389",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "PAfzi",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I see what you mean. The open question here seems to be about AI \"pragmatics\" in the sense of "
                            },
                            {
                                "type": "link",
                                "url": "https://en.wikiversity.org/wiki/Semantics_vs_pragmatics"
                            },
                            {
                                "type": "text",
                                "text": ". Perhaps I'm airing incompetence here, but I seldom check my coworkers' "
                            },
                            {
                                "type": "text",
                                "text": "logic",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " in PRs. I mostly check product concerns (are we building the right thing?), process concerns (e.g. are the right things documented?) and architecture (does this PR change roughly the places I would expect?). For logic we rely on tests, and I build up trust over time in the people (entities) I work with (or give feedback to try to gain trust).\n\nI worry that an AI might be good at slipping through these heuristics of mine while performing its (automated or manual) tests in an antagonistic manner. Will it share my values and those of the broader culture I'm embedded in? Can I build up confidence over time that it shares my values, the way I can for the people I work with. Perhaps I'm still prejudiced because I don't live cheek by jowl with AIs yet "
                            },
                            {
                                "type": "emoji",
                                "name": "sweat_smile",
                                "unicode": "1f605"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UCUSW7WVD",
            "ts": "1700852261.000000"
        },
        "thread_ts": "1700837030.649029",
        "parent_user_id": "UEQ7QL15F",
        "reactions": [
            {
                "name": "thinking_face",
                "users": [
                    "UEQ7QL15F"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "a90f4734-7178-4c5e-9b31-377085ec77b0",
        "type": "message",
        "text": "I was about to flippantly say that I'm best at debugging when I've had a solid drink of beer or wine to start me off. But in fact, that's what is needed, human or AI: to take away the personal commitment to what you've done, and got wrong.",
        "user": "UE6EFEPTQ",
        "ts": "1700869316.785959",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "MxEJm",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I was about to flippantly say that I'm best at debugging when I've had a solid drink of beer or wine to start me off. But in fact, that's what is needed, human or AI: to take away the personal commitment to what you've done, and got wrong."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1700837030.649029",
        "parent_user_id": "UEQ7QL15F"
    },
    {
        "client_msg_id": "6359973A-83BB-42A1-B42A-7C77784EA087",
        "type": "message",
        "text": "Humans can get many times better than today at figuring systems out. That is the premise of Moldable Development. By now we have good evidence that an order of magnitude is attainable without extraordinary effort (and no AI). AI has the potential of improving this even further, but not in how people use it today.",
        "user": "UE1JQM9HQ",
        "ts": "1700902191.504349",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "HWckg",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Humans can get many times better than today at figuring systems out. That is the premise of Moldable Development. By now we have good evidence that an order of magnitude is attainable without extraordinary effort (and no AI). AI has the potential of improving this even further, but not in how people use it today."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1700837030.649029",
        "parent_user_id": "UEQ7QL15F"
    },
    {
        "client_msg_id": "afa56149-c126-4d92-bbeb-4dce1a3eb345",
        "type": "message",
        "text": "Bold claims, no \"Moldable Development\" link!",
        "user": "UE6EFEPTQ",
        "ts": "1700904931.823659",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "RM3O5",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Bold claims, no \"Moldable Development\" link!"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1700837030.649029",
        "parent_user_id": "UEQ7QL15F"
    },
    {
        "client_msg_id": "49e50a88-feac-4f93-8a56-741d25d4904e",
        "type": "message",
        "text": "<https://moldabledevelopment.com/>",
        "user": "UJBAJNFLK",
        "ts": "1700931987.738469",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Uj6RR",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "link",
                                "url": "https://moldabledevelopment.com/"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1700837030.649029",
        "parent_user_id": "UEQ7QL15F"
    },
    {
        "client_msg_id": "b59f1588-1e55-4c7a-bbb6-3c5527ee511d",
        "type": "message",
        "text": "<https://futureofcoding.org/episodes/036|Future of Coding episode 36 \u2014 Moldable Development: Tudor Girba>",
        "user": "UC2A2ARPT",
        "ts": "1700934023.595229",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "llw13",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "link",
                                "url": "https://futureofcoding.org/episodes/036",
                                "text": "Future of Coding episode 36 \u2014 Moldable Development: Tudor Girba"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1700837030.649029",
        "parent_user_id": "UEQ7QL15F",
        "reactions": [
            {
                "name": "point_up::skin-tone-3",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "045F21AA-4A8B-4E58-BAC7-6DAFC8344105",
        "type": "message",
        "text": "&gt; debugging: humans aren't very good at \"seeing\" how an app operated when it failed.\nI think about this a lot, how we are usually limited to the sense of sight when coding. Unlike trying to fix a machine or figure out a problem IRL, we can\u2019t feel our way to shift and steer the code out of the snowbank. We can\u2019t listen to the sounds of loose parts rattling around in the code while debugging. ",
        "user": "U0166ETPH61",
        "ts": "1700949717.793379",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "7jVsK",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "debugging: humans aren't very good at \"seeing\" how an app operated when it failed."
                            }
                        ],
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nI think about this a lot, how we are usually limited to the sense of sight when coding. Unlike trying to fix a machine or figure out a problem IRL, we "
                            },
                            {
                                "type": "text",
                                "text": "can\u2019t fe"
                            },
                            {
                                "type": "text",
                                "text": "el our way to shift and steer the code out of the snowbank. We "
                            },
                            {
                                "type": "text",
                                "text": "can\u2019t"
                            },
                            {
                                "type": "text",
                                "text": " listen to the sounds of loose parts rattling around in the code while debugging. "
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1700837030.649029",
        "parent_user_id": "UEQ7QL15F"
    },
    {
        "client_msg_id": "0865BD37-DDA7-4CCF-81E1-494EDFBAE81E",
        "type": "message",
        "text": "<@UCUSW7WVD> That\u2019s reasonable. \n\nFor a I wouldn\u2019t say I usually check my coworkers\u2019 logic adversarially, but I usually take time to see \u201cdo I see how this fixes the bug.\u201d More often than not I can tell quickly\u2014not to the point that I\u2019m sure there are no errors, but I usually get the gist of the change. When I don\u2019t, I tend to ask, because it\u2019s an opportunity to document/clarify.",
        "user": "UKJGU23KP",
        "ts": "1700953116.711729",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "qzWhj",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UCUSW7WVD"
                            },
                            {
                                "type": "text",
                                "text": " That\u2019s reasonable. \n\nFor a I wouldn\u2019t say I usually check my coworkers\u2019 logic adversarially, but I usually take time to see \u201cdo I see how this fixes the bug.\u201d More often than not I can tell quickly"
                            },
                            {
                                "type": "text",
                                "text": "\u2014"
                            },
                            {
                                "type": "text",
                                "text": "not to the point that "
                            },
                            {
                                "type": "text",
                                "text": "I\u2019m"
                            },
                            {
                                "type": "text",
                                "text": " sure there are no errors, but I usually get the gist of the change. When "
                            },
                            {
                                "type": "text",
                                "text": "I don\u2019t"
                            },
                            {
                                "type": "text",
                                "text": ", I tend to ask, because "
                            },
                            {
                                "type": "text",
                                "text": "it\u2019s"
                            },
                            {
                                "type": "text",
                                "text": " an opportunity to document/clarify."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1700837030.649029",
        "parent_user_id": "UEQ7QL15F",
        "reactions": [
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "41658DD5-EE8E-4AB8-ABDB-F8074C1EA151",
        "type": "message",
        "text": "I don\u2019t use it often, but sound can be a really interesting debugging mechanism\u2014play a little warble every time a particular method is entered, and you may be able to just hear when something unusual happens.",
        "user": "UKJGU23KP",
        "ts": "1700953192.273329",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "B7nHD",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I "
                            },
                            {
                                "type": "text",
                                "text": "don\u2019t"
                            },
                            {
                                "type": "text",
                                "text": " use it often, but sound can be a really interesting debugging mechanism"
                            },
                            {
                                "type": "text",
                                "text": "\u2014"
                            },
                            {
                                "type": "text",
                                "text": "play a little warble every time a particular method is entered, and you may be able to just hear when something unusual happens."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1700837030.649029",
        "parent_user_id": "UEQ7QL15F",
        "reactions": [
            {
                "name": "bulb",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "342acb8a-31cc-4876-8ed0-860c05f8ca52",
        "type": "message",
        "text": "Among other concerns with machine debugging: humans are the arbiters of what constitutes buggy behavior. So at minimum you need a human providing a more detailed bug description than \"it's not working. you know, the thingy\" (dramatized version of real bug reports). I suspect that problem will propagate to deeper stages of the debugging process as well, where it can't be trivially eliminated with boring language safety/formal methods.",
        "user": "U016VUZGUUQ",
        "ts": "1700963832.047319",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "TI5i0",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Among other concerns with machine debugging: humans are the arbiters of what constitutes buggy behavior. So at minimum you need a human providing a more detailed bug description than \"it's not working. you know, the thingy\" (dramatized version of real bug reports). I suspect that problem will propagate to deeper stages of the debugging process as well, where it can't be trivially eliminated with boring language safety/formal methods."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1700837030.649029",
        "parent_user_id": "UEQ7QL15F"
    },
    {
        "client_msg_id": "8167C7A6-83FF-48A9-A317-1FB7CE54C8A6",
        "type": "message",
        "text": "<@UE6EFEPTQ> I can understand how the claim is bold. Perhaps a bolder claim is that the act of building custom tools for \u201creading\u201d systems compresses communication and by this it changes the nature of programming.\n\nBeside the links provided by others above, please take a look at Glamorous Toolkit. We built it to show how Moldable Development works in practice, and to offer an elaborate case study people can learn from, too:\n<https://gtoolkit.com|https://gtoolkit.com> ",
        "user": "UE1JQM9HQ",
        "ts": "1700967803.133219",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "tgVDW",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UE6EFEPTQ"
                            },
                            {
                                "type": "text",
                                "text": " I can understand how the claim is bold. Perhaps a bolder claim is that the act of building custom tools for \u201creading\u201d systems compresses communication and by this it changes the nature of programming.\n\nBeside the links provided by others above, please take a look at Glamorous Toolkit. We built it to show how Moldable Development works in practice, and to offer an elaborate case study people can learn from, too:\n"
                            },
                            {
                                "type": "link",
                                "url": "https://gtoolkit.com",
                                "text": "https://gtoolkit.com"
                            },
                            {
                                "type": "text",
                                "text": " "
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "from_url": "https://gtoolkit.com/",
                "service_icon": "https://gtoolkit.com/favicon.ico",
                "thumb_url": "https://gtoolkit.com//assets/pictures/glamoroustoolkit-icon.png",
                "thumb_width": 1496,
                "thumb_height": 272,
                "id": 1,
                "original_url": "https://gtoolkit.com",
                "fallback": "Glamorous Toolkit: Home",
                "text": "Glamorous Toolkit is the Moldable Development environment.",
                "title": "Home",
                "title_link": "https://gtoolkit.com/",
                "service_name": "Glamorous Toolkit"
            }
        ],
        "thread_ts": "1700837030.649029",
        "parent_user_id": "UEQ7QL15F"
    },
    {
        "client_msg_id": "104a3d80-f160-4992-a65d-69560c91b4be",
        "type": "message",
        "text": "I believe that <@UE1JQM9HQ>'s bold claim is justified, but I do so after a few years of exposure to and then active use of moldable development as supported by Glamorous Toolkit. I am not sure there is a way to judge the claim without actually investing some serious efforts to gain personal experience. But it's one of those ideas that, in the end, you wonder how you ever did without. I have had only a few similar experiences in 40 years of using computers: live development, Lisp macros, immutability, version control, and most recently functional package managers. All of these have changed the way I apply computing technology to solve real-world problems (meaning problems that do not come from the computing technology itself).",
        "user": "UJBAJNFLK",
        "ts": "1700992684.232459",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "074+a",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I believe that "
                            },
                            {
                                "type": "user",
                                "user_id": "UE1JQM9HQ"
                            },
                            {
                                "type": "text",
                                "text": "'s bold claim is justified, but I do so after a few years of exposure to and then active use of moldable development as supported by Glamorous Toolkit. I am not sure there is a way to judge the claim without actually investing some serious efforts to gain personal experience. But it's one of those ideas that, in the end, you wonder how you ever did without. I have had only a few similar experiences in 40 years of using computers: live development, Lisp macros, immutability, version control, and most recently functional package managers. All of these have changed the way I apply computing technology to solve real-world problems (meaning problems that do not come from the computing technology itself)."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1700837030.649029",
        "parent_user_id": "UEQ7QL15F",
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "UE1JQM9HQ",
                    "UCUSW7WVD"
                ],
                "count": 2
            }
        ]
    }
]