[
    {
        "client_msg_id": "1e64e35b-419f-44b7-b848-aeb015c9b6d2",
        "type": "message",
        "text": "Branching out from the discussions about the current state of AI agents vs. how they were imagined in the text from the recent podcast episode...\n\nI was glad to hear our hosts were on a similar thought-track when discussing the \"send this draft to the rest of the group and let me know when they've read it\" example regarding how programmers tend to parse the last bit as \"let me know when the metrics indicate they scrolled to the end\" (etc) whereas a human agent would parse it as \"and follow up with them after a reasonable time to ask if they've read it or not.\"\n\nOne thing that struck me was the number of times I've told a white lie in that kind of scenario. Yes, I read it! (No, I haven't, but I just pulled it up when you asked and I'm skimming it now before the meeting starts).\n\nDishonesty with the metrics-mindset takes a different form. In simple forms, it's like terms of service pages which gate the \"agree\" button behind a scroll value... You scroll to the end to lie. But if the designers of those metrics were somehow able to perfect them (eye tracking? a quiz at the end?) then an AI agent could force a more accurate/truthful answer from you.\n\nAll that to get to my point... Do we have a right to lie about this stuff? How important is it for us to be able to present less-than-truthful representations to other people even if the medium is via an AI agent? If we don't include this concern in our designs, are we facilitating a world of micro-surveillance of coworkers and friends?",
        "user": "U05G29UQHKK",
        "ts": "1694310307.429679",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ah8",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Branching out from the discussions about the current state of AI agents vs. how they were imagined in the text from the recent podcast episode...\n\nI was glad to hear our hosts were on a similar thought-track when discussing the \"send this draft to the rest of the group and let me know when they've read it\" example regarding how programmers tend to parse the last bit as \"let me know when the metrics indicate they scrolled to the end\" (etc) whereas a human agent would parse it as \"and follow up with them after a reasonable time to ask if they've read it or not.\"\n\nOne thing that struck me was the number of times I've told a white lie in that kind of scenario. Yes, I read it! (No, I haven't, but I just pulled it up when you asked and I'm skimming it now before the meeting starts).\n\nDishonesty with the metrics-mindset takes a different form. In simple forms, it's like terms of service pages which gate the \"agree\" button behind a scroll value... You scroll to the end to lie. But if the designers of those metrics were somehow able to perfect them (eye tracking? a quiz at the end?) then an AI agent could force a more accurate/truthful answer from you.\n\nAll that to get to my point... Do we have a right to lie about this stuff? How important is it for us to be able to present less-than-truthful representations to other people even if the medium is via an AI agent? If we don't include this concern in our designs, are we facilitating a world of micro-surveillance of coworkers and friends?"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1694310307.429679",
        "reply_count": 2,
        "reply_users_count": 2,
        "latest_reply": "1694358695.893869",
        "reply_users": [
            "UFEQUBNNT",
            "UC2A2ARPT"
        ],
        "is_locked": false,
        "subscribed": false,
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "U05597GCDDK"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "EBAB46B7-4B81-48C1-A2EC-F2CD1AF1F9B2",
        "type": "message",
        "text": "Absolutely.\n\nAn app that automatically sends read receipts is often wrong about whether I\u2019ve read something. _That\u2019s_ a lie. If my AI is going to lie, I\u2019d rather it be on my behalf. I don\u2019t think I can even consider it my AI unless its lies are in my interest.",
        "user": "UFEQUBNNT",
        "ts": "1694312701.157499",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "=n+F",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Absolutely.\n\nAn app that automatically sends read receipts is often wrong about whether I\u2019ve read something. "
                            },
                            {
                                "type": "text",
                                "text": "That\u2019s",
                                "style": {
                                    "bold": false,
                                    "italic": true,
                                    "strike": false
                                }
                            },
                            {
                                "type": "text",
                                "text": " a lie. If my AI is going to lie, I\u2019d rather it be on my behalf. I don\u2019t think I can even consider it my AI unless its lies are in my interest."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UFEQUBNNT",
            "ts": "1694312861.000000"
        },
        "thread_ts": "1694310307.429679",
        "parent_user_id": "U05G29UQHKK"
    },
    {
        "client_msg_id": "924BD838-3D24-4754-8FC5-153C51501F48",
        "type": "message",
        "text": "Totally agree with Tom \u2014 we have the right to lie.\n\nFeels relevant: <https://jeffreymoro.com/blog/2020-02-13-against-cop-shit/|https://jeffreymoro.com/blog/2020-02-13-against-cop-shit/>",
        "user": "UC2A2ARPT",
        "ts": "1694358695.893869",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "PNxv",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Totally agree with Tom \u2014 we have the right to lie.\n\nFeels relevant: "
                            },
                            {
                                "type": "link",
                                "url": "https://jeffreymoro.com/blog/2020-02-13-against-cop-shit/",
                                "text": "https://jeffreymoro.com/blog/2020-02-13-against-cop-shit/"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1694310307.429679",
        "parent_user_id": "U05G29UQHKK"
    }
]