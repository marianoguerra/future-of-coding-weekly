[
    {
        "client_msg_id": "db2bbcdb-4bf8-4e29-bcf5-002ceae5073f",
        "type": "message",
        "text": "Oh friends, here we have one of my favorite topics.\n\nLet's with the specific question: parsing documentation out of comments.  If you have a whole language parser on hand (or just the lexer), then you may be able to use that to grab the comments, which you then parse separately.  Feels like overkill, right?  Why not just scan for the comments?  One way to think of it is that the full language parser has a simpler sub-parser that only cares about comments.  It's fun to think of how to automatically transform a full parser to one that just cares about comments.  Or another way is to be clever.  (See also XML where you can get a 90% good parser with 10% of the grammar.)  Your comment marker can only appear in strings of which there are two kinds, oh and regular expressions too, oh and... well at least you can be certain that literals don't cross line boundaries.  Still... something feels off.\n\nConsider how algorithmic parsing (a parser for things is a function from strings to lists of pairs of strings and things) is at odds with how you as a programmer parse things (starting right in the middle looking for fencepost spacing and brackets rarely needing to see the whole file).  Instead of having a complete system, we look around a little bit and guess between with many partial systems (with simpler ones working most of the time) and end goals in mind.  If we see anything too weird, we fudge it to make things fit.  Try reading with a five-year old.  It can be a great challenge to have them focus on the letters in front of them over a fitting word in their head.  How would a more person-like parser work?\n\nSeparately, parsers are interesting for their close connection to all kinds of other traversals.  It's a small step from a streams of tokens (first, rest) to trees (node, left branch, right branch) to the world (here, north, east, south, west), and parsers are unique for how richly they interpret the stream.\n\nA lot to explore.",
        "user": "UA14TGLTC",
        "ts": "1595661754.374900",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gae6d55db9d1",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/3ae6d55db9d15b79bc683a8031fc2588.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0009-72.png",
            "first_name": "",
            "real_name": "William Taysom",
            "display_name": "wtaysom",
            "team": "T5TCAFTA9",
            "name": "wtaysom",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "kBh",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Oh friends, here we have one of my favorite topics.\n\nLet's with the specific question: parsing documentation out of comments.  If you have a whole language parser on hand (or just the lexer), then you may be able to use that to grab the comments, which you then parse separately.  Feels like overkill, right?  Why not just scan for the comments?  One way to think of it is that the full language parser has a simpler sub-parser that only cares about comments.  It's fun to think of how to automatically transform a full parser to one that just cares about comments.  Or another way is to be clever.  (See also XML where you can get a 90% good parser with 10% of the grammar.)  Your comment marker can only appear in strings of which there are two kinds, oh and regular expressions too, oh and... well at least you can be certain that literals don't cross line boundaries.  Still... something feels off.\n\nConsider how algorithmic parsing (a parser for things is a function from strings to lists of pairs of strings and things) is at odds with how you as a programmer parse things (starting right in the middle looking for fencepost spacing and brackets rarely needing to see the whole file).  Instead of having a complete system, we look around a little bit and guess between with many partial systems (with simpler ones working most of the time) and end goals in mind.  If we see anything too weird, we fudge it to make things fit.  Try reading with a five-year old.  It can be a great challenge to have them focus on the letters in front of them over a fitting word in their head.  How would a more person-like parser work?\n\nSeparately, parsers are interesting for their close connection to all kinds of other traversals.  It's a small step from a streams of tokens (first, rest) to trees (node, left branch, right branch) to the world (here, north, east, south, west), and parsers are unique for how richly they interpret the stream.\n\nA lot to explore."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595604347.298300",
        "parent_user_id": "U5STGTB3J"
    }
]