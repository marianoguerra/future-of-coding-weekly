[
    {
        "client_msg_id": "194dda95-5dab-4251-994b-f06f68a4eda1",
        "type": "message",
        "text": "I accept all the boilerplate and layers upon layers of cruft simply because (apart from doing this paying the mortgage), 90% of the time I can type (in vim!) in modern Javascript. I write tests, make them pass, repeat. I get sufficiently immediate feedback to be able to get into a productive work \"zone\". Modern JS is very satisfying and powerful. But I'm a techie, and like all techies I'm an outlier. I wouldn't wish my work life on a non-techie.",
        "user": "UE6EFEPTQ",
        "ts": "1585647371.046200",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "8073c43d5d8d",
            "image_72": "https:\/\/avatars.slack-edge.com\/2018-12-18\/508431502471_8073c43d5d8dd3d3b4b2_72.jpg",
            "first_name": "Duncan",
            "real_name": "Duncan Cragg",
            "display_name": "Duncan Cragg",
            "team": "T5TCAFTA9",
            "name": "fp",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "d2aXO",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I accept all the boilerplate and layers upon layers of cruft simply because (apart from doing this paying the mortgage), 90% of the time I can type (in vim!) in modern Javascript. I write tests, make them pass, repeat. I get sufficiently immediate feedback to be able to get into a productive work \"zone\". Modern JS is very satisfying and powerful. But I'm a techie, and like all techies I'm an outlier. I wouldn't wish my work life on a non-techie."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585616341.042100",
        "parent_user_id": "UBSMEUXAA"
    },
    {
        "client_msg_id": "a0266b8d-61f6-4f39-8de8-f393d2242b5e",
        "type": "message",
        "text": "Part of the satisfaction is being able to work in a very low bureaucracy tech shop where I (and newbie grads) can put to live without asking anyone.",
        "user": "UE6EFEPTQ",
        "ts": "1585647474.046400",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "8073c43d5d8d",
            "image_72": "https:\/\/avatars.slack-edge.com\/2018-12-18\/508431502471_8073c43d5d8dd3d3b4b2_72.jpg",
            "first_name": "Duncan",
            "real_name": "Duncan Cragg",
            "display_name": "Duncan Cragg",
            "team": "T5TCAFTA9",
            "name": "fp",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ukJkT",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Part of the satisfaction is being able to work in a very low bureaucracy tech shop where I (and newbie grads) can put to live without asking anyone."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585616341.042100",
        "parent_user_id": "UBSMEUXAA"
    },
    {
        "client_msg_id": "2b756d1d-1d38-4753-96ea-ab4064014440",
        "type": "message",
        "text": "Vim?  Vim?!  Man, I was the one who passed around the original TextMate peace pipe in 2003.  This was before hotel WiFi.  At Ruby Conf we shared USB.",
        "user": "UA14TGLTC",
        "ts": "1585647495.046600",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gae6d55db9d1",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/3ae6d55db9d15b79bc683a8031fc2588.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0009-72.png",
            "first_name": "",
            "real_name": "William Taysom",
            "display_name": "wtaysom",
            "team": "T5TCAFTA9",
            "name": "wtaysom",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "JfnEg",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Vim?  Vim?!  Man, I was the one who passed around the original TextMate peace pipe in 2003.  This was before hotel WiFi.  At Ruby Conf we shared USB."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585592468.037600",
        "parent_user_id": "UUMQH3TA5",
        "reactions": [
            {
                "name": "v",
                "users": [
                    "UUMQH3TA5",
                    "UC2A2ARPT"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "72864aa7-56c7-43f0-933a-acb3b6f09305",
        "type": "message",
        "text": "<@UEQ6M68H0> I'm using the term macro broadly. I could also be using the term \"template\" in its place. I'm referring to any language construct that describes a pattern with details to be filled in. Accordingly, my definition is independent of any compilation or execution details. My original assertion is that any realisation of this broad concept can fulfil the role that you claim functions with call\/return semantics need to fill. Unfortunately, I can't give you a concrete example of a macro\/template feature in a language that is implemented by a means other than functions or a debug-harming preprocessing step. But that's because the status quo of programming is functions (and sometimes preprocessing), which brings us full circle. Hopefully you can see that this broad definition admits other approaches for a language that doesn't include functions. A compiler with \"smart preprocessing\" that preserves the mapping between the original source and the (opaque, implementation-defined) runtime representation is probably the basis for any approach.",
        "user": "UCGAK10LS",
        "ts": "1585649650.046800",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "770c193fd379",
            "image_72": "https:\/\/avatars.slack-edge.com\/2020-04-17\/1092364753072_770c193fd379ebbced3f_72.jpg",
            "first_name": "",
            "real_name": "Nick Smith",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "nmsmith65",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "edited": {
            "user": "UCGAK10LS",
            "ts": "1585650022.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "6hJE",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UEQ6M68H0"
                            },
                            {
                                "type": "text",
                                "text": " I'm using the term macro broadly. I could also be using the term \"template\" in its place. I'm referring to any language construct that describes a pattern with details to be filled in. Accordingly, my definition is independent of any compilation or execution details. My original assertion is that any realisation of this broad concept can fulfil the role that you claim functions with call\/return semantics need to fill. Unfortunately, I can't give you a concrete example of a macro\/template feature in a language that is implemented by a means other than functions or a debug-harming preprocessing step. But that's because the status quo of programming is functions (and sometimes preprocessing), which brings us full circle. Hopefully you can see that this broad definition admits other approaches for a language that doesn't include functions. A compiler with \"smart preprocessing\" that preserves the mapping between the original source and the (opaque, implementation-defined) runtime representation is probably the basis for any approach."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1"
    },
    {
        "client_msg_id": "6cc729f7-abbf-449c-8b57-53fb283a920a",
        "type": "message",
        "text": "what kinda online training do you do <@UC2A2ARPT>? Just curious, I just got out of an online learning business (not quite training though)",
        "user": "UAJKEBGP8",
        "ts": "1585654653.047500",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "ge0cf3605817",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/be0cf3605817ed3839061421303ee896.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png",
            "first_name": "",
            "real_name": "Srini Kadamati",
            "display_name": "srini",
            "team": "T5TCAFTA9",
            "name": "skadamat",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "oPA",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "what kinda online training do you do "
                            },
                            {
                                "type": "user",
                                "user_id": "UC2A2ARPT"
                            },
                            {
                                "type": "text",
                                "text": "? Just curious, I just got out of an online learning business (not quite training though)"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585583686.028900",
        "parent_user_id": "USEQV4KCH"
    },
    {
        "client_msg_id": "755BC1C4-D59D-469C-9854-A641FE9868D2",
        "type": "message",
        "text": "<https:\/\/www.lunchboxsessions.com> Main customers are resources, manufacturing, logistics, colleges, and a little bit of aerospace. \"Training\" is a bit of a misnomer, it's just a collection of resources that can be used self-directed or by a teacher in a class. Our specialty is interactive system simulations, and I mostly develop the tooling our artists use to build those. I also built the web site (all design, frontend, backend), since I'm the only actual dev in the company.\n\nThe FoC project I'm working on (Hest) is something we're planning to use internally to make interactive simulations, though I'm designing it to be general purpose.",
        "user": "UC2A2ARPT",
        "ts": "1585669684.048100",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gf94d2ed5e18",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6f94d2ed5e188be9865a531021b0afcd.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0013-72.png",
            "first_name": "Ivan",
            "real_name": "Ivan Reese",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "ivanreese",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "edited": {
            "user": "UC2A2ARPT",
            "ts": "1585672886.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "0tL",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "link",
                                "url": "https:\/\/www.lunchboxsessions.com"
                            },
                            {
                                "type": "text",
                                "text": " Main customers are resources, manufacturing, logistics, colleges, and a little bit of aerospace. \"Training\" is a bit of a misnomer, it's just a collection of resources that can be used self-directed or by a teacher in a class. Our specialty is interactive system simulations, and I mostly develop the tooling our artists use to build those. I also built the web site (all design, frontend, backend), since I'm the only actual dev in the company.\n\nThe FoC project I'm working on (Hest) is something we're planning to use internally to make interactive simulations, though I'm designing it to be general purpose."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585583686.028900",
        "parent_user_id": "USEQV4KCH"
    },
    {
        "client_msg_id": "63ad3f42-c30f-4a88-9d81-7ea938b8ab36",
        "type": "message",
        "text": "ah those heady post Y2K pandemic days...",
        "user": "UUMQH3TA5",
        "ts": "1585669851.048500",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g57b1d4618df",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/57b1d4618df41d243ddd46b6a29f97ed.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0015-72.png",
            "first_name": "",
            "real_name": "Alan Laidlaw",
            "display_name": "Alan Laidlaw",
            "team": "T5TCAFTA9",
            "name": "alanlaidlaw",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "w52",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "ah those heady post Y2K pandemic days..."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585592468.037600",
        "parent_user_id": "UUMQH3TA5"
    },
    {
        "client_msg_id": "9739046b-db07-43bc-b99e-64d4f78b4ac1",
        "type": "message",
        "text": "The problem with a lot of heterodox programming paradigms is they fundamentally obscure their own mechanics, because they have to run on an x86 processor, (because x86 processors actually exist and easily accessible by a lot of humans).\n\nMy *most hated* experience in programming is hitting some leaky abstraction, and my program not doing what I expect for some reason that is literally impossible to work out from \"within\" the system. Eventually you have to dig around at a lower level to find out what' \"actually\" going on. For example, two functions might appear mathematically identical, but in one form the compiler is able to transform tail recursion into a loop, drastically changing what actually happens in terms of memory.\n\nSo, my only contribution in this discussion is if you are doing this to please, please, please make it possible to seamlessly \"peel away\" these layers of abstraction.\n\nFor example, in the temperature converter - in terms of actual physical reality - are there TWO places in memory, one storing 0 (Celsius), once storing 32 (Farenheit), which are kept appropriately in sync, or is there ONE place in memory storing X, all operations on which are appropriately transformed? This distinction might seem trivial, but actually it is likely to have massive user-impacting consequences at some unanticipated place in the future.",
        "user": "UDQBTJ211",
        "ts": "1585674186.049400",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "2624b1e78c0a",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-02-14\/551655871797_2624b1e78c0a9eaed529_72.jpg",
            "first_name": "Chris",
            "real_name": "Chris Knott",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "chrisknott",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "jmJVF",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The problem with a lot of heterodox programming paradigms is they fundamentally obscure their own mechanics, because they have to run on an x86 processor, (because x86 processors actually exist and easily accessible by a lot of humans).\n\nMy "
                            },
                            {
                                "type": "text",
                                "text": "most hated",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " experience in programming is hitting some leaky abstraction, and my program not doing what I expect for some reason that is literally impossible to work out from \"within\" the system. Eventually you have to dig around at a lower level to find out what' \"actually\" going on. For example, two functions might appear mathematically identical, but in one form the compiler is able to transform tail recursion into a loop, drastically changing what actually happens in terms of memory.\n\nSo, my only contribution in this discussion is if you are doing this to please, please, please make it possible to seamlessly \"peel away\" these layers of abstraction.\n\nFor example, in the temperature converter - in terms of actual physical reality - are there TWO places in memory, one storing 0 (Celsius), once storing 32 (Farenheit), which are kept appropriately in sync, or is there ONE place in memory storing X, all operations on which are appropriately transformed? This distinction might seem trivial, but actually it is likely to have massive user-impacting consequences at some unanticipated place in the future."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1",
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "9f51ee68-ce66-41df-a088-217ba2492cca",
        "type": "message",
        "text": "<@UDQBTJ211> Are you familiar with this? <https:\/\/queue.acm.org\/detail.cfm?id=3212479>",
        "user": "UC2A2ARPT",
        "ts": "1585674263.049600",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gf94d2ed5e18",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6f94d2ed5e188be9865a531021b0afcd.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0013-72.png",
            "first_name": "Ivan",
            "real_name": "Ivan Reese",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "ivanreese",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "edited": {
            "user": "UC2A2ARPT",
            "ts": "1585674273.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "cWG4",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UDQBTJ211"
                            },
                            {
                                "type": "text",
                                "text": " Are you familiar with this? "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/queue.acm.org\/detail.cfm?id=3212479"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1"
    },
    {
        "client_msg_id": "57e06327-8af0-46f7-9d79-c1707cad8c38",
        "type": "message",
        "text": "Yes it is great, but I feel like people often use it in discussions as a kind of Continuum Fallacy - \"You think your language is low-level ha! What about CPU cache sidechannel attacks! C is no more low-level than Javascript!\".\n\nObviously, unless you are soldering wires you are abstracted away from what is actually happening in physically reality, but at the same time, clearly C is to a very great extent more \"honest\" about what is happening that e.g. Haskell or Lisp. This fact about C has obviously become much much less true in the last few decades with multicore processors and deep memory cache hierarchies, which C dishonestly conceals, but to me that just means there is need for a high-level language like C that is *more honest*, not need for a more abstract language where physical reality \"matters less\", or C compilers that slice and dice your code to a bewildering extent.",
        "user": "UDQBTJ211",
        "ts": "1585674788.050000",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "2624b1e78c0a",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-02-14\/551655871797_2624b1e78c0a9eaed529_72.jpg",
            "first_name": "Chris",
            "real_name": "Chris Knott",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "chrisknott",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "edited": {
            "user": "UDQBTJ211",
            "ts": "1585674805.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "rye",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yes it is great, but I feel like people often use it in discussions as a kind of Continuum Fallacy - \"You think your language is low-level ha! What about CPU cache sidechannel attacks! C is no more low-level than Javascript!\".\n\nObviously, unless you are soldering wires you are abstracted away from what is actually happening in physically reality, but at the same time, clearly C is to a very great extent more \"honest\" about what is happening that e.g. Haskell or Lisp. This fact about C has obviously become much much less true in the last few decades with multicore processors and deep memory cache hierarchies, which C dishonestly conceals, but to me that just means there is need for a high-level language like C that is "
                            },
                            {
                                "type": "text",
                                "text": "more honest",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ", not need for a more abstract language where physical reality \"matters less\", or C compilers that slice and dice your code to a bewildering extent."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1",
        "reactions": [
            {
                "name": "point_up",
                "users": [
                    "UA14TGLTC"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "12a51b2d-a082-43bc-9304-98aa9b4f4f4f",
        "type": "message",
        "text": "To put it in more concrete terms, I think it is a bad feature of languages where you get StackOverflow questions coming from earnest users saying \"Why is my program acting like this?!?\", and then power users answer them with an answer from OUTSIDE the system. (\"Ah, see this is a consequence of how CPython implements...\").\n\nWhen I was a novice programmer, I had an algorithm that was O(n) in CPython, and O(n**2) in Pypy. The reason was that CPython implements list.pop(0) as a pointer increase, whereas Pypy copies the memory to a new location. Discovering this information i.e. discovering what was \"actually happening\" (obviously, still an abstaction, just a less leaky one) was a process of digging round on Github, asking questions on dev IRC channels etc.\n\nIn the future of programming, this process of discovery should be seamlessly possible from within the environment. I should just be able to keep opening up the machine and \"seeing how it works\", until I hit (at least!) x86.",
        "user": "UDQBTJ211",
        "ts": "1585675193.050300",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "2624b1e78c0a",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-02-14\/551655871797_2624b1e78c0a9eaed529_72.jpg",
            "first_name": "Chris",
            "real_name": "Chris Knott",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "chrisknott",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "+aUk",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "To put it in more concrete terms, I think it is a bad feature of languages where you get StackOverflow questions coming from earnest users saying \"Why is my program acting like this?!?\", and then power users answer them with an answer from OUTSIDE the system. (\"Ah, see this is a consequence of how CPython implements...\").\n\nWhen I was a novice programmer, I had an algorithm that was O(n) in CPython, and O(n**2) in Pypy. The reason was that CPython implements list.pop(0) as a pointer increase, whereas Pypy copies the memory to a new location. Discovering this information i.e. discovering what was \"actually happening\" (obviously, still an abstaction, just a less leaky one) was a process of digging round on Github, asking questions on dev IRC channels etc.\n\nIn the future of programming, this process of discovery should be seamlessly possible from within the environment. I should just be able to keep opening up the machine and \"seeing how it works\", until I hit (at least!) x86."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1",
        "reactions": [
            {
                "name": "100",
                "users": [
                    "UCUSW7WVD",
                    "UA14TGLTC"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "94d410e5-a10f-4afc-acdd-546a79948676",
        "type": "message",
        "text": "Those are excellent points. My counter is that, with the skills I have, I would not be able to create a FoC language that allows someone to dig as far down as x86. By necessity, I need to make contributions at a level far removed from the true behaviour of the underlying machine. I will need to build on top of abstractions that already exist. If those existing abstractions are poor, I can't solve that problem myself, and I will almost certainly need to introduce my own abstractions explicitly to hide underlying issues (nobody _wants_ to to make the mess bigger, but sometimes you _need_ to given all the circumstances). But perhaps with many people creating better things at the higher levels, it will motivate the people responsible for lower levels to improve their abstractions — like we've seen with GPU designers implementing new things in response to the demands of game developers, or folks working on RISC-V or ARM instruction sets removing complexities that don't fit with modern use cases — and then the compensatory intermediate abstractions can be peeled away (as we've seen with the new graphics APIs like Metal and Vulkan)\n\nYes, I'm just making a \"perfect is the enemy of the good\" argument. I agree broadly with all your points. I just don't think it's reasonable to say that all new FoC projects _must_ or even _should_ conform to them.",
        "user": "UC2A2ARPT",
        "ts": "1585676210.050700",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gf94d2ed5e18",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6f94d2ed5e188be9865a531021b0afcd.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0013-72.png",
            "first_name": "Ivan",
            "real_name": "Ivan Reese",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "ivanreese",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "edited": {
            "user": "UC2A2ARPT",
            "ts": "1585676385.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "SpDbN",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Those are excellent points. My counter is that, with the skills I have, I would not be able to create a FoC language that allows someone to dig as far down as x86. By necessity, I need to make contributions at a level far removed from the true behaviour of the underlying machine. I will need to build on top of abstractions that already exist. If those existing abstractions are poor, I can't solve that problem myself, and I will almost certainly need to introduce my own abstractions explicitly to hide underlying issues (nobody "
                            },
                            {
                                "type": "text",
                                "text": "wants",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " to to make the mess bigger, but sometimes you "
                            },
                            {
                                "type": "text",
                                "text": "need",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " to given all the circumstances). But perhaps with many people creating better things at the higher levels, it will motivate the people responsible for lower levels to improve their abstractions — like we've seen with GPU designers implementing new things in response to the demands of game developers, or folks working on RISC-V or ARM instruction sets removing complexities that don't fit with modern use cases — and then the compensatory intermediate abstractions can be peeled away (as we've seen with the new graphics APIs like Metal and Vulkan)\n\nYes, I'm just making a \"perfect is the enemy of the good\" argument. I agree broadly with all your points. I just don't think it's reasonable to say that all new FoC projects "
                            },
                            {
                                "type": "text",
                                "text": "must",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " or even "
                            },
                            {
                                "type": "text",
                                "text": "should",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " conform to them."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1",
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "U8A5MS6R1",
                    "UCUSW7WVD",
                    "UA14TGLTC"
                ],
                "count": 3
            }
        ]
    },
    {
        "client_msg_id": "a3b525ff-58dd-4608-b3eb-49f8eae02766",
        "type": "message",
        "text": "&gt; So, my only contribution in this discussion is if you are doing this to please, please, please make it possible to seamlessly \"peel away\" these layers of abstraction.\n&gt; In the future of programming, this process of discovery should be seamlessly possible from within the environment.\n:100:\n\nStrongly agree with that. I call this _permeable layers._ However I think we still need layers, and in fact better higher level models. Programming x86 is too low level, which is why compilers and higher level languages are popular, of course. It's a tragedy call\/return is deeply embedded in the prevalent hardware, however it's not the only thing available (there's also `jmp`:wink:). Seems like there's kind of this feedback loop that keeps some designs propagating - hardware influences software and software influences hardware. E.g. Intel is not going release a chip that deviates from the call\/return stack or use tagged memory only because it immediately becomes incompatible with all existing software. Industry will continue to evolve and extend C and C-like replacements. The only way out is to have different models in software first, mapped to the existing hardware. Over time new hardware might become economically feasible. In any case, good layers also let you stay at the higher level (don't require dropping down) as much as they enable dropping down by choice.\n\nI'll leave this here: <https:\/\/www.quora.com\/People-who-are-really-serious-about-software-should-make-their-own-hardware-Why\/answer\/Alan-Kay-11> (\"Computing is about _processes_\")",
        "user": "U8A5MS6R1",
        "ts": "1585676500.051100",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "b7c63cc07373",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-03-21\/584465935395_b7c63cc07373326ec6ea_72.jpg",
            "first_name": "Shalabh",
            "real_name": "Shalabh Chaturvedi",
            "display_name": "shalabh",
            "team": "T5TCAFTA9",
            "name": "shalabh.chaturvedi",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "attachments": [
            {
                "title": "Alan Kay's answer to People who are really serious about software should make their own hardware. Why? - Quora",
                "title_link": "https:\/\/www.quora.com\/People-who-are-really-serious-about-software-should-make-their-own-hardware-Why\/answer\/Alan-Kay-11",
                "text": "The first part of the idea is that computing is about -processes- (all kinds) both understanding them and making them. At the next level of practicality, if one is making something that is supposed to be good for people to use — that actually mig...",
                "fallback": "Alan Kay's answer to People who are really serious about software should make their own hardware. Why? - Quora",
                "from_url": "https:\/\/www.quora.com\/People-who-are-really-serious-about-software-should-make-their-own-hardware-Why\/answer\/Alan-Kay-11",
                "service_icon": "https:\/\/www.quora.com\/favicon.ico",
                "service_name": "quora.com",
                "id": 1,
                "original_url": "https:\/\/www.quora.com\/People-who-are-really-serious-about-software-should-make-their-own-hardware-Why\/answer\/Alan-Kay-11"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "2SRF5",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "So, my only contribution in this discussion is if you are doing this to please, please, please make it possible to seamlessly \"peel away\" these layers of abstraction."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "In the future of programming, this process of discovery should be seamlessly possible from within the environment."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "emoji",
                                "name": "100"
                            },
                            {
                                "type": "text",
                                "text": "\n\nStrongly agree with that. I call this "
                            },
                            {
                                "type": "text",
                                "text": "permeable layers.",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " However I think we still need layers, and in fact better higher level models. Programming x86 is too low level, which is why compilers and higher level languages are popular, of course. It's a tragedy call\/return is deeply embedded in the prevalent hardware, however it's not the only thing available (there's also "
                            },
                            {
                                "type": "text",
                                "text": "jmp",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "emoji",
                                "name": "wink"
                            },
                            {
                                "type": "text",
                                "text": "). Seems like there's kind of this feedback loop that keeps some designs propagating - hardware influences software and software influences hardware. E.g. Intel is not going release a chip that deviates from the call\/return stack or use tagged memory only because it immediately becomes incompatible with all existing software. Industry will continue to evolve and extend C and C-like replacements. The only way out is to have different models in software first, mapped to the existing hardware. Over time new hardware might become economically feasible. In any case, good layers also let you stay at the higher level (don't require dropping down) as much as they enable dropping down by choice.\n\nI'll leave this here: "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/www.quora.com\/People-who-are-really-serious-about-software-should-make-their-own-hardware-Why\/answer\/Alan-Kay-11"
                            },
                            {
                                "type": "text",
                                "text": " (\"Computing is about "
                            },
                            {
                                "type": "text",
                                "text": "processes",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\")"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UCGAK10LS"
                ],
                "count": 1
            },
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UJ6LDMMN0"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "fdac8c29-1092-4082-89d7-396e43e8cd57",
        "type": "message",
        "text": "&gt;  But perhaps with many people creating better things at the higher levels, it will motivate the people responsible for lower levels to improve their abstractions\nYes, this is what I was trying to say.\n\nI see Ivan's point too. I think the principle of permeable layers is solid (just like in principle, we should redesign hardware too). Finding good higher level programming models is very valuable and fully compatible with the principle itself (which is kind of a defferred goal).",
        "user": "U8A5MS6R1",
        "ts": "1585677307.051500",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "b7c63cc07373",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-03-21\/584465935395_b7c63cc07373326ec6ea_72.jpg",
            "first_name": "Shalabh",
            "real_name": "Shalabh Chaturvedi",
            "display_name": "shalabh",
            "team": "T5TCAFTA9",
            "name": "shalabh.chaturvedi",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Uzktb",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": " But perhaps with many people creating better things at the higher levels, it will motivate the people responsible for lower levels to improve their abstractions"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yes, this is what I was trying to say.\n\nI see Ivan's point too. I think the principle of permeable layers is solid (just like in principle, we should redesign hardware too). Finding good higher level programming models is very valuable and fully compatible with the principle itself (which is kind of a defferred goal)."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1"
    },
    {
        "client_msg_id": "7308c4b2-89e1-4b2d-a3c8-104dc289ef81",
        "type": "message",
        "text": "I should clarify that in \"real life\" I am also totally \"perfect is enemy of good\" and massively in favour of real tools that actually exist now and actually empower people.\n\nFor example, I made a reasonably popular Python GUI library (<https:\/\/github.com\/ChrisKnott\/Eel>) that completely obscures it's mechanisms. I get a lot of Github issues from people that have obviously run into trouble with this incredibly leaky abstraction.\n\nHowever, I am also often heartened by just how \"bad\" most of my users are, people who aren't interested AT ALL in \"good programming\" and just have some problem they need fixing as easy as possible - e.g. this guy - <https:\/\/github.com\/samuelhwilliams\/Eel\/issues\/264> - hit some unsolvable problem today with my library, dodged it himself in some hacky way and went on his way. From his profile it's obvious he is a Psychology professor <http:\/\/www.reading.ac.uk\/psychology\/about\/staff\/a-haffey.aspx> - (\"I am studying individual differences in human reward processing. I am specifically interested in the question of how autistic traits influence social and nonsocial reward processing.\") and was just making some temporary program as part of an experiment. It would be borderline immoral to burden people like this with Rust ownership semantics. At the same time, ideally, *if he wanted* he should be able to dig through those layers.",
        "user": "UDQBTJ211",
        "ts": "1585677414.051700",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "2624b1e78c0a",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-02-14\/551655871797_2624b1e78c0a9eaed529_72.jpg",
            "first_name": "Chris",
            "real_name": "Chris Knott",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "chrisknott",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "edited": {
            "user": "UDQBTJ211",
            "ts": "1585677510.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "y2u",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I should clarify that in \"real life\" I am also totally \"perfect is enemy of good\" and massively in favour of real tools that actually exist now and actually empower people.\n\nFor example, I made a reasonably popular Python GUI library ("
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/github.com\/ChrisKnott\/Eel"
                            },
                            {
                                "type": "text",
                                "text": ") that completely obscures it's mechanisms. I get a lot of Github issues from people that have obviously run into trouble with this incredibly leaky abstraction.\n\nHowever, I am also often heartened by just how \"bad\" most of my users are, people who aren't interested AT ALL in \"good programming\" and just have some problem they need fixing as easy as possible - e.g. this guy - "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/github.com\/samuelhwilliams\/Eel\/issues\/264"
                            },
                            {
                                "type": "text",
                                "text": " - hit some unsolvable problem today with my library, dodged it himself in some hacky way and went on his way. From his profile it's obvious he is a Psychology professor "
                            },
                            {
                                "type": "link",
                                "url": "http:\/\/www.reading.ac.uk\/psychology\/about\/staff\/a-haffey.aspx"
                            },
                            {
                                "type": "text",
                                "text": " - (\"I am studying individual differences in human reward processing. I am specifically interested in the question of how autistic traits influence social and nonsocial reward processing.\") and was just making some temporary program as part of an experiment. It would be borderline immoral to burden people like this with Rust ownership semantics. At the same time, ideally, "
                            },
                            {
                                "type": "text",
                                "text": "if he wanted",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " he should be able to dig through those layers."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UC2A2ARPT",
                    "UJ6LDMMN0"
                ],
                "count": 2
            },
            {
                "name": "heart",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "42c60516-1d60-4aea-b8fb-779d8ddf885d",
        "type": "message",
        "text": "Yeah programming is a means to an end - which is some other human endeavor. Hmm I'm now thinking if 'looking below' the layers of abstraction is just a personal preference of us 'programmers'. I mean, most people who drive cars don't need to know the mechanisms, they just need to learn the behaviors for the context they encounter - how the car reacts to pushing the pedals, acceleration, braking, skid etc (note: skid is a 'leak' in the 'brake' abstraction). A _complete_ layer of abstraction is perhaps a higher goal than a permeable one.",
        "user": "U8A5MS6R1",
        "ts": "1585679824.052900",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "b7c63cc07373",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-03-21\/584465935395_b7c63cc07373326ec6ea_72.jpg",
            "first_name": "Shalabh",
            "real_name": "Shalabh Chaturvedi",
            "display_name": "shalabh",
            "team": "T5TCAFTA9",
            "name": "shalabh.chaturvedi",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "1rM",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yeah programming is a means to an end - which is some other human endeavor. Hmm I'm now thinking if 'looking below' the layers of abstraction is just a personal preference of us 'programmers'. I mean, most people who drive cars don't need to know the mechanisms, they just need to learn the behaviors for the context they encounter - how the car reacts to pushing the pedals, acceleration, braking, skid etc (note: skid is a 'leak' in the 'brake' abstraction). A "
                            },
                            {
                                "type": "text",
                                "text": "complete",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " layer of abstraction is perhaps a higher goal than a permeable one."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1"
    },
    {
        "client_msg_id": "a1c40dfb-dbdf-4139-95d1-f636d7b5e8ab",
        "type": "message",
        "text": "At the risk of sounding like a broken record, <@UDQBTJ211> my project is doing precisely this sort of transparency all the way down to x86.\n\n<https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1584343418341800?thread_ts=1584343418.341800>\n<https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1578083883321500?thread_ts=1578008614.279100>\n\n<@UC2A2ARPT>:\n&gt; with the skills I have, I would not be able to create a FoC language that allows someone to dig as far down as x86.\nPlease build your prototypes atop Mu!\n\nIt's nowhere near ready yet. I have no idea how to do graphics or sound. But a forcing function would be helpful. For example, perhaps there's a minimum in sound syscalls I could provide that would enable text-mode UIs for music.",
        "user": "UCUSW7WVD",
        "ts": "1585680051.053200",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6e649a383cf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-07-14\/687915485201_6e649a383cf8f9e366e3_72.png",
            "first_name": "Kartik",
            "real_name": "Kartik Agaram",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "ak",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "edited": {
            "user": "UCUSW7WVD",
            "ts": "1585680104.000000"
        },
        "attachments": [
            {
                "from_url": "https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1584343418341800?thread_ts=1584343418.341800",
                "fallback": "[March 16th, 2020 12:23 AM] ak: Everything about my project, in one place: <http:\/\/akkartik.name\/akkartik-convivial-20200315.pdf> (pdf; 25 pages)\n\n(Well, two places. This paper and the repo at <https:\/\/github.com\/akkartik\/mu> should subsume any previous writings.)\n\n&gt; *Bicycles for the mind have to be see-through*\n&gt; \n&gt; This paper describes ongoing research on building software to be comprehensible to its users so that they can tailor it to their needs in the field. Our test-bed is a computing stack called Mu that deemphasizes a clean interface in favor of a few global implementation properties: small implementation size, few distinct notations, parsimonious dependencies, a simple dependency graph that avoids cycles, and early warning on breaking changes. Assuming a 32-bit x86 processor and (for now) a basic third-party Unix-like kernel, Mu builds up from raw machine code to a memory-safe but less expressive language than C.\n&gt; \n&gt; Our approach to keeping software comprehensible is to reduce information hiding and abstraction, and instead encourage curiosity about internals. Our hypothesis is that abstractions help insiders who understand a project but hinder newcomers who understand only that project's domain. Where recent efforts to create ``bicycles for the mind'' have tended to focus on reducing learning time and effort, we explore organizing the curriculum to be incrementally useful, providing an hour of actionable value for an hour (or three) of study. The hope is that rewarding curiosity will stimulate curiosity in a virtuous cycle, so that more people are motivated to study and reflect on the difference between good vs bad design and good vs bad architecture, even as the study takes place over a lifetime of specialization in other domains. Spreading expertise in design is essential to the creation of a better society of more empowered citizens. Software tools have a role to play in this process, both by exemplifying good design and by providing visceral illustrations of the consequences of design choices.\nI hope to eventually do a talk for <https:\/\/2020.programming-conference.org\/home\/salon-2020>, but since it's been postponed the paper I wrote has been burning a hole in my pocket. Many thanks to <@U6KQ2S410> and the rest of the organizers for an inspiring theme this year. I didn't think anything would ever induce me to write an academic paper again.",
                "ts": "1584343418.341800",
                "author_id": "UCUSW7WVD",
                "author_subname": "Kartik Agaram",
                "channel_id": "C5T9GPWFL",
                "channel_name": "general",
                "is_msg_unfurl": true,
                "is_thread_root_unfurl": true,
                "text": "Everything about my project, in one place: <http:\/\/akkartik.name\/akkartik-convivial-20200315.pdf> (pdf; 25 pages)\n\n(Well, two places. This paper and the repo at <https:\/\/github.com\/akkartik\/mu> should subsume any previous writings.)\n\n&gt; *Bicycles for the mind have to be see-through*\n&gt; \n&gt; This paper describes ongoing research on building software to be comprehensible to its users so that they can tailor it to their needs in the field. Our test-bed is a computing stack called Mu that deemphasizes a clean interface in favor of a few global implementation properties: small implementation size, few distinct notations, parsimonious dependencies, a simple dependency graph that avoids cycles, and early warning on breaking changes. Assuming a 32-bit x86 processor and (for now) a basic third-party Unix-like kernel, Mu builds up from raw machine code to a memory-safe but less expressive language than C.\n&gt; \n&gt; Our approach to keeping software comprehensible is to reduce information hiding and abstraction, and instead encourage curiosity about internals. Our hypothesis is that abstractions help insiders who understand a project but hinder newcomers who understand only that project's domain. Where recent efforts to create ``bicycles for the mind'' have tended to focus on reducing learning time and effort, we explore organizing the curriculum to be incrementally useful, providing an hour of actionable value for an hour (or three) of study. The hope is that rewarding curiosity will stimulate curiosity in a virtuous cycle, so that more people are motivated to study and reflect on the difference between good vs bad design and good vs bad architecture, even as the study takes place over a lifetime of specialization in other domains. Spreading expertise in design is essential to the creation of a better society of more empowered citizens. Software tools have a role to play in this process, both by exemplifying good design and by providing visceral illustrations of the consequences of design choices.\nI hope to eventually do a talk for <https:\/\/2020.programming-conference.org\/home\/salon-2020>, but since it's been postponed the paper I wrote has been burning a hole in my pocket. Many thanks to <@U6KQ2S410> and the rest of the organizers for an inspiring theme this year. I didn't think anything would ever induce me to write an academic paper again.",
                "author_name": "Kartik Agaram",
                "author_link": "https:\/\/futureofcoding.slack.com\/team\/UCUSW7WVD",
                "author_icon": "https:\/\/avatars.slack-edge.com\/2019-07-14\/687915485201_6e649a383cf8f9e366e3_48.png",
                "mrkdwn_in": [
                    "text"
                ],
                "id": 1,
                "original_url": "https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1584343418341800?thread_ts=1584343418.341800",
                "footer": "Thread in #general"
            },
            {
                "from_url": "https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1578083883321500?thread_ts=1578008614.279100",
                "fallback": "[January 3rd, 2020 12:38 PM] ak: Right. But you wanted the political side here :smile: If I decide that my approach is broken I'll subside.\n\nI don't mean to make it seem like a small tent. It's not about Mu the project, but Mu the way. The thing I'm doing that I don't see anybody else in this group doing is trying to communicate costs to end users and occasionally saying, \"this feature isn't worth the cost, you shouldn't chase it\".\n\nWe should all look upon anything reassuringly hermetic with suspicion. What is the curtain hiding, and who's pulling the strings there?",
                "ts": "1578083883.321500",
                "author_id": "UCUSW7WVD",
                "author_subname": "Kartik Agaram",
                "channel_id": "C5T9GPWFL",
                "channel_name": "general",
                "is_msg_unfurl": true,
                "is_reply_unfurl": true,
                "text": "Right. But you wanted the political side here :smile: If I decide that my approach is broken I'll subside.\n\nI don't mean to make it seem like a small tent. It's not about Mu the project, but Mu the way. The thing I'm doing that I don't see anybody else in this group doing is trying to communicate costs to end users and occasionally saying, \"this feature isn't worth the cost, you shouldn't chase it\".\n\nWe should all look upon anything reassuringly hermetic with suspicion. What is the curtain hiding, and who's pulling the strings there?",
                "author_name": "Kartik Agaram",
                "author_link": "https:\/\/futureofcoding.slack.com\/team\/UCUSW7WVD",
                "author_icon": "https:\/\/avatars.slack-edge.com\/2019-07-14\/687915485201_6e649a383cf8f9e366e3_48.png",
                "mrkdwn_in": [
                    "text"
                ],
                "id": 2,
                "original_url": "https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1578083883321500?thread_ts=1578008614.279100",
                "footer": "From a thread in #general"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "P8g",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "At the risk of sounding like a broken record, "
                            },
                            {
                                "type": "user",
                                "user_id": "UDQBTJ211"
                            },
                            {
                                "type": "text",
                                "text": " my project is doing precisely this sort of transparency all the way down to x86.\n\n"
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1584343418341800?thread_ts=1584343418.341800"
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1578083883321500?thread_ts=1578008614.279100"
                            },
                            {
                                "type": "text",
                                "text": "\n\n"
                            },
                            {
                                "type": "user",
                                "user_id": "UC2A2ARPT"
                            },
                            {
                                "type": "text",
                                "text": ":\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "with the skills I have, I would not be able to create a FoC language that allows someone to dig as far down as x86."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Please build your prototypes atop Mu!\n\nIt's nowhere near ready yet. I have no idea how to do graphics or sound. But a forcing function would be helpful. For example, perhaps there's a minimum in sound syscalls I could provide that would enable text-mode UIs for music."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1"
    },
    {
        "client_msg_id": "fa0bccb8-4ac7-473b-b8f5-5398bd9d81ea",
        "type": "message",
        "text": "<@UDQBTJ211>:\n&gt; It would be borderline immoral to burden people like this with Rust ownership semantics. At the same time, ideally, if he wanted he should be able to dig through those layers.\nFrom my abstract:\n&gt; The hope is that rewarding curiosity will stimulate curiosity in a virtuous cycle, so that more people are motivated to study and reflect on the difference between good vs bad design and good vs bad architecture, even as the study takes place over a lifetime of specialization in other domains.",
        "user": "UCUSW7WVD",
        "ts": "1585680398.053800",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6e649a383cf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-07-14\/687915485201_6e649a383cf8f9e366e3_72.png",
            "first_name": "Kartik",
            "real_name": "Kartik Agaram",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "ak",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "BZy",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UDQBTJ211"
                            },
                            {
                                "type": "text",
                                "text": ":\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "It would be borderline immoral to burden people like this with Rust ownership semantics. At the same time, ideally, if he wanted he should be able to dig through those layers."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nFrom my abstract:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The hope is that rewarding curiosity will stimulate curiosity in a virtuous cycle, so that more people are motivated to study and reflect on the difference between good vs bad design and good vs bad architecture, even as the study takes place over a lifetime of specialization in other domains."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UDQBTJ211"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "1ee318fe-ff5d-4303-988b-b4715873ab78",
        "type": "message",
        "text": "<@U8A5MS6R1>, the synthesis between your (paraphrasing of the paper's) point and Chris's seems to be:\n\na) It's good for abstractions to terminate in the machine model. That's a feature, not a bug.\nb) There's some missing layers in between where you can step through your programming model in its own terms.\n\nThis feels like a gap in tooling that necessarily depends on whoever is providing the model. Which is why I was so confused that the paper was blaming call\/ret. It's saying that implementors of new models are still cognitively captured by the model they're implementing in. Einstein was troubled by the implications of his theories in ways that we are quite comfortable with. Jesus was Jewish.",
        "user": "UCUSW7WVD",
        "ts": "1585680808.055400",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6e649a383cf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-07-14\/687915485201_6e649a383cf8f9e366e3_72.png",
            "first_name": "Kartik",
            "real_name": "Kartik Agaram",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "ak",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "edited": {
            "user": "UCUSW7WVD",
            "ts": "1585680838.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "8\/J",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U8A5MS6R1"
                            },
                            {
                                "type": "text",
                                "text": ", the synthesis between your (paraphrasing of the paper's) point and Chris's seems to be:\n\na) It's good for abstractions to terminate in the machine model. That's a feature, not a bug.\nb) There's some missing layers in between where you can step through your programming model in its own terms.\n\nThis feels like a gap in tooling that necessarily depends on whoever is providing the model. Which is why I was so confused that the paper was blaming call\/ret. It's saying that implementors of new models are still cognitively captured by the model they're implementing in. Einstein was troubled by the implications of his theories in ways that we are quite comfortable with. Jesus was Jewish."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1"
    },
    {
        "client_msg_id": "9f0f4d1f-901d-4832-95fd-91793909b59d",
        "type": "message",
        "text": "I can definitely feel #2.. it seems the bulk of programmers don't care quite enough about programmer ergonomics to effect change",
        "user": "UHDQ62M4P",
        "ts": "1585686133.056000",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "465336060ae8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-03-27\/582042668721_465336060ae83dc74288_72.jpg",
            "first_name": "Wouter",
            "real_name": "Wouter van Oortmerssen",
            "display_name": "Wouter",
            "team": "T5TCAFTA9",
            "name": "aardappel",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Rlq=",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I can definitely feel #2.. it seems the bulk of programmers don't care quite enough about programmer ergonomics to effect change"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585616341.042100",
        "parent_user_id": "UBSMEUXAA"
    },
    {
        "client_msg_id": "56d623b5-56b5-4360-ab50-1aed49c6c719",
        "type": "message",
        "text": "Where I work, a lot of programmers seem to think vim+bash+make+logs+tests is an adequate development cycle.. having the convenience of an IDE+language that support eachother is a distant dream, let alone some of the entirely achievable ideas going around in this community",
        "user": "UHDQ62M4P",
        "ts": "1585686257.056200",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "465336060ae8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-03-27\/582042668721_465336060ae83dc74288_72.jpg",
            "first_name": "Wouter",
            "real_name": "Wouter van Oortmerssen",
            "display_name": "Wouter",
            "team": "T5TCAFTA9",
            "name": "aardappel",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "scg",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Where I work, a lot of programmers seem to think vim+bash+make+logs+tests is an adequate development cycle.. having the convenience of an IDE+language that support eachother is a distant dream, let alone some of the entirely achievable ideas going around in this community"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585616341.042100",
        "parent_user_id": "UBSMEUXAA"
    },
    {
        "client_msg_id": "651316e2-be56-4ba1-be60-760489b983ca",
        "type": "message",
        "text": "Also, even if better systems exist.. most programmers get paid to maintain systems in existing languages, so it naturally will take on the order of 20 years to see notable change in what people on average have to work with",
        "user": "UHDQ62M4P",
        "ts": "1585686387.056400",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "465336060ae8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-03-27\/582042668721_465336060ae83dc74288_72.jpg",
            "first_name": "Wouter",
            "real_name": "Wouter van Oortmerssen",
            "display_name": "Wouter",
            "team": "T5TCAFTA9",
            "name": "aardappel",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "A32",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Also, even if better systems exist.. most programmers get paid to maintain systems in existing languages, so it naturally will take on the order of 20 years to see notable change in what people on average have to work with"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585616341.042100",
        "parent_user_id": "UBSMEUXAA"
    },
    {
        "client_msg_id": "44cf0cd8-c482-431f-9370-59c5ede36a47",
        "type": "message",
        "text": "note, the \"tyranny\" of call\/return is not just enforced by CPUs, it is also also enforced by compilers like LLVM. The moment your language implements a calling\/control flow structure not representable in LLVM by call\/return, you immediately take a 10x or worse hit to performance, since now LLVMs suite of optimisations don't apply to your alternative structure (which is likely emulated by using memory directly). So to escape the tyranny of call\/return while staying competitive, you need to be willing to put in similar effort to create a new compiler infrastructure",
        "user": "UHDQ62M4P",
        "ts": "1585687142.056800",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "465336060ae8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-03-27\/582042668721_465336060ae83dc74288_72.jpg",
            "first_name": "Wouter",
            "real_name": "Wouter van Oortmerssen",
            "display_name": "Wouter",
            "team": "T5TCAFTA9",
            "name": "aardappel",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "PNnc",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "note, the \"tyranny\" of call\/return is not just enforced by CPUs, it is also also enforced by compilers like LLVM. The moment your language implements a calling\/control flow structure not representable in LLVM by call\/return, you immediately take a 10x or worse hit to performance, since now LLVMs suite of optimisations don't apply to your alternative structure (which is likely emulated by using memory directly). So to escape the tyranny of call\/return while staying competitive, you need to be willing to put in similar effort to create a new compiler infrastructure"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1",
        "reactions": [
            {
                "name": "point_up_2",
                "users": [
                    "U8A5MS6R1"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "ae419729-3df9-4e4d-9774-94f2d1a74e79",
        "type": "message",
        "text": "Well, yes and no. What if your structure is representable by GPU ops, or SIMD ops?",
        "user": "UC2A2ARPT",
        "ts": "1585687262.057000",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gf94d2ed5e18",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6f94d2ed5e188be9865a531021b0afcd.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0013-72.png",
            "first_name": "Ivan",
            "real_name": "Ivan Reese",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "ivanreese",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ST0",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Well, yes and no. What if your structure is representable by GPU ops, or SIMD ops?"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1"
    },
    {
        "client_msg_id": "95c8df03-90b9-4b59-b372-542ee9bcd009",
        "type": "message",
        "text": "GPU's and SIMD are even less flexible that general CPU instructions or whatever LLVM IR can represent? How would they help?",
        "user": "UHDQ62M4P",
        "ts": "1585687544.057200",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "465336060ae8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-03-27\/582042668721_465336060ae83dc74288_72.jpg",
            "first_name": "Wouter",
            "real_name": "Wouter van Oortmerssen",
            "display_name": "Wouter",
            "team": "T5TCAFTA9",
            "name": "aardappel",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "sS7",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "GPU's and SIMD are even less flexible that general CPU instructions or whatever LLVM IR can represent? How would they help?"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1"
    },
    {
        "client_msg_id": "c1417ff5-0269-434f-9788-de38b1a322ce",
        "type": "message",
        "text": "They offer alternatives to CPU norms, and are faster for certain kinds of work. It's possible (though — sure — unlikely) to imagine implementing a novel programming model (or part of one) in terms of these. I mean, after all, look at what folks are doing with ML on GPUs.\n\nLLVM IR is not a great substrate. For instance, Lattner designed <https:\/\/mlir.llvm.org> as an even more general representation — even he wasn't happy being constrained to LLVM IR. So your point is a good one — sometimes escaping tyranny requires changing the compiler, indeed. Nice work if you can get it.\n\n(Also — note that MLIR includes support for dataflow right in the IR.)",
        "user": "UC2A2ARPT",
        "ts": "1585687706.057400",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gf94d2ed5e18",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6f94d2ed5e188be9865a531021b0afcd.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0013-72.png",
            "first_name": "Ivan",
            "real_name": "Ivan Reese",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "ivanreese",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "edited": {
            "user": "UC2A2ARPT",
            "ts": "1585709009.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "X8u",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "They offer alternatives to CPU norms, and are faster for certain kinds of work. It's possible (though — sure — unlikely) to imagine implementing a novel programming model (or part of one) in terms of these. I mean, after all, look at what folks are doing with ML on GPUs.\n\nLLVM IR is not a great substrate. For instance, Lattner designed "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/mlir.llvm.org"
                            },
                            {
                                "type": "text",
                                "text": " as an even more general representation — even he wasn't happy being constrained to LLVM IR. So your point is a good one — sometimes escaping tyranny requires changing the compiler, indeed. Nice work if you can get it.\n\n(Also — note that MLIR includes support for dataflow right in the IR.)"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1"
    },
    {
        "client_msg_id": "88512978-c09d-4287-91e8-30052664fe82",
        "type": "message",
        "text": "Somewhat tangential, but this blurb by Mike Pall (author of Luajit) is interesting: TL;DR the layers of abstraction just above\/under the machine code look wasteful as well:\n<https:\/\/www.freelists.org\/post\/luajit\/Ramblings-on-languages-and-architectures-was-Re-any-benefit-to-throwing-off-lua51-constraints>",
        "user": "U8A5MS6R1",
        "ts": "1585687793.057600",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "b7c63cc07373",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-03-21\/584465935395_b7c63cc07373326ec6ea_72.jpg",
            "first_name": "Shalabh",
            "real_name": "Shalabh Chaturvedi",
            "display_name": "shalabh",
            "team": "T5TCAFTA9",
            "name": "shalabh.chaturvedi",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "edited": {
            "user": "U8A5MS6R1",
            "ts": "1585687808.000000"
        },
        "attachments": [
            {
                "title": "Ramblings on languages and architectures (was Re: any benefit to throwing off lua51 constraints?) - luajit - FreeLists",
                "title_link": "https:\/\/www.freelists.org\/post\/luajit\/Ramblings-on-languages-and-architectures-was-Re-any-benefit-to-throwing-off-lua51-constraints",
                "text": "Ramblings on languages and architectures (was Re: any benefit to throwing off lua51 constraints?), luajit at FreeLists",
                "fallback": "Ramblings on languages and architectures (was Re: any benefit to throwing off lua51 constraints?) - luajit - FreeLists",
                "from_url": "https:\/\/www.freelists.org\/post\/luajit\/Ramblings-on-languages-and-architectures-was-Re-any-benefit-to-throwing-off-lua51-constraints",
                "service_icon": "https:\/\/www.freelists.org\/favicon.ico",
                "service_name": "freelists.org",
                "id": 1,
                "original_url": "https:\/\/www.freelists.org\/post\/luajit\/Ramblings-on-languages-and-architectures-was-Re-any-benefit-to-throwing-off-lua51-constraints"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "YSmI7",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Somewhat tangential, but this blurb by Mike Pall (author of Luajit) is interesting: TL;DR the layers of abstraction just above\/under the machine code look wasteful as well:\n"
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/www.freelists.org\/post\/luajit\/Ramblings-on-languages-and-architectures-was-Re-any-benefit-to-throwing-off-lua51-constraints"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1"
    },
    {
        "client_msg_id": "0889a92d-c042-4822-be9d-5c0a62ac8bed",
        "type": "message",
        "text": "Also, lets not forget FPGAs.",
        "user": "U8A5MS6R1",
        "ts": "1585688016.058500",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "b7c63cc07373",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-03-21\/584465935395_b7c63cc07373326ec6ea_72.jpg",
            "first_name": "Shalabh",
            "real_name": "Shalabh Chaturvedi",
            "display_name": "shalabh",
            "team": "T5TCAFTA9",
            "name": "shalabh.chaturvedi",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "mzX",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Also, lets not forget FPGAs."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "b129c3e8-c28b-41ab-bd84-98386c741499",
        "type": "message",
        "text": "I'm a bit late to this chat (just joined the slack group), but Alan Kay gave a demo on a reconstructed Alto VM as a tribute to Ted Nelson: <https:\/\/www.youtube.com\/watch?v=AnrlSqtpOkw>",
        "user": "U0112C10V4Y",
        "ts": "1585688060.058700",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gf521cc065bb",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/f521cc065bb724c90c57c263ec7ee857.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0008-72.png",
            "first_name": "",
            "real_name": "Naveen Michaud-Agrawal",
            "display_name": "Naveen Michaud-Agrawal",
            "team": "T5TCAFTA9",
            "name": "naveen.michaudagrawal",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "attachments": [
            {
                "service_name": "YouTube",
                "service_url": "https:\/\/www.youtube.com\/",
                "title": "Alan Kay's tribute to Ted Nelson at \"Intertwingled\" Fest",
                "title_link": "https:\/\/www.youtube.com\/watch?v=AnrlSqtpOkw",
                "author_name": "TheTedNelson",
                "author_link": "https:\/\/www.youtube.com\/user\/TheTedNelson",
                "thumb_url": "https:\/\/i.ytimg.com\/vi\/AnrlSqtpOkw\/hqdefault.jpg",
                "thumb_width": 480,
                "thumb_height": 360,
                "fallback": "YouTube Video: Alan Kay's tribute to Ted Nelson at \"Intertwingled\" Fest",
                "video_html": "<iframe width=\"400\" height=\"225\" src=\"https:\/\/www.youtube.com\/embed\/AnrlSqtpOkw?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>",
                "video_html_width": 400,
                "video_html_height": 225,
                "from_url": "https:\/\/www.youtube.com\/watch?v=AnrlSqtpOkw",
                "service_icon": "https:\/\/a.slack-edge.com\/80588\/img\/unfurl_icons\/youtube.png",
                "id": 1,
                "original_url": "https:\/\/www.youtube.com\/watch?v=AnrlSqtpOkw"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "OJ+oq",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I'm a bit late to this chat (just joined the slack group), but Alan Kay gave a demo on a reconstructed Alto VM as a tribute to Ted Nelson: "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/www.youtube.com\/watch?v=AnrlSqtpOkw"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1583565732.099000",
        "parent_user_id": "UC2A2ARPT",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U8A5MS6R1"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "d864c2a5-18de-4c00-8835-7e9b5771dfaa",
        "type": "message",
        "text": "One interesting aspect of the demo is they were able to salvage a discarded harddrive from Xerox and after building an Alto emulator the system could run unmodified",
        "user": "U0112C10V4Y",
        "ts": "1585688197.059100",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gf521cc065bb",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/f521cc065bb724c90c57c263ec7ee857.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0008-72.png",
            "first_name": "",
            "real_name": "Naveen Michaud-Agrawal",
            "display_name": "Naveen Michaud-Agrawal",
            "team": "T5TCAFTA9",
            "name": "naveen.michaudagrawal",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "MLh",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "One interesting aspect of the demo is they were able to salvage a discarded harddrive from Xerox and after building an Alto emulator the system could run unmodified"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1583565732.099000",
        "parent_user_id": "UC2A2ARPT"
    },
    {
        "client_msg_id": "be3c1521-d70a-429f-8ddc-a1fac5e4db2b",
        "type": "message",
        "text": "How does SIMD offer an alternative to call return? I'm confused.. and MLIR improves on the generality of the IR representation, it doesn't necessarily change anything about the computational model it represents",
        "user": "UHDQ62M4P",
        "ts": "1585694955.059400",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "465336060ae8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-03-27\/582042668721_465336060ae83dc74288_72.jpg",
            "first_name": "Wouter",
            "real_name": "Wouter van Oortmerssen",
            "display_name": "Wouter",
            "team": "T5TCAFTA9",
            "name": "aardappel",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "s34F",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "How does SIMD offer an alternative to call return? I'm confused.. and MLIR improves on the generality of the IR representation, it doesn't necessarily change anything about the computational model it represents"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1"
    },
    {
        "client_msg_id": "ddad20c8-77b9-47be-ad25-8541511f60af",
        "type": "message",
        "text": "SIMD offers an alternative to the perf hit of not aligning with LLVM — if your new language primitive can be expressed efficiently in terms of SIMD, then missing out on the LLVM optimizations doesn't matter to you.\n\nThis is of course just a theory. For one, I don't have any particular primitive in mind. For two, I don't know enough about LLVM — perhaps there is, in fact, no computation that can be accelerated by SIMD that wouldn't be meaningfully slowed for lack of compiler optimizations.",
        "user": "UC2A2ARPT",
        "ts": "1585701826.059700",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gf94d2ed5e18",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6f94d2ed5e188be9865a531021b0afcd.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0013-72.png",
            "first_name": "Ivan",
            "real_name": "Ivan Reese",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "ivanreese",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "edited": {
            "user": "UC2A2ARPT",
            "ts": "1585702241.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "tPEA",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "SIMD offers an alternative to the perf hit of not aligning with LLVM — if your new language primitive can be expressed efficiently in terms of SIMD, then missing out on the LLVM optimizations doesn't matter to you.\n\nThis is of course just a theory. For one, I don't have any particular primitive in mind. For two, I don't know enough about LLVM — perhaps there is, in fact, no computation that can be accelerated by SIMD that wouldn't be meaningfully slowed for lack of compiler optimizations."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1"
    },
    {
        "client_msg_id": "77c40a40-ddd5-443a-b2af-5fc2e1e4ac0e",
        "type": "message",
        "text": "Also I'll just point out that I'm getting a vibe from a lot of people that their \"future of coding\" involves C-like performance. Most applications aren't limited by operations per second... so I'm puzzled by why people are limiting their visions to ones with a clear mapping to C-like constructs. Only asymptotic complexity matters broadly, since that is what separates the possible from the impossible.",
        "user": "UCGAK10LS",
        "ts": "1585702390.060400",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "770c193fd379",
            "image_72": "https:\/\/avatars.slack-edge.com\/2020-04-17\/1092364753072_770c193fd379ebbced3f_72.jpg",
            "first_name": "",
            "real_name": "Nick Smith",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "nmsmith65",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Ltc",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Also I'll just point out that I'm getting a vibe from a lot of people that their \"future of coding\" involves C-like performance. Most applications aren't limited by operations per second... so I'm puzzled by why people are limiting their visions to ones with a clear mapping to C-like constructs. Only asymptotic complexity matters broadly, since that is what separates the possible from the impossible."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UC2A2ARPT",
                    "U8A5MS6R1",
                    "UJ6LDMMN0",
                    "UHWC9PXBL"
                ],
                "count": 4
            }
        ]
    },
    {
        "client_msg_id": "52ba3807-7924-4b52-bfcd-097eadb3bf83",
        "type": "message",
        "text": "LLVM and its gigantic array of optimizations, is insanely complex, with diminishing benefits for ordinary programs. I once did a test of a huge program and compiled it with lots of optimizations, and then compiled down to 486 era only instructions. About 1% difference. The sad truth is that CPU's are so fast now that both sides of a branch are executed, and many things that used to cost don't; but what determines your overall performance is how you have your data arranged in memory. If you can keep from hopping around RAM and stay in the caches your program runs like the wind. That's why some of the C programs are so fast, is that they were laid out very carefully from a data structure point of view, and why Java is notorious slow, because it sprays objects all over the heap. 99% of computers are idle nowadays; outside of big data and very specialized applications performance is really the last place to put your effort. Ease of maintenance trumps CPU costs in the vast majority of applications. That being said, there is no excuse for the sweathogs that we see today, where hundreds of megabytes are used to draw a single tab  window in Chrome, etc.\n\nIt is also true that CPU's are often advertised as being much faster than they really are. I once did a benchmark on a fairly CPU intensive app, and found that an e3 was faster than a far more expensive Xeon processor with many cores, because this was a mostly single threaded program, and adding all the cores trades off performance for single threaded. Also i discovered that some programs are faster with hyperthreading turned off, particularly those that do lots of interrupts because pretending you have more cores than you really do entails tradeoffs as well. Intel's product line is bewildering and a lot of products are sold for huge premiums just because they have some super rare instructions that spy agencies want. There's lots of nonsense out there. Intel hasn't added a useful instruction since they added true random numbers; most of the new ones are crazy; designed primarily to waste the engineering time of the cloners in China.",
        "user": "UEQ6M68H0",
        "ts": "1585712805.061200",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "326328f75c3f",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-02-05\/542651515888_326328f75c3f2a08544c_72.jpg",
            "first_name": "Edward",
            "real_name": "Edward de Jong",
            "display_name": "Edward de Jong \/ Beads Project",
            "team": "T5TCAFTA9",
            "name": "magicmouse94937",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "edited": {
            "user": "UEQ6M68H0",
            "ts": "1585714485.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "YQgI",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "LLVM and its gigantic array of optimizations, is insanely complex, with diminishing benefits for ordinary programs. I once did a test of a huge program and compiled it with lots of optimizations, and then compiled down to 486 era only instructions. About 1% difference. The sad truth is that CPU's are so fast now that both sides of a branch are executed, and many things that used to cost don't; but what determines your overall performance is how you have your data arranged in memory. If you can keep from hopping around RAM and stay in the caches your program runs like the wind. That's why some of the C programs are so fast, is that they were laid out very carefully from a data structure point of view, and why Java is notorious slow, because it sprays objects all over the heap. 99% of computers are idle nowadays; outside of big data and very specialized applications performance is really the last place to put your effort. Ease of maintenance trumps CPU costs in the vast majority of applications. That being said, there is no excuse for the sweathogs that we see today, where hundreds of megabytes are used to draw a single tab  window in Chrome, etc.\n\nIt is also true that CPU's are often advertised as being much faster than they really are. I once did a benchmark on a fairly CPU intensive app, and found that an e3 was faster than a far more expensive Xeon processor with many cores, because this was a mostly single threaded program, and adding all the cores trades off performance for single threaded. Also i discovered that some programs are faster with hyperthreading turned off, particularly those that do lots of interrupts because pretending you have more cores than you really do entails tradeoffs as well. Intel's product line is bewildering and a lot of products are sold for huge premiums just because they have some super rare instructions that spy agencies want. There's lots of nonsense out there. Intel hasn't added a useful instruction since they added true random numbers; most of the new ones are crazy; designed primarily to waste the engineering time of the cloners in China."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1"
    },
    {
        "client_msg_id": "d6b21782-bcfb-44c0-81a2-6c2e5d931551",
        "type": "message",
        "text": "Reminds me of a Ruby interpreter story from a while back.  (I forget the details.)  But the gist is that the struct for a Ruby object is generally five words in size.  *Padding* the size to eight words yielded a performance improvement from lining up better CPU caches.",
        "user": "UA14TGLTC",
        "ts": "1585716111.061600",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gae6d55db9d1",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/3ae6d55db9d15b79bc683a8031fc2588.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0009-72.png",
            "first_name": "",
            "real_name": "William Taysom",
            "display_name": "wtaysom",
            "team": "T5TCAFTA9",
            "name": "wtaysom",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "mI9D",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Reminds me of a Ruby interpreter story from a while back.  (I forget the details.)  But the gist is that the struct for a Ruby object is generally five words in size.  "
                            },
                            {
                                "type": "text",
                                "text": "Padding ",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "the size to eight words yielded a performance improvement from lining up better CPU caches."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1"
    },
    {
        "client_msg_id": "c21bf7e9-3263-4af6-ae05-0d900b4ba8d9",
        "type": "message",
        "text": "Alignment used to matter quite a bit. I don't think so any more, because so much pipelining is happening. They have so many billions of transistors to throw around, but RAM is holding the whole thing back. RAM speeds have only slightly increased compared to CPU power; billions awaits to the company that creates a breakthrough. DRAM has hardly changed. And is the main cost in servers. A few years ago, Samsung had a terrible recall for the Note cellphones that caught on fire; they lost billions and made it up by tripling RAM prices, and then everyone else raised their prices. Took years to come back down again. There is a revolution coming where the RAM will no longer be volatile. That is a very interesting change that i have planned for in my Beads system. Writing to the disk will be a thing of the past.",
        "user": "UEQ6M68H0",
        "ts": "1585720719.061800",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "326328f75c3f",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-02-05\/542651515888_326328f75c3f2a08544c_72.jpg",
            "first_name": "Edward",
            "real_name": "Edward de Jong",
            "display_name": "Edward de Jong \/ Beads Project",
            "team": "T5TCAFTA9",
            "name": "magicmouse94937",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "zS\/",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Alignment used to matter quite a bit. I don't think so any more, because so much pipelining is happening. They have so many billions of transistors to throw around, but RAM is holding the whole thing back. RAM speeds have only slightly increased compared to CPU power; billions awaits to the company that creates a breakthrough. DRAM has hardly changed. And is the main cost in servers. A few years ago, Samsung had a terrible recall for the Note cellphones that caught on fire; they lost billions and made it up by tripling RAM prices, and then everyone else raised their prices. Took years to come back down again. There is a revolution coming where the RAM will no longer be volatile. That is a very interesting change that i have planned for in my Beads system. Writing to the disk will be a thing of the past."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1585420887.013400",
        "parent_user_id": "U8A5MS6R1"
    }
]