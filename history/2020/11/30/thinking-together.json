[
    {
        "client_msg_id": "9e8b1758-43ab-440c-a42a-eb7995083f2a",
        "type": "message",
        "text": "The one point made by <@U8A5MS6R1> on which I tend to insist is \"standardize\". It's actually a condition for productively moving on to higher abstraction levels. The reason we can discuss information management at the byte level (and higher) is that we do have standards for storing and communicating bytes. Even the byte itself as a practical unit of information is a standard.\n\nIf you look at the history of computing, it started out, like other technologies, with cycles of messy innovation followed by standardization. Until about the year 2000. All major standards of the computing world were created before 2000, although some have been updated since. But nobody seems to be interested in standardization any more. Tech is dominated by a few big players whose game is \"Who can impose their conventions on the rest of the world?\" And even small players accept this game, proposing new ideas they consider \"better\", and thus deserving to \"win\" by the ideas of meritocracy. Some have been cited above.\n\nSo what happened to the idea of compromise for the benefit of everyone? Many technical issues are reasonably well understood. We know about the relative benefits of function calls with on-stack argument passing, subprocess creation with command-line arguments, and other techniques for calling code blocks. A committee of experts could come up with a minimal list of techniques that cover the various use cases\/priorities, and write up a standard with something like three or four calling conventions. If everybody accepted and implemented them, we could then move on to discussing higher levels of abstraction. But this isn't happening. There is no incentive for agreeing with others. Can we fix that somehow?",
        "user": "UJBAJNFLK",
        "ts": "1606733271.169400",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "e169f54bbaf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-03-12\/1859691333940_e169f54bbaf8b9b36b12_72.png",
            "first_name": "Konrad",
            "real_name": "Konrad Hinsen",
            "display_name": "Konrad Hinsen",
            "team": "T5TCAFTA9",
            "name": "konrad.hinsen",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "OjXS",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The one point made by "
                            },
                            {
                                "type": "user",
                                "user_id": "U8A5MS6R1"
                            },
                            {
                                "type": "text",
                                "text": " on which I tend to insist is \"standardize\". It's actually a condition for productively moving on to higher abstraction levels. The reason we can discuss information management at the byte level (and higher) is that we do have standards for storing and communicating bytes. Even the byte itself as a practical unit of information is a standard.\n\nIf you look at the history of computing, it started out, like other technologies, with cycles of messy innovation followed by standardization. Until about the year 2000. All major standards of the computing world were created before 2000, although some have been updated since. But nobody seems to be interested in standardization any more. Tech is dominated by a few big players whose game is \"Who can impose their conventions on the rest of the world?\" And even small players accept this game, proposing new ideas they consider \"better\", and thus deserving to \"win\" by the ideas of meritocracy. Some have been cited above.\n\nSo what happened to the idea of compromise for the benefit of everyone? Many technical issues are reasonably well understood. We know about the relative benefits of function calls with on-stack argument passing, subprocess creation with command-line arguments, and other techniques for calling code blocks. A committee of experts could come up with a minimal list of techniques that cover the various use cases\/priorities, and write up a standard with something like three or four calling conventions. If everybody accepted and implemented them, we could then move on to discussing higher levels of abstraction. But this isn't happening. There is no incentive for agreeing with others. Can we fix that somehow?"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1606359276.136400",
        "parent_user_id": "UCUSW7WVD",
        "reactions": [
            {
                "name": "100",
                "users": [
                    "U5STGTB3J",
                    "U8A5MS6R1"
                ],
                "count": 2
            },
            {
                "name": "point_up_2",
                "users": [
                    "U5STGTB3J"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "A133D81D-6E99-4BA2-AFD8-F705C4ED9BA0",
        "type": "message",
        "text": "A different solution to the same problem is offered by the universal build systems Nix and Guix. They turn all file references into content addressing via cryptographic hashes, which they compute from a global build configuration.",
        "user": "UJBAJNFLK",
        "ts": "1606745437.172700",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "e169f54bbaf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-03-12\/1859691333940_e169f54bbaf8b9b36b12_72.png",
            "first_name": "Konrad",
            "real_name": "Konrad Hinsen",
            "display_name": "Konrad Hinsen",
            "team": "T5TCAFTA9",
            "name": "konrad.hinsen",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "PS0",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "A different solution to the same problem is offered by the universal build systems Nix and Guix. They turn all file references into content addressing via cryptographic hashes, which they compute from a global build configuration."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1606580326.162400",
        "parent_user_id": "UMVFWPZ36",
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "UMVFWPZ36",
                    "UDQKHNP51"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "be264f87-69d7-4ebe-8075-11f770cf1c0e",
        "type": "message",
        "text": "<@U016VUZGUUQ> wrote:\n&gt; Perhaps the closest thing to a disagreement is this: it would be more precise to say that we're only doing the work once, rather than not doing it at all (and we want to let a compiler handle the details of hooking up encodings to business logic).\nI think that's fair. There's definitely some work we'll always need to do and some complexity in the way. BTW there's an old thread which disputes that there's a sharp distinction between incidental and essential complexity. Hopefully this <https:\/\/marianoguerra.github.io\/future-of-coding-weekly\/history\/?fromDate=2020-02-03&amp;toDate=2020-02-05&amp;channel=general#2020-02-04T04:04:54.491Z|link to the search history> works.",
        "user": "U8A5MS6R1",
        "ts": "1606761117.173300",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "b7c63cc07373",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-03-21\/584465935395_b7c63cc07373326ec6ea_72.jpg",
            "first_name": "Shalabh",
            "real_name": "Shalabh",
            "display_name": "shalabh",
            "team": "T5TCAFTA9",
            "name": "shalabh.chaturvedi",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "MxX",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U016VUZGUUQ"
                            },
                            {
                                "type": "text",
                                "text": " wrote:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Perhaps the closest thing to a disagreement is this: it would be more precise to say that we're only doing the work once, rather than not doing it at all (and we want to let a compiler handle the details of hooking up encodings to business logic)."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I think that's fair. There's definitely some work we'll always need to do and some complexity in the way. BTW there's an old thread which disputes that there's a sharp distinction between incidental and essential complexity. Hopefully this "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/marianoguerra.github.io\/future-of-coding-weekly\/history\/?fromDate=2020-02-03&toDate=2020-02-05&channel=general#2020-02-04T04:04:54.491Z",
                                "text": "link to the search history"
                            },
                            {
                                "type": "text",
                                "text": " works."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1606359276.136400",
        "parent_user_id": "UCUSW7WVD"
    },
    {
        "client_msg_id": "4fd45fab-d48a-4af8-bfac-36723355c105",
        "type": "message",
        "text": "Bad behavior by tech companies aside (which I agree is a problem), I disagree that we're technically ready to standardize on inter-procedure calling conventions. In particular, picking among the current options for inter-process communication fills me with dread. I don't see consensus on how to even address processes, much less a language for them to speak.\n\nIt's natural for higher-level abstractions to take longer to stabilize. In some sense they have more degrees of freedom in their design, so there's an exponentially larger search space. More tradeoffs to optimize, with more local minima.",
        "user": "U016VUZGUUQ",
        "ts": "1606762390.173500",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gaee3c99144d",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/aee3c99144dfc6644c6c1f1303683140.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0009-72.png",
            "first_name": "",
            "real_name": "Andrew F",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "andrewflnr",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Oph",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Bad behavior by tech companies aside (which I agree is a problem), I disagree that we're technically ready to standardize on inter-procedure calling conventions. In particular, picking among the current options for inter-process communication fills me with dread. I don't see consensus on how to even address processes, much less a language for them to speak.\n\nIt's natural for higher-level abstractions to take longer to stabilize. In some sense they have more degrees of freedom in their design, so there's an exponentially larger search space. More tradeoffs to optimize, with more local minima."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1606359276.136400",
        "parent_user_id": "UCUSW7WVD"
    },
    {
        "client_msg_id": "48ae420f-c000-4449-8456-59b254622212",
        "type": "message",
        "text": "Using a standard model that is higher level and *independent* of the underlying mechanism is key. This is the option 2 I was suggesting earlier in the thread. Eg. with TCP\/IP you don't have to stay stuck to copper wire or powerline or whatever it was originally designed with. You can switch those around _even later_ while the systems using it continue to work. Same thing with 'bits'. This is why I am interested in models that are \"not bits\" however \"can be mapped to bits many different ways\". BTW, transmitting and storing information is a subset of organizing computation (e.g. decomposing into processes, defining execution models), so doing this abstract model for distributed computation is much harder.\n\nOne more thing I find very interesting is that software gives us a new superpower for achieving standardization because it is \"virtual\". Imagine you could magically and instantaneously ship FM receivers to everyone in the world. The shift from AM radio to FM would be overnight. With software, the limitations of hardware are gone, you can actually ship such software _receivers_. Yet we live in a world where switching to a new _software_ protocol or media format is very burdensome. Our standard-making ideas are holdovers from a hardware world. So maybe instead of making software standards we usually do,we should be inventing new standard-making software (i.e. standardize the meta level)?",
        "user": "U8A5MS6R1",
        "ts": "1606763676.173700",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "b7c63cc07373",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-03-21\/584465935395_b7c63cc07373326ec6ea_72.jpg",
            "first_name": "Shalabh",
            "real_name": "Shalabh",
            "display_name": "shalabh",
            "team": "T5TCAFTA9",
            "name": "shalabh.chaturvedi",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "dYIcU",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Using a standard model that is higher level and "
                            },
                            {
                                "type": "text",
                                "text": "independent",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " of the underlying mechanism is key. This is the option 2 I was suggesting earlier in the thread. Eg. with TCP\/IP you don't have to stay stuck to copper wire or powerline or whatever it was originally designed with. You can switch those around "
                            },
                            {
                                "type": "text",
                                "text": "even later",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " while the systems using it continue to work. Same thing with 'bits'. This is why I am interested in models that are \"not bits\" however \"can be mapped to bits many different ways\". BTW, transmitting and storing information is a subset of organizing computation (e.g. decomposing into processes, defining execution models), so doing this abstract model for distributed computation is much harder.\n\nOne more thing I find very interesting is that software gives us a new superpower for achieving standardization because it is \"virtual\". Imagine you could magically and instantaneously ship FM receivers to everyone in the world. The shift from AM radio to FM would be overnight. With software, the limitations of hardware are gone, you can actually ship such software "
                            },
                            {
                                "type": "text",
                                "text": "receivers",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ". Yet we live in a world where switching to a new "
                            },
                            {
                                "type": "text",
                                "text": "software",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " protocol or media format is very burdensome. Our standard-making ideas are holdovers from a hardware world. So maybe instead of making software standards we usually do,we should be inventing new standard-making software (i.e. standardize the meta level)?"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1606359276.136400",
        "parent_user_id": "UCUSW7WVD"
    },
    {
        "client_msg_id": "6ef7d19c-33c9-4c0a-a0ae-d15ddb6fa5f2",
        "type": "message",
        "text": "<@URKQXRCAC> I am not a fan of object oriented programming and design. I've had several decades experience of OOP in an industrial programming setting, I see a lot of problems, and I'm looking for better methodologies.\n\nI like the philosophy behind modular programming (eg, as seen in SML). Your code is decomposed into modules, on the criterion of information hiding. A module encapsulates an important design decision, and hides the implementation of that decision behind an abstract interface. A module can contain a collection of functions, or it can encapsulate a single data type together with operations on that type, hiding the types representation. Or it can encapsulate 2 or more closely related data types, hiding their representations and exporting operations on those types. But, and this is important, there is no requirement that functions must be placed in the same module as the type of their first argument. That requirement would prevent you from modularizing your code effectively. Modules can be nested, and information hiding can occur at each level of nesting, if needed. At the top level, a package (the unit of software distribution across the internet) is also a module. The problem with class-based OOP is that the unit of modularity is the data type. This distorts the large scale structure of a system by inhibiting you from modularizing in the most effective way.\n\nInheritance in class-based OOP languages is a bad idea, it's the enemy of modularity. A modular should have a simple abstract interface that it easy to understand and document, and this interface should hide implementation details. Consider the interface to a class that exports virtual functions, and expects subclasses to override those virtual functions. In practice, the only way to understand such an interface is by reading the superclass's source code. Which is the opposite of abstraction and hiding implementation details.",
        "user": "UJN1TAYEQ",
        "ts": "1606765624.173900",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g4185a542241",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/34185a5422416f82b3e4a62964f2866b.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0008-72.png",
            "first_name": "",
            "real_name": "Doug Moen",
            "display_name": "Doug Moen",
            "team": "T5TCAFTA9",
            "name": "doug",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "A1j",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "URKQXRCAC"
                            },
                            {
                                "type": "text",
                                "text": " I am not a fan of object oriented programming and design. I've had several decades experience of OOP in an industrial programming setting, I see a lot of problems, and I'm looking for better methodologies.\n\nI like the philosophy behind modular programming (eg, as seen in SML). Your code is decomposed into modules, on the criterion of information hiding. A module encapsulates an important design decision, and hides the implementation of that decision behind an abstract interface. A module can contain a collection of functions, or it can encapsulate a single data type together with operations on that type, hiding the types representation. Or it can encapsulate 2 or more closely related data types, hiding their representations and exporting operations on those types. But, and this is important, there is no requirement that functions must be placed in the same module as the type of their first argument. That requirement would prevent you from modularizing your code effectively. Modules can be nested, and information hiding can occur at each level of nesting, if needed. At the top level, a package (the unit of software distribution across the internet) is also a module. The problem with class-based OOP is that the unit of modularity is the data type. This distorts the large scale structure of a system by inhibiting you from modularizing in the most effective way.\n\nInheritance in class-based OOP languages is a bad idea, it's the enemy of modularity. A modular should have a simple abstract interface that it easy to understand and document, and this interface should hide implementation details. Consider the interface to a class that exports virtual functions, and expects subclasses to override those virtual functions. In practice, the only way to understand such an interface is by reading the superclass's source code. Which is the opposite of abstraction and hiding implementation details."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1603601936.277700",
        "parent_user_id": "U5STGTB3J"
    },
    {
        "client_msg_id": "bd6464dc-819b-4a13-ac96-74099316648f",
        "type": "message",
        "text": "Exactly. Calling conventions can require some intermediary, which could well involve no performance overhead via JIT techniques.",
        "user": "UJBAJNFLK",
        "ts": "1606765647.174100",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "e169f54bbaf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-03-12\/1859691333940_e169f54bbaf8b9b36b12_72.png",
            "first_name": "Konrad",
            "real_name": "Konrad Hinsen",
            "display_name": "Konrad Hinsen",
            "team": "T5TCAFTA9",
            "name": "konrad.hinsen",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "6O8al",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Exactly. Calling conventions can require some intermediary, which could well involve no performance overhead via JIT techniques."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1606359276.136400",
        "parent_user_id": "UCUSW7WVD"
    },
    {
        "client_msg_id": "f10229ec-3334-44f0-bee4-f0e6892640c3",
        "type": "message",
        "text": "Another problem with OOP is that it is fundamentally based on shared mutable state. You system is composed of objects, each of which has an identity and mutable state, and you compute by sending messages to those objects, causing them to change their internal state. Shared mutable state is the source of massive complexity in software systems.",
        "user": "UJN1TAYEQ",
        "ts": "1606765776.174300",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g4185a542241",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/34185a5422416f82b3e4a62964f2866b.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0008-72.png",
            "first_name": "",
            "real_name": "Doug Moen",
            "display_name": "Doug Moen",
            "team": "T5TCAFTA9",
            "name": "doug",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "lL\/cO",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Another problem with OOP is that it is fundamentally based on shared mutable state. You system is composed of objects, each of which has an identity and mutable state, and you compute by sending messages to those objects, causing them to change their internal state. Shared mutable state is the source of massive complexity in software systems."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1603601936.277700",
        "parent_user_id": "U5STGTB3J"
    },
    {
        "client_msg_id": "709dfdb4-a710-4e1f-ae33-8793c3d13126",
        "type": "message",
        "text": "So I want a better programming methodology than OOP, one that has very good support for modularity, simple abstract interfaces, composable software components. The solutions I'm looking at are related to functional programming. Instead of mutable objects, you work with immutable values. Instead of \"Object Oriented Design\", I'm learning \"Algebra Driven Design\", where you consider a type (a set of immutable values), together with constructors for those values, and operations on those values, as an algebra. You work out the equational laws that relate these constructors and operations, and that gives you the abstract interface and the semantics of your algebra (which is a kind of module). My experience so far is that this design methodology can produce simple, elegant and powerful interfaces that have a quality of \"life\" that I would not be able to reproduce in any other way. I found the book \"Algebra Driven Design\" to be helpful in learning how this works.",
        "user": "UJN1TAYEQ",
        "ts": "1606766276.174500",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g4185a542241",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/34185a5422416f82b3e4a62964f2866b.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0008-72.png",
            "first_name": "",
            "real_name": "Doug Moen",
            "display_name": "Doug Moen",
            "team": "T5TCAFTA9",
            "name": "doug",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "P2dG0",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "So I want a better programming methodology than OOP, one that has very good support for modularity, simple abstract interfaces, composable software components. The solutions I'm looking at are related to functional programming. Instead of mutable objects, you work with immutable values. Instead of \"Object Oriented Design\", I'm learning \"Algebra Driven Design\", where you consider a type (a set of immutable values), together with constructors for those values, and operations on those values, as an algebra. You work out the equational laws that relate these constructors and operations, and that gives you the abstract interface and the semantics of your algebra (which is a kind of module). My experience so far is that this design methodology can produce simple, elegant and powerful interfaces that have a quality of \"life\" that I would not be able to reproduce in any other way. I found the book \"Algebra Driven Design\" to be helpful in learning how this works."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1603601936.277700",
        "parent_user_id": "U5STGTB3J"
    }
]