<!--
.. title: Future of Coding Weekly 2023/08 Week 2
.. slug: future-of-coding-weekly-202308-week-2
.. date: 2023-08-13 23:09:00 UTC+02:00
.. tags: 
.. category: 
.. link: 
.. description: 
.. type: text
-->

âš™ï¸ Rage Against the State Machine ğŸš² Structured Focused Writing ğŸ’¡ Live, Rich & Composable

# Our Work

ğŸ¦ [Nicolae Rusan on Twitter](https://twitter.com/NicolaeRusan/status/1689428120695390208) via **Nicolae Rusan**

[ğŸ§µ conversation](https://history.futureofcoding.org/history/weekly/2023/08/W2/share-your-work.html#2023-08-10T01:25:50.554Z)

ğŸ‘‹ howdy folks! We just shipped an integration for Linear & Github issues in Magnet ([www.magnet.run](http://www.magnet.run)) our AI coding assistant that is powered by GPT-4.



This gives you a way to quickly take an issue, and go end-to-end on getting suggestion for relevant files, having Magnet ask clarifying questions, and having it make suggestions on how to implement the feature across your entire stack, e.g. front-end, backend, and database.




Lots of fun explorations as weâ€™ve built this, and weâ€™re going to be diving deeper into some of the research questions that have come up in terms of how to give AI appropriate context on the task at hand

> ğŸ¦ [Nicolae Rusan on Twitter](https://twitter.com/NicolaeRusan/status/1689428120695390208): Magnet (<https://t.co/hyTk0nzO28>) now offers Linear &amp; GitHub issue integration:
>
> â†’ Start a workflow from a Linear or GitHub issue
> â†’ Magnet suggests relevant files from your codebase for that issue
> â†’ Magnet poses clarifying questions, guiding you end-to-end on features and bugs
>

ğŸ¥ [Magnet Issues Integration - Adding a new feature around meta tags](https://www.loom.com/share/e20772ec32b248ba977bbb9d526c0951?t=1) via **Nicolae Rusan**

[ğŸ§µ conversation](https://history.futureofcoding.org/history/weekly/2023/08/W2/share-your-work.html#2023-08-10T01:26:34.265Z)

ğŸ¥ Hereâ€™s a Loom video of me starting from an issue in Linear and getting to a working feature using Magnet if you want to skip the thread above:

>In this video, I discuss how I am utilizing magnets to enhance the process of shipping new features. I noticed that when sharing a magnet link from our blog, the title tags and images were not updated for the specific blog posts on the blog page. To address this, I demonstrate how to select the relevant files using the linear issues integration and suggest implementing the feature. Additionally, I explore the benefits of using Next SEO and explain why it is a valuable addition. Join me as we work on this feature together!

ğŸ¤– [Visual Programming in VSCode: Create Discord Bots the Easy Way](https://www.flyde.dev) via **Gabriel Grinberg**

[ğŸ§µ conversation](https://history.futureofcoding.org/history/weekly/2023/08/W2/share-your-work.html#2023-08-12T18:54:32.844Z)

Hey all ğŸ‘‹

I just published a tutorial on how to use Flyde ([flyde.dev](https://www.flyde.dev)) to build a Discord bot - [Visual Programming in VSCode: Create Discord Bots the Easy Way](https://medium.com/@gabrielgrinberg/visual-programming-in-vscode-create-discord-bots-the-easy-way-dcccc6a9528d) - an attempt to provide a real-world use-case to visual flow-based programming ğŸš€



Looking forward to any feedback or comment ğŸ™



PS: It's more beginners oriented, as that's the direction I'm taking Flyde at the moment, so expect it to be laid simpler than the usual content here ğŸ™ƒ

![gif5.gif](http://history.futureofcoding.org/history/msg_files/F05/F05M4CMKV1D.gif)

# Devlog Together

ğŸ’¬ [Kartik Agaram](http://akkartik.name/about)

[ğŸ§µ conversation](https://history.futureofcoding.org/history/weekly/2023/08/W2/devlog-together.html#2023-08-11T18:09:57.149Z)

Yesterday was a good day. I built a little app for someone to connect to their R server, plot a dataset based on different dimensions. Pretty trivial, but hopefully easier for them to modify than other similar apps out there.


# Thinking Together

ğŸ¦ [John Carmack on Twitter](https://twitter.com/ID_AA_Carmack/status/1689297553408315392) via [Mariano Guerra](https://twitter.com/warianoguerra)

[ğŸ§µ conversation](https://history.futureofcoding.org/history/weekly/2023/08/W2/thinking-together.html#2023-08-10T09:23:06.827Z)

What do you think about this?








> ğŸ¦ [John Carmack on Twitter](https://twitter.com/ID_AA_Carmack/status/1689297553408315392): Despite all the effort that has gone into it, it doesnâ€™t look like programming language design has any real compounding power. There are better and worse languages, but other market and technical forces can swamp language choices.


âš™ï¸ [State machine: Rplot](https://docs.google.com/document/d/1EbK4AxDCDWonMa8KyGJFX4jllXXLew0qBsGxsmqoYqk) via [Kartik Agaram](http://akkartik.name/about)

[ğŸ§µ conversation](https://history.futureofcoding.org/history/weekly/2023/08/W2/thinking-together.html#2023-08-13T16:59:59.321Z)

Last night I spent some time documenting an almost-trivial state machine that I keep getting wrong: [State machine: Rplot](https://docs.google.com/document/d/1EbK4AxDCDWonMa8KyGJFX4jllXXLew0qBsGxsmqoYqk)



State machines are  _hard_ !




* We usually have one in our head when we program.
* The abstract state in my head is usually made up of multiple concrete variables in the program.
* Mutations happen to variables, but it's not obvious at each how the abstract state is changing.
* The state machine in my head often evolves, which makes documentation challenging to keep up to date. Which is why I think nobody builds documents like these.



Tell me how immutability or State Charts will solve all my problems ğŸ™‚


# Content

ğŸš² [Bike Outliner: Structured focused writing app for Mac](https://www.hogbaysoftware.com/bike/) via **Eli Mellen**

[ğŸ§µ conversation](https://history.futureofcoding.org/history/weekly/2023/08/W2/linking-together.html#2023-08-07T14:24:36.681Z)

[Is anyone else using Jesse Grosjeanâ€™s Bike outliner on mac?](https://www.hogbaysoftware.com/bike/)



As an outliner it is fairly minimal. It canâ€™t hold a candle to something like omnioutliner or org-mode by ways of features. But the text handling and rendering is pretty gorgeous, especially at input.
> ğŸ“ [Bike Outliner: Structured focused writing app for Mac](https://www.hogbaysoftware.com/bike/)
>
>Use Bike to think, write, organize. Make lists, take notes, create documents. Bike's an unusually fast outliner designed for your Mac.

ğŸ’» [Project IDX](https://idx.dev/) via [Mattia Fregola](https://twitter.com/MattiaFregola)

[ğŸ§µ conversation](https://history.futureofcoding.org/history/weekly/2023/08/W2/linking-together.html#2023-08-09T06:21:15.546Z)

[idx.dev](https://idx.dev)
> ğŸ“ [Project IDX](https://idx.dev/)
>
>Project IDX is an entirely web-based workspace for full-stack application development, complete with the latest generative AI (powered by Codey and PaLM 2), and full-fidelity app previews, powered by cloud emulators.



ğŸ“ [Who Can Name the Bigger Number?](https://www.scottaaronson.com/writings/bignumbers.html) via **Eli Mellen**

[ğŸ§µ conversation](https://history.futureofcoding.org/history/weekly/2023/08/W2/linking-together.html#2023-08-11T18:57:11.038Z)

Has anyone read [Who Can Name the Bigger Number?](https://www.scottaaronson.com/writings/bignumbers.html) It was just recommended to me at work

ğŸ’¡ [Live, Rich, and Composable: Qualities for Programming Beyond Static Text](https://arxiv.org/pdf/2303.06777.pdf) via [Lu Wilson](https://twitter.com/TodePond)

[ğŸ§µ conversation](https://history.futureofcoding.org/history/weekly/2023/08/W2/linking-together.html#2023-08-12T08:31:31.772Z)

This was posted here back in March but it didn't get much discussion (at least, that's what the archive says), so I'm reposting: [arxiv.org/pdf/2303.06777.pdf](https://arxiv.org/pdf/2303.06777.pdf)


ğŸ“ [Do Machine Learning Models Memorize or Generalize?](https://pair.withgoogle.com/explorables/grokking) via [Kartik Agaram](http://akkartik.name/about)

[ğŸ§µ conversation](https://history.futureofcoding.org/history/weekly/2023/08/W2/of-ai.html#2023-08-10T22:15:09.739Z)

 *Grokking*






> In 2021, researchers made a striking discovery while training a series of tiny models on toy tasks . They found a set of models that suddenly flipped from memorizing their training data to correctly generalizing on unseen inputs after training for much longer. This phenomenon â€“ where generalization seems to happen abruptly and long after fitting the training data â€“ is called
>  _grokking_
>  and has sparked a flurry of interest .

>An interactive introduction to grokking and mechanistic interpretability.

